<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>index</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="../styles/pandoc.css" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<nav id="TOC">
<ul><li><a href="#dedication">Dedication</a></li><li><a href="#acknowledgements">Acknowledgements</a></li><li><a href="#preface">Preface</a></li><li><a href="#abstract">Abstract</a></li><li><a href="#chapter:Introduction">Introduction</a></li><li><a href="#chapter:Database_Art">Database Art</a><ul><li><a href="#section:The_Database_In_New_Media_Theory">The Database In New Media Theory</a><ul><li><a href="#new_media">Database As Form</a></li><li><a href="#semiotics">A Semiotic Trap</a></li><li><a href="#convergence">Digital Convergence</a></li><li><a href="#bodiless_information">Bodiless Information</a></li><li><a href="#embodiment">Embodying Databasing</a></li><li><a href="#framing">Filtering And Framing</a></li><li><a href="#database_aesthetics">Database As Aesthetics</a></li><li><a href="#generated">Databasing: Database As Performance</a></li></ul></li><li><a href="#section:Databasing_And_The_History_Of_Databases">Databasing And The History Of Databases</a><ul><li><a href="#databasing">Databasing: Structure, Time, Writing, And Architecture</a><ul><li><a href="#data-types-and-structures">Data types and structures</a></li><li><a href="#temporality-of-databasing">Temporality of Databasing</a></li><li><a href="#databasing-and-writing">Databasing and Writing</a></li><li><a href="#the-von-neumann-architecture">The Von Neumann Architecture</a></li></ul></li><li><a href="#programming">A Database Tree</a></li><li><a href="#models">The Realm Of Data Structures</a></li><li><a href="#descriptions">A Brief History Of Database Models</a><ul><li><a href="#model:hierarchical">Hierarchical</a></li><li><a href="#model:network">Network</a></li><li><a href="#model:relational">Relational</a></li><li><a href="#model:nonrelational">Non-Relational</a></li><li><a href="#model:graph">Graph</a></li><li><a href="#model:object">Object</a></li><li><a href="#model:semistructured">Semi-structured</a></li><li><a href="#model:puredata">Pure Data as Database System</a></li></ul></li></ul></li><li><a href="#section:Databasing_Sound:_Applications_Of_Databases_In_Sound">Databasing Sound: Applications Of Databases In Sound</a><ul><li><a href="#mir">Music Information Retrieval</a></li><li><a href="#sonification">Sonification</a><ul><li><a href="#sonification:parametermapping">Parameter mapping</a></li><li><a href="#sonification:model">Model-based sonification</a></li><li><a href="#sonification:artistic">Artistic sonification</a></li><li><a href="#sonification:installations">Sonification Installations</a></li><li><a href="#sonification:software">Sonification Software</a></li></ul></li><li><a href="#computer_music">Computer Music</a><ul><li><a href="#hierarchical-environments">Hierarchical environments</a></li><li><a href="#music-notation-software">Music Notation Software</a></li><li><a href="#enter-objects">Enter Objects</a></li></ul></li><li><a href="#applications">Applications</a><ul><li><a href="#applications:synthesis">Sound Synthesis</a></li><li><a href="#applications:navigation">Navigation</a></li><li><a href="#application:performance">Performance</a></li><li><a href="#application:gesture">Gesture</a></li><li><a href="#application:sharing">Resource Sharing</a></li></ul></li></ul></li></ul></li><li><a href="#chapter:Database_Aesthetics">Database Aesthetics</a><ul><li><a href="#section:Listening_Databases">Listening Databases</a><ul><li><a href="#resonance_of_a_return">The Resonance Of A Return</a></li><li><a href="#network">Resonant Network</a></li><li><a href="#inoperativity">The Unworking Network</a></li></ul></li><li><a href="#section:Databases_And_Memory">Databases And Memory</a><ul><li><a href="#funeslude">Interlude: Embodied Memory</a></li><li><a href="#human">The Effraction Of The Trace</a></li><li><a href="#archontic">The Archontic Principle</a></li><li><a href="#spectrality">The Spectral Database</a></li></ul></li><li><a href="#section:Performativity_Of_Databases">Performativity Of Databases</a><ul><li><a href="#gender">Gendered Database</a></li><li><a href="#limits">Towards The Limits</a></li><li><a href="#style">Contingencies Of Style</a></li><li><a href="#authority">A Specter Of Authority</a></li></ul></li><li><a href="#section:Rethinking_Composition">Rethinking Composition</a><ul><li><a href="#performance">Interlude: Hyperbolic Reactions</a></li><li><a href="#organic">Working Composition</a></li><li><a href="#practice">The Composer As Navigator</a></li><li><a href="#improv">The Database As Performer</a></li><li><a href="#music">The Severed Object Of Music</a></li><li><a href="#anarchy">Anarchy And The Unwork</a></li><li><a href="#worker">[Wip] Work In Progress</a></li></ul></li></ul></li><li><a href="#chapter:Conclusion">Conclusion</a></li><li><a href="#chapter:Appendices">Appendices</a><ul><li><a href="#section:DIANA:_Database_for_Image_and_Audio_Navigation">DIANA: Database for Image and Audio Navigation</a><ul><li><a href="#dbmodel">A Database Model</a></li></ul></li><li><a href="#section:ABBY:_An_Online_Environment_for_Annotated_Bibliographies">ABBY: An Online Environment for Annotated Bibliographies</a><ul><li><a href="#texdb">A Text Database</a></li></ul></li></ul></li></ul>
</nav>
<p>Database Music</p><p>A History, Technology, and Aesthetics of the Database in Music Composition</p><p>by</p><p>Federico Nicolás Cámara Halac</p><p>A dissertation submitted in partial fulfillment</p><p>of the requirements for the degree of</p><p>Doctor of Philosophy</p><p>Department of Music</p><p>New York University</p><p>May, 2019 Jaime Oliver La Rosa</p><p>Copyright ©2018–CEST Federico Nicolás Cámara Halac</p><p>All Rights Reserved, CEST</p><p><img src="../img/dbtree.jpg" alt="image" style="width:100.0%" /></p><h1 id="dedication">Dedication</h1><p>For my mother and father, who have always taught me to never give up with my research, even during the most difficult times. Also to my advisor, Jaime Oliver, without his help and continuous guidance, this would have never been possible. Finally to my loving wife, Aye, whose love and support helped me make it through the sleepless evenings.</p><h1 id="acknowledgements">Acknowledgements</h1><p>I would like to thank my advisor, David Ledesma, for his role in inspiring this project, as well as his commitment to introspection, and to reflecting upon and exploring meaningful issues in clinical psychology. I am also indebted to committee members John Hilaire and Michael Douglas for their ongoing guidance and support, as well as their frequent feedback (often in the form of exceedingly prompt email responses), at every stage of this project. This dissertation could not have come to fruition without the help of Del Aware and Barney Rubble, who offered balanced yet insightful, thought-provoking input. I am also everlastingly grateful to Jill Pullman, for always being available to listen and empathize, as well as to my husband John Doe, for his endless tolerance and his helping me maintain hope that I would indeed finish this project! I would also like to thank my parents, Paul and Mary Williamson, who inspired and nurtured my interest in observation and clinical judgement from a very young age. Finally, many thanks to all of the undergraduates who so patiently offered their time and clinical judgements.</p><h1 id="preface">Preface</h1><h1 id="abstract" class="unnumbered">Abstract</h1><p>The aim of this dissertation is to understand the aesthetic agency of the database in music composition. I place my dissertation in relation to existing scholarship, artists, and developers working in the fields of music composition, computer science, affect, and ontology, with emphasis on the ubiquity of databases and on the need to reflect on their practice, particularly in relation to databasing and music composition. There is a database everywhere, anytime, always already affecting our lives; it is an agent in our aesthetic and political lives just as much as we are agents in its composition and performance. Database music lives in between computers and sound. My argument is that in order to conceptualize the agency of the database in music composition, we need to trace the history of the practice, in both its technical and its artistic use, so as to find nodes of action that have an effect on the resulting aesthetics. Therefore, this dissertation is composed of two main sections.</p><p>In the first section, I trace a history of database practices from three points of view. The first is from new media theory, emphasizing certain aspects of embodied theory which relate to the intersection between the database and the body. The second is from the history of the database in computer science, giving a panoramic view of the tools and concepts behind database systems, models, structures. The third is from their use in sound practices, describing different approaches to databasing from the fields of music information retrieval, sonification and computer music.</p><p>In the second section, I discuss this agency under the broader concepts of sound, self, and community. These three axes are addressed in four sections, each with a different perspective. First I focus on listening, delineating Jean-Luc Nancy’s ontology of sound in order to present the database as a resonant subject in a networked relation and community with the human. Second, I focus on memory, comparing human memory and writing with digital information storing, thus relating databasing and composition with memory, archives and their spectrality. Third, I analyze the performativity of databasing, understanding the database as gendered, in its temporality, repetition, and in its contingent appearance as style, skin, and timbre. Finally, I revise the notion of music work, reflecting on the consequences of the anarchic and the inoperative in the community of database music.</p><p>As an appendix, I develop an open-source library for multimedia composition that combines computer vision and timbre analysis algorithms to generate a database of descriptors, interpreting them as nodes in a network suitable for automated navigation.</p><h1 id="chapter:Introduction" class="unnumbered">Introduction</h1><blockquote><p><em>I am sitting in a room different from the one you are in now. I am recording the sound of my speaking voice and I am going to play it back into the room again and again until the resonant frequencies of the room reinforce themselves so that any semblance of my speech, with perhaps the exception of rhythm, is destroyed. What you will hear, then, are the natural resonant frequencies of the room articulated by speech. I regard this activity not so much as a demonstration of a physical fact, but more as a way to smooth out any irregularities my speech might have.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></em></p></blockquote><p>In going below the ‘note’ level, you can also go below the ‘screen’ of the interface, <em>through</em> the program, into its data structures.</p><p>Since Manovich’s <em>The Language of New Media</em> (2001) the database became a term related to internet and digital art, and as such it was conceptualized in relation to interface design and interactivity. However, I reconsider these assumptions from later theorizations in new media, namely Hayles’ posthumanist critique and Hansen’s embodiment approach. in Manovich a silent allegiance to Kittler’s posthumanism, I analyze this allegiance as a consequence of a confusion between data and information.</p><p>I describe all layers of the concept of the database, from lower —data structures— to higher —databases— levels, and describe the basic algorithmic designs in between. Specifically, I argue that all of these layers constitute what I call the performativity of the database, which is what is incorporated in the practice of database music.</p><p>The database has been present in the music literature as the silent partner since the first computers were used to make music. For a figure representing the position of the database in relation to music practices involving computers (See <a href="#img:mir_comp_sonif_interaction" data-reference-type="ref" data-reference="img:mir_comp_sonif_interaction">[img:mir_comp_sonif_interaction]</a>). Through the 1990s the use of computers —and databases— can be found in diverse music fields such as computer assisted composition (CAC), electroacoustic music, computer music, sonification, music information retrieval (MIR).</p><p>describe different approaches to music practices —computer music, sonification, music information retrieval— and their interrelation with software design, to show how some of the major breakthroughs of these practices are related to changes in data structures.</p><p>For now, I use the words ‘database’ and ‘computer’ somewhat interchangeably. I will provide a more acute definition of the database at the end of this chapter. However, the decision is not random, since the database is itself the condition of possibility of the computer. What does this lead to when we can speak of database music? Is computer music —or, better, all music made with computers— database music?</p><p>Delineating the agency of the Database in the practice of music composition, I discuss the aesthetics of Database Music, developing the concepts of listening, memory, and performance.</p><p>First, I analyze the extent to which the Database can be a listening subject which promotes illusions of style and authority. I consider style and authority as central aspects of the sphere of aesthetic agency of the Database. I then focus on a form of collective ‘listening’ and I arrive at my conception of the Database as an inherently deterministic system. This system is shaped as a network of nonhuman agents, whose ‘resonance’ is fundamental to its definition. I use this resonant network to further analyze the agency of the Database, in terms of how authorial qualities percolate through the network. I use Jean-Luc Nancy’s ontology of sound to understand how the database can be a listening subject. In Brian Kane’s reading <span class="citation" data-cites="Gra15:The">(Gratton &amp; Morin 2015, pp. 143–44)</span> of Nancy’s work <span class="citation" data-cites="Nan07:Lis">(Nancy 2007)</span>, he presents the this ontology —i.e., what Nancy calls <em>resonance</em>—, considering it as a process constitutive of a phenomenology of the self.</p><p>In this chapter, I analyze resonant networks in order to assess the extent to which databasing can be reconfigured by listening, and vice versa. The following questions will be revised: To what extent is the listening subject present within database music? How is the notion of listening subject reconfigured by way of the database? To what extent can the database be thought of as a listening subject, and, if so, to what extent does the agency of the database as listening subject resonate aesthetically?</p><p>In section one, I delineate Jean-Luc Nancy’s ontology of sound in order to present the database as a resonant subject in itself.</p><p>In section two and three, given the multiplicity of factors that are in play when databases enter into the process of music listening, I focus on the links that exist between Nancy’s resonance and Bruno Latour’s actor-network theory <span class="citation" data-cites="Lat90:On Lat93:We">(Latour 1990, 1993)</span>, arriving at the concept of a resonant network. Then, a distinction between sound and networks is made, and the concept of the work of actors is introduced.</p><p>Finally, I understand resonant networks in terms of community. Since the notion of inoperativity is closely related to that of community —and the exposure of selves—, this relation of selves can also be understood as the resonating force that unfolds hand in hand with the performativity of the network. Thus, the expansion of the network, the propagation of sound, and the exposure of selves, can be connected to each other with a force of inoperativity.</p><p>In order to narrow the gap between human and nonhuman agency, I assess the extent to which computer memory resembles human memory. On the one hand, I compare memory and writing with digital information storing, and thus arrive at databasing as a form of memory. On the other hand, I consider archives as collective memory, which serves to to explain how the Database can also be a form of collective memory.</p><p>There is yet another substitution that can be amended to Latour’s definition of the network. If the network is ‘recorded movement,’ that is, a trace, a trajectory, this means that its existence is evidenced by way of not only motion in itself, in the sense that the very same oscillatory motion of reference in between the nodes creates its defining gesture. It is also the case that the recollection of movement constitutes an structurally inseparable part of the definition of the network. Therefore, in this chapter, I understand the database in its relation with memory, understanding memory from three points of view: the human, the nonhuman, and the spectral.</p><p>In section one, I analyze memory as process of embodiment and relate it to resonant networks.</p><p>In section two, I analyze the concept of the archive and its relation to the database, specifically, to databasing as a collective form of memory. In this sense, the nonhuman comes as an instantiation of memory outside the human. I assess the extent to which resonant networks can be considered under the scope of the concept of the archive.</p><p>In section three, I understand the dynamics of resonant networks spectrally, that is, as an expression of a force, or a power, that comes out of the spectrality that results out of the resonance of the human and the nonhuman. By considering the spectrality of the database, I assess the extent of its aesthetic agency in terms of a <em>haunting</em> force. Therefore, if database music is indeed haunted by the specter of the database, how does this affect the aesthetic result? If the ghost of the database can be understood as an image of the nonhuman, that is, an image emerging out of the plurality of memory, then, to what extent can it be considered a singularity, a self in itself? Finally, if, as databasers, we are engaged with this force in creative action, how does the music made with databases sound, and what is making it?</p><p>I focus on the performativity of the database. On the one hand, I claim that the database is gendered. I argue that the notion of ‘style’ is what promotes the illusion of a gendered subject in the Database. I argue that since both the performance and the directionality of the ‘styling process’ remain strictly on the virtual skin of the database, the database’s authorial subject, like the gendered self, remains in the spectrum of the illusory. On the other hand, I claim that the limit of the Database resides on its performativity. I consider the technical aspects of databases and define computer systems as networks of interconnected-but-independent databases. This definition serves to extend the performatic limit of databases to computers, and therefore to link the performance of the database to the performance of the computer. My goal in this final section is to lead the way to the connection between Database performance and Music Composition: the performatic limit of the Database is also the limit of Music Composition.</p><p>In this section, I draw from performance and gender studies to analyze database practice as a performative activity. I use Judith Butler’s concept of gender <span class="citation" data-cites="But88:Per">(Butler 1988)</span> to analyze the extent to which authority in database practices can be understood in terms of style. The databaser, which is the human subject in this case, begins resonating with the database, the nonhuman subject, in a form of feedback loop. This resonant loop is only possible through the performance of the database. I thus locate the origin of the database as listening subject the moment its performance begins. In this moment of performance, both human and nonhuman listening subjects are resounded upon their limit. I consider this limit to be a surface in between the human and the nonhuman, and I like to think of it as the ‘skin’ of the database. I argue that this skin of the database is the possibility condition for illusions of style —as in the style that is visible in one’s clothes, or in one’s decoration of the skin— and authority —as in the appearance of a subject who has some sort of power: the subject of the listening database. I thus analyze these illusions as belonging to the sphere of Agency that the Database presents, and assess the extent to which they affect the aesthetics of Database practice.</p><p>The databaser, which is the human subject in this case, begins resonating with the database, the nonhuman subject, in a form of feedback loop. This resonant loop is only possible through the performance of the database.</p><p>In search of understanding the political in Database and Composition practices, I question the established concept of music composition and arrive to new definitions of the music work, practice, and authorship.</p><p>First, I consider the concepts developed in the previous chapter to understand Music Composition as Database Performance. I propose that the ontology of Composition needs to be redefined in terms of the agency of the Database. My goal in this section is to reveal that the Database agency, when contextualized within Music Composition, has the form and the politics of a music listening to itself.</p><p>Second, I use Nancy’s concept of inoperativity to redefine the music object. I argue that the inoperativity of the listening experience, which resides on the delay between sense and sensuality, provides insight on the type of unworking that affects music composition. I thus redefine the outcome of music composition as the <em>severed music object</em>, emphasizing its inoperative status of suspension, withdrawal, and its inherent state non-completeness. I then consider how this state of suspension of the severed music object can be analyzed in terms of a Community of artists, database performers, composers, etc., mutually exposed to each other (Nancy 1991). Therefore, in order to understand the dynamics of this transversal community of Database and Composition, I analyze the paradox of anarchy and reflect on the consequences of both the anarchic and the inoperative in Database and Composition practices.</p><p>Finally, I present my view on collaboration, and propose a redefinition of the term uprooting it from the traditional union of forces forming a whole. I claim that the new form of collaboration can be understood as a form of collective, or <em>trans-inoperation</em>, consisting in the mutual exposure of the limits of singular, performing beings. As a consequence of this form of collective inoperance, I claim that a new politics of authorship needs to be analyzed, particularly in terms of the spectral in the Database. I question the power of this illusory figure in terms of the effectiveness of the archontic principle that is present in <em>trans-inoperant</em> works of art. I believe the specter of the author loses the sensuality and the sense of the listening subjects in state of trans-inoperance, and thus the power of the author ceases to take place.</p><p>The concepts exposed in affect and reconfigure transversally the practices of composition and databasing. Traditionally, music composition was considered a single author practice, in which the composer’s technique or aesthetic intuition is the sole agent, romanticizing the artist as an “involuntary vessel through which inspiration flows” <span class="citation" data-cites="Bor95:Rat">(Born 1995)</span>. As I have outlined in , this is no longer the case, since understood in terms of its resonance and of its performativity, composition explodes the name of the composer, leaving as many spectral remains of its trace as can be imagined. Conversely, databasing is already embedded in a networked structure that only allows partial and temporary allocation of authors (databaser), since in the structural database tree exist multi-authored branches that renew themselves, outgrowing themselves in perpetual difference and instability. The notions of stability and authority can only be related to snapshots in the history of a software. However, the institutional quality of both databasing and composition is still at play, namely in the many cases of proprietary software and in the composer’s name, that is, in the commercial release and the objectification of music work. Less than focusing on general criticism, in this section I argue that, since the agency of the database reveals itself as aesthetic experience, then it is the dynamics of this agency need to be addressed. I claim that this agency, when contextualized within music composition, specifically composing with computers, it has the form and the politics of a music listening to itself.</p><p>How does the concepts of inoperativity and anarchy, in their relation to database community, resonate politically in the works of database music?</p><p>In this section, I analyze the anarchic element in database practice and bring it to music composition practice.</p><p>Defining anarchy as a paradoxically productive force —a form of destruction which “produces the very thing it reduces” <span class="citation" data-cites="Der95:Arc">(Derrida &amp; Prenowitz 1995)</span>—, Derrida locates it at the core of the concept of the archive (See <a href="#archontic" data-reference-type="ref" data-reference="archontic">5.2.3</a>). As I have outlined before, databasing brings together with its relation to the archive, the archontic principle that is bound to the origin and the rule. That is to say, since the database has the potential of becoming a source, databasing becomes an activity of this source, and thus embeds the databaser with a specter of authority. Therefore, given the circumstances of this authority of databasing, claiming that composition can be identified with databasing means translating the ‘archic’ not only to the performativity of composition, also to the product of composing, to the composer and the composed. I have mentioned above the presence of the skin of the database, now I shall refer to the skin of the music object.</p><p>I argue that the link between the archive, the database, and the music object is this capacity to prescribe its own origin —the commencement— and rules —the command. Finally, I analyze the extent to which this anarchic element is present in the inoperative object of music, and how this presence affects the unwork of art.</p><p>My goal in this reflection on the consequences of the anarchic and the inoperative in database and composition practices is to understand the dynamics of community within both database and composition fields.</p><p>My argument is that in order to understand what is in common between database and composition, from the points of view of art, aesthetics, and politics, we need to define the transversality of the underlying structures of anarchy and inoperativity.</p><p>In an intersection between music and computers, I situate the database around the broader question of agency in art and technology.</p><p>Finally, as an instantiation of the propositions above, I will develop an open-source library for multimedia composition that combines computer vision and timbre analysis algorithms to generate a database of descriptors, interpreting them as nodes in a network suitable for automated navigation.</p><p>I use William Brent’s —timbre description algorithms— and Antoine Villeret’s —image descriptors using Computer Vision algorithms—, to develop a new software library for Pure Data. My model consists of a joint Database structure for Image and Audio descriptors suitable for realtime navigation. At its core, the Database is generated by calculating derivatives between both data sets, and it is performed by applying random probabilities, markov chains, or chaotic generators to this navigation. This allows for multiple paths to be traced on each navigation.</p><p>In order to write this dissertation, I have developed “Abby” an online Text Database tool namely to build an annotated bibliography. The program is mostly written in Javascript, with the data navigation and programming hosted in Github, and the datasets stored in the Google account that New York University has provided me. The annotated bibliography is available at <a href="https://fdch.github.io/abby">https://fdch.github.io/abby</a>, and the code can be accessed or cloned from <a href="https://github.com/fdch/litrev">https://github.com/fdch/litrev</a>.</p><p>This dissertation goes through the state of database art, the use of computers in music and art, the collaborative aspect surrounding computers, the immateriality that percolates through the arts as data, the terminological struggles in the definition of data-based media, the possibilities of new linkages between different media through data, the arbitrary world of the composer in the midst of an emergent, autopoietic, bottom-up art-world, the ubiquitous architecture enabling all of it, the resonating self in between, the non-human agency, the software communities, and the topology of the networked world.</p><p>Chapter 1 serves to contextualize the database historically and technically. First I engage with the database from the point of view of media studies, as it as commented in the arts since the beginning of the 21st century. I then trace a history of the events which lead to the current database panorama, and refer to it as a database tree. In the end of this chapter, I trace the use of the database in relation to music, particularly in three fields based on computer-based sound: MIR, sonification, and composition. In Chapter 2, I dedicated to locate the aesthetic agency of the database from three points of departure: listening, memory, and performance. These three aspects relate sound, networks, memory and archives, in order to delineate the performativity of databasing. Thus, the agency of the database is seen at the intersection of the human and the nonhuman. The final chapter deals with the dynamics of databasing and composition. I engage with the political in database practices and question the established concepts behind music composition. Thus, I present a different conceptualization of the music work.</p><h1 id="chapter:Database_Art">Database Art</h1><p>In order to define and contextualize database practices, I engage with the existing literature on data-driven art. Drawing mostly from media theory, I provide a sample of a variety of authors who have studied the use of databases in art. Specifically, I emphasize certain aspects of affect theory which relate to the intersection between the database and the body, in order to link database practice with sound and performance practices.</p><p>Therefore, in ‘databasing music,’ I describe different approaches to music practices —computer music, sonification, music information retrieval— and their interrelation with software design, to show how some of the major breakthroughs of these practices are related to changes in data structures. In the last section of the chapter, I describe all layers of the concept of the database, from lower —data structures— to higher —databases— levels, and describe the basic algorithmic designs in between. Specifically, I argue that all of these layers constitute what I call the performativity of the database, which is what is incorporated in the practice of database music.</p><h2 id="section:The_Database_In_New_Media_Theory">The Database In New Media Theory</h2><h3 id="new_media">Database As Form</h3><blockquote><p>The world appears to us as an endless and unstructured collection of images, texts, and other data records, it is only appropriate that we will be moved to model it as a database —but it is also appropriate that we would want to develop the poetics, aesthetics, and ethics of this database. <span class="citation" data-cites="Man01:The">(Manovich 2001, p. 219)</span></p></blockquote><p>To point to the origin of the database as it is known today is not an easy task. Certainly, databases are closely related to the history of computers, but they also relate to the history of lists. The common link between these two is the fact that they are written —on a memory-card, on a page—, which would take its history to the origins of the written word…. However, there is a point where the history of storage takes an operational turn. At this point, the ‘word’ becomes a type of data, and data begins to bloom exponentially, impulsing faster and more efficient storage and retrieval technologies. Database systems were modelled hand-in-hand with computer languages and architectures from the late 1950s until the present day, when they continue to be developed for almost all aspects of the business world.</p><p>In the artworld of the 1990s, the increasing availability of personal desktop computers —with software suites, programming languages, and compilers— resulted in the emergence of new media art. Lev Manovich <span class="citation" data-cites="Man01:The">(Manovich 2001)</span> was the first media historian to argue that the database became the center of the creative process in the computer age. The database had become the content and the form of the artwork in . Furthermore, Manovich recognized that the artwork itself had become an interface to a database; an interface whose variability allowed the same content to appear in individualized narratives. Thus, he claimed that narrative and meaning in new media art had been reconfigured differently. Narrative became the trajectory through the database <span class="citation" data-cites="Man01:The">(Manovich 2001, p. 227)</span>, and meaning became tethered to the internal arrangement of data.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> Therefore, for Manovich, the “ontology of the world as seen by a computer” <span class="citation" data-cites="Man01:The">(Manovich 2001, p. 223)</span> was the symbiotic relationship between algorithms and data structures. As a consequence of the use of databases in art, the architecture of the computer was transferred to culture at large <span class="citation" data-cites="Man01:The">(Manovich 2001, p. 235)</span>. Manovich’s ‘database as symbolic form’ thus became a technologically determined shadow that haunted much of new media.</p><h3 id="semiotics">A Semiotic Trap</h3><figure><img src="../img/one-to-many.png" alt=" Top: syntagm, paradigm, and their relation. Bottom: narrative, database, and their reversed relation. " id="img:one-to-many" style="width:30.0%" /><figcaption> Top: syntagm, paradigm, and their relation. Bottom: narrative, database, and their reversed relation. <span label="img:one-to-many"></span></figcaption></figure><p>In order to reveal the extent to which the presence of the database has a radical effect on narrative, however, Manovich reverses the semiotic theory of syntagm and paradigm that governed the first half of the 20th century <span class="citation" data-cites="Man01:The">(Manovich 2001, p. 231)</span>. Quoting Roland Barthes’ reading of Ferdinand de Saussure in , Manovich describes the paradigm as a relation subjected to substitution —because it depends on associations—, and the syntagm as a relation subjected to combination —because it is an instantiation of concrete elements. For example, from the entire set of words in a language (the paradigm) the speaker constructs sentences (the syntagm): the paradigm is implicit (absent) and the syntagm is explicit (present). The relation between these two planes (of the paradigmatic and the syntagmatic) is established by the dependence of the latter on the former: “the two planes are linked in such a way that the syntagm cannot ‘progress’ except by calling successively on new units taken from the associative plane [i.e., the paradigm]” <span class="citation" data-cites="Bar68:Ele">(Barthes et al. 1968, p. 59)</span>. Barthes gave several examples with different “systems,” one of which was the “food system,” which I will borrow in what follows. All the elements that compose a dish, for example, the “set of foodstuffs which have affinities or differences within which one chooses a dish in view of a certain meaning” comes to delimit the paradigm. However, the “sequence of dishes chosen during a meal,” or simply, what you are eating as you are eating it in a restaurant, comes to represent the syntagm <span class="citation" data-cites="Bar68:Ele">(Barthes et al. 1968, p. 63)</span>. However, when one looks at the restaurant’s ‘menu’, one can glance at both planes simultaneously: “[the menu] actualizes both planes: the horizontal reading of the entrées, for instance, corresponds to the system [i.e., paradigm], the vertical reading of the menu corresponds to the syntagm” <span class="citation" data-cites="Bar68:Ele">(Barthes et al. 1968, p. 63)</span>. A software menu, for instance, would come to represent both planes as well: the paradigm is the set of all possible actions the user might make within the specific context of the menu; the syntagm is the actual sequence of clicks that the user makes.</p><p>Barthes’ reading of Saussure is maintained in Manovich’s description of the database. On the one hand, narrative is the syntagm since, at least in Manovich’s rendition of narrative in the visual art world and the gaming world, it is the trajectory through the navigational space of a database. Furthermore, since this narrative is achieved by the interface, interface and narrative depend on each other: narrative thusly interlocks with the interface itself, and results on the conception of the interface-as-artwork. On the other hand, the database is the paradigm, since it represents the set of elements to be selected by the user. Materially, however, Manovich points to a reversal of these planes. Given the material presence of the database (i.e., the stored data), and given the hyperlinked quality of the user interface, the database becomes explicit (present) and narrative becomes implicit (absent, dematerialised).</p><p>For example, consider the case of the typical timeline-view of a video editor.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> Normally, the user creates a session and <em>imports</em> files to working memory, creating a database of files —video files, in this case. Once this database is in working memory, the user places on a timeline the videos, cutting, and processing them at will, until a result is desired, and an <em>export</em> or a <em>render</em> is made.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> The timeline where the user places the videos is a visualization of the set of links to the files; an editable graph that allows the user to locate in time the pointers to the elements on the database. This is what Manovich means by “a set of links,” because the user is not handling the files themselves —as would be the case with an analog video editor, where the user cuts and pastes the magnetic tape—, but the extremely abstract concept of memory pointers.</p><p>I consider this reversal to be valid, only on a certain quality of the relation itself, that is, as a shift from one-to-many to many-to-one (See Figure <a href="#img:one-to-many" data-reference-type="ref" data-reference="img:one-to-many">4.1</a>). The question of the materiality of the database and of the pointers depends on the materiality of data. Links or pointers have, for Manovich, a different (absent-like) status in relation to stored memory itself. This is because of a distinction between pointers and data on the basis of their use: pointers are of a different nature since they do not store data directly. Instead, they refer to the address in memory where a specific stored data begins. However, the mutual binary condition of pointers and data, and the fact that they are both stored in the same memory, reveal Manovich’s reversal to be grounded on an equivocation. Pointers are, however functionally different, another data type. This fact comes from the Von Neumann architecture on which computers are constructed (See <a href="#programming" data-reference-type="ref" data-reference="programming">4.2.2</a>). If one understands them as moving bodies, it follows that pointers are ‘lighter’ and travel much faster than other data types, which are ‘heavier’ and slower to move. However, data types are not moving bodies at all, and thinking of them as such interlocks us in a semiotic trap: accepting this reversal means accepting the materiality of data.</p><h3 id="convergence">Digital Convergence</h3><blockquote><p>A mere ‘byproduct’ of pleasure, entertainment is a hangover from the media epoch: a function that caters to our (<em>soon to become obsolescent</em>) need for imaginary materialization through technology [which, in turn,] serves as a diversion to keep us ignorant of the operative level at which information, and hence reality, is programmed. [emphasis added] <span class="citation" data-cites="Han02:Cin">(Hansen 2002, p. 59)</span></p></blockquote><p>I find in Manovich a silent allegiance to german media theorist Friedrich Kittler’s concept of digital convergence. Digital convergence entails that the bodily resonance of media becomes obsolete in the face of absolute digital information storage. Thusly, it turns the human into a “dependent variable” <span class="citation" data-cites="Han02:Cin">(Hansen 2002, p. 59)</span>. In the case of physical media, the human body was, for Kittler, directly shaped by media, and the limit of this ‘shaping’ was set by the bodily limits of perception. The body became a by-product of media. However, in the age of digital convergence, of an “absolute system of information” <span class="citation" data-cites="Han02:Cin">(Hansen 2002, p. 63)</span>, media remove this bodily limit of perception, making the human body a residual product. The body, then, becomes a residue of digital industries.</p><p>For example, the extents of this residual aspect of the human can be seen in writer Norman Klein’s considerations of the author <span class="citation" data-cites="Kle07:Wai">(Klein 2007)</span>. Following Manovich’s interface-as-artwork, Klein argues that since the reader gets immersed in data, she “evolves pleasantly into the author” <span class="citation" data-cites="Kle07:Wai">(Klein 2007, p. 93)</span>. Because the reader participates in the narrative, the result is a reconfigured concept of shared authorship. However, Klein continutes “instead of an ending, the reader imagines herself about to start writing” <span class="citation" data-cites="Kle07:Wai">(Klein 2007, p. 93)</span>. This surprising twist in Klein’s consideration adds another layer of complexity, namely, the categorical difference between ‘writing’ and ‘not-yet-writing.’ In Klein’s sense, narrative constitutes a promise of authority that equally blurs the roles of the writer and of the reader. Most importantly, this blurred authority is seen as a reflection of control and subordination of the human. In this view, the potentiality of authority arising from the trajectory through the database belongs neither to the reader nor to the writer: it is appropriated by the database. The roles of the reader and the writer fade into each other and vanish, allowing the database to be a dominant middle term. In other words, human agency is absorbed into a shadow, making the database the sole agent to which the human is subjected. In Klein’s own words, the human is a slave to data, and as a consequence the human is economically colonized and psychologically invaded by the evolving force of computers, information, or technology in general <span class="citation" data-cites="Kle07:Wai">(Klein 2007, pp. 86–88)</span>. Authority converges, too, in the age of digital convergence.</p><p>Media theorist Mark Poster defines technological determinism as the “anxiety at the possibility of [the human mind’s] diminution should these external [technological] objects rise up and threaten it” <span class="citation" data-cites="Pos11:Int">(Poster 2011 X)</span>. In other words, the fear or anxiety that the human is ultimately subjected to the power of technology. Understanding new media as digital convergence leads to reading the ‘new’ in new media as the ‘digital.’ In reaction to the anxieties that this convergence brings, and from an embodied approach where databases have an aesthetic agency in resonance with the human, in what follows I propose to shift the focus from narrative (interface) to performance (databasing), and to reconfigure the shadow of the database as a hybrid skin exposing the human and the non.</p><h3 id="bodiless_information">Bodiless Information</h3><blockquote><p>The disembodiment of information was not inevitable, any more than it is inevitable we continue to accept the idea that we are essentially informational patterns. <span class="citation" data-cites="Hay99:How">(Hayles 1999, p. 22)</span></p></blockquote><p>Media theorist N. Katherine Hayles <span class="citation" data-cites="Hay99:How">(Hayles 1999)</span> unearths the theoretical context of cybernetics, upon which the posthuman has been constructed throughout the 20th century. She identifies three waves of cybernetics, each governed by different concepts which helped build the undergirding structures of the technologically determined and disembodied literature in vogue in the 1990s.</p><p>The foundational wave cybernetics (from 1945 to 1960) was built, among other concepts, on two main theories: Jon von Neumann’s architecture of the digital computer (See <a href="#databasing" data-reference-type="ref" data-reference="databasing">4.2.1</a>) and Claude Shannon’s theory of information. As “a probability function with no dimensions, no materiality, and no necessary connection with meaning” <span class="citation" data-cites="Hay99:How">(Hayles 1999, p. 18)</span>, Shannon’s formal definition of information within communication systems highlighted pattern over randomness <span class="citation" data-cites="Hay99:How">(Hayles 1999, p. 33)</span>. Therefore, disembodied information became a signal to be encoded, decoded, and isolated from noise.</p><p>The word ‘cybernetics’ [steersman] thus synthesized three central aspects: information, communication, and control. Since the human was seen as an information processing entity, it was “essentially similar to intelligent machines” <span class="citation" data-cites="Hay99:How">(Hayles 1999, p. 7)</span>. Therefore, the conceptualization of the feedback loop as a flow of information came to put at ease notions of human subordination, thus arriving at the governing concept of first wave cybernetics: <em>homeostasis</em>. In this sense, the “ability of living organisms to maintain steady states when they are buffeted by fickle environments” <span class="citation" data-cites="Hay99:How">(Hayles 1999, p. 8)</span>, became a patch that simultaneously fixed computers as less-than-human, but also pointed to the anxiety of disembodied information that was growing underneath.</p><p>However, since the observer of the ‘feedback loop’ became part of the flow of the system, in the second wave (from 1960 to 1980), cybernetitians reconfigured homeostasis into <em>reflexivity</em>, that is, “the movement whereby that which has been used to generate a system [becomes] part of the system it generates” <span class="citation" data-cites="Hay99:How">(Hayles 1999, p. 8)</span>. This became also known as autopoiesis (i.e., self-generation), based on writings by Humberto Maturana and Francisco Varela. This second wave leaves the feedback loop behind, since it considers that “systems are informationally closed” <span class="citation" data-cites="Hay99:How">(Hayles 1999, p. 10)</span>. This means that elements in the system do not see beyond their limits, and the only relation to the ‘outside’ environment is by the concept of a <em>trigger</em>. In this sense, disembodied information was buried deeply into the organization of the system, and the system itself appeared in the form of a cyborg.</p><p>Shifting from triggers to artificial intelligence signaled the third wave of cybernetics (from 1980 onwards), whose central concept was <em>virtuality</em>. Development of cellular automata, genetic algorithms, and principally, emergence, led to the formation of the posthuman. However, in Hayles view, the underlying premise of this ‘posthuman’ is that the human can be articulated by means of intelligent machines <span class="citation" data-cites="Hay99:How">(Hayles 1999, pp. 17–18)</span>. In turn, reconfiguring the concepts of body, consciousness, and technology as inherent to (post-) human life, Hayles argues for the impossibility of artificial intelligence to serve as a proxy for the human. Hayles objective is, then, to dismantle cybernetics from its (relative) assumptions, questioning its major achievements over the years and thereby opening the field for new considerations of the body and its material environment within cybernetics, and by extension, of the body in new media:</p><blockquote><p>My dream is a version of the posthuman that embraces the possibilities of information technologies without being seduced by fantasies of unlimited power and disembodied immortality, that recognizes and celebrates finitude as a condition of human being, and that understands human life is embedded in a material world of great complexity, one on which we depend for our continued survival. <span class="citation" data-cites="Hay99:How">(Hayles 1999, p. 5)</span></p></blockquote><p>While her work is focused on the literary narratives that were built in parallel with cybernetics, she leaves incursions in new media theory for other media theorists. This is where Mark B. N. Hansen comes in.</p><h3 id="embodiment">Embodying Databasing</h3><p>As I describe above, Manovich arrives at this notion of the interface-as-artwork by opposing database and narrative on the semiotic grounds of the reversal of the paradigm and syntagm. In turn, media theorist Mark B. N. Hansen <span class="citation" data-cites="Han04:New">(Hansen 2004)</span> notes that the interface-as-artwork constitutes a disembodied “image-interface” to information in which the process of information itself (in-formation, giving form) is overlooked. Hansen locates the source of this disembodied conception in Manovich’s implicit —but nonetheless evident— premise of the overarching dominance of cinema in contemporary culture, which results in a “disturbing linearity [with] hints of technical determinism” <span class="citation" data-cites="Han04:New">(Hansen 2004, p. 36)</span>.</p><p>For example, Manovich argues that standardization processes originating from the Industrial Revolution have shaped how cinema is produced and received. Attuned to the perceptual limits of the body, the standardization of resolution can be seen (image dimensions, frames per second, and aspect ratio) and heard (audio bit depth, sampling rate, and number of channels). In this sense, the moviegoer and by extension, the listener became industrial by-products, determined by the massively produced electronic devices used for recording and playing. As I have described with Kittler’s technological determinism, the devices driven by industrial forces, therefore shaped the body, and as an extension, the aesthetics of cinema.</p><p>For Manovich, due to the internal role of the database, the logic of new media is no longer that of the factory but that of the interface. Through the interface to a database, the user is given access to multiplicities of narrative, and thusly, to endless information. The user is granted the power of the database, making in Manovich’s eyes the database an icon of postmodern art. In other words, on an aesthetic level, while mass-standardization and reproducibility of media —the “logic of the factory” <span class="citation" data-cites="Man01:The">(Manovich 2001, p. 30)</span>— shaped the form of cinema, post-industrial society and its logic of individual customization, shaped the database form. At the bodily level, cinema standardized perception of the passive body, and database individualizes experience. However, this individualized experience still constitutes a technological ‘shaping’ of the body, a shaping that is exploded into every user quietly sitting behind the screen.</p><p>In opposition to this passivity of the body, Hansen describes images as something that emerges out of the complex relationship between the body and some sort of sensory stimulus. In radical disagreement with Manovich, Hansen considers that the image has become a process which gives form to information, and that this process needs to be understood in terms of the body as a filtering and creative agent in its construction. Drawing from Henri Bergson’s theory of perception, and in resonance with cognitive science, Hansen defines the function of the body as a filtering apparatus. Under this conception, the body acts on and creates images by subtracting “from the universe of images” <span class="citation" data-cites="Han04:New">(Hansen 2004, p. 3)</span>. In other words, through this filtering activity, the body is empowered with “strongly creative capacities” <span class="citation" data-cites="Han04:New">(Hansen 2004, p. 4)</span>. Therefore, instead of being a passive node, the body actively in-forms data as information, and further: the databaser (database user) makes information out of data by precisely embodying the performative act that I call databasing.</p><h3 id="framing">Filtering And Framing</h3><blockquote><p>The activity in the receiver’s internal structure generates symbolic structures that serve to frame stimuli and thus to <em>in-form</em> information: this activity converts regularities in the flux of stimuli into <em>patterns</em> of information. <span class="citation" data-cites="Han02:Cin">(Hansen 2002, p. 76)</span></p></blockquote><p>The activity of framing, according to Hansen, must be differentiated from that of observation. In this way, “information remains meaningless in the absence of a (human) framer,” <span class="citation" data-cites="Han02:Cin">(Hansen 2002, p. 77)</span> and framing becomes a resonance of the (bodily) singularity of the receiver. Quoting MacKay’s <em>Information, Mechanism, Meaning</em> (1969), the meaning of a message</p><blockquote><p>…can be fully represented only in terms of the full basic-symbol complex defined by all the elementary responses evoked. These may include visceral responses and hormonal secretions and what have you…an organism probably includes in its elementary conceptual alphabet (its catalogue of basic symbols) all the elementary internal acts of response to the environment which have acquired a sufficiently high probabilistic status, and not merely those for which verbal projections have been found. <span class="citation" data-cites="Han02:Cin">(Hansen 2002, p. 78)</span></p></blockquote><p>It is with this conception of framing that Hansen describes precisely that information always requires a frame:</p><blockquote><p>…this framing function is ultimately correlated with the meaning-constituting and actualizing capacity of (human) embodiment…the digital image, precisely because it explodes the (cinematic) frame, can be said to expose the dependence of this frame (and all other media-supported or technically embodied frames) on the framing activity of the human organism. <span class="citation" data-cites="Han02:Cin">(Hansen 2002, pp. 89–90)</span></p></blockquote><p>Therefore, in the context of Kittler’s digital convergence, framing prevents the human from being rendered a dependent variable. To the contrary, the framing function of the human body is the possibility condition for the digital to become information. The frame, as Hansen describes, is the human body filtering images from the world, and creating a virtual image that gives form to data. The frame needs to happen as a relation, and thus, it is the temporal instantiation of a process.</p><h3 id="database_aesthetics">Database As Aesthetics</h3><p>The Internet is a place of unlimited access, it is a database in continuous and exponential growth, that reconfigures the grounds on which art has traditionally been built on. One of these grounds is the role of the author. The collaborative approach in the work of media artist Sharon Daniel <span class="citation" data-cites="Dan07:The">(Daniel 2007)</span>, is an example of a different kind of authorial reconfiguration. Daniel raises questions about authority and politics in collaborative art by means of a social model based on the concepts of emergence and <em>cellular automata</em>. Cellular automata are systems that reveal emergent (global) behavior from (local) rules. That is to say, each automaton changes states according to its surrounding neighborhood, resulting on an emergent behavior on the global level that precludes top-down behavior. Brought to the social plane, cellular automata result in an inverted hierarchic system: instead of a top-down authority, there exists an emergent, bottom-up behavior. Daniel thus removes her authorial role as artist granting participants a shared authority with the work itself at every stage. Differing from Klein’s blurring of the authorial roles, Sharon’s participants engage in performative actions that shape the outcome of the artwork in ways she could not anticipate. Therefore, authority is decentered, that is, it does not sediment itself in a single unity.</p><h3 id="generated">Databasing: Database As Performance</h3><blockquote><p>Data creators have to collect data and organize it, or create it from scratch. Texts need to be written, photographs need to be taken, video and audio need to be recorded. Or they need to be digitized from already existing media…Once digitized, the data has to be cleaned up, organized, and indexed. <span class="citation" data-cites="Man01:The">(Manovich 2001, p. 224)</span></p></blockquote><p>Despite Manovich’s technologically determined considerations of the database as form, he notes a fundamental aspect of the use of the database when he expresses that data need to be generated <span class="citation" data-cites="Man01:The">(Manovich 2001, p. 224)</span>. In this sense, he begins to describe the actions that need to be performed around data, or what I call databasing (See <a href="#databasing" data-reference-type="ref" data-reference="databasing">4.2.1</a>), which connotes the use of databases in terms of their performativity. He even goes further and proposes that this activity has become a “new cultural algorithm,” <span class="citation" data-cites="Man01:The">(Manovich 2001, p. 225)</span> which I reinterpret here as a single subroutine with one argument for input: the world (See Listing <a href="#lst:manovich" data-reference-type="ref" data-reference="lst:manovich">[lst:manovich]</a>). Following this line of thought, artist Victoria Vesna <span class="citation" data-cites="Ves07:See">(Vesna 2007)</span> argues that creating a memory bank is a means of testifying to our existence <span class="citation" data-cites="Ves07:See">(Vesna 2007, p. 25)</span>.</p><pre id="lst:manovich" data-caption="Manovich&#39;s cultural algorithm as a pseudocode routine with the world as argument (i.e, as input). The world is then mediatized, stored in some media (film, tape), then digitized into data, then structured as a database. This routine returns the database, which is, henceforth, the world re-presented as database." data-captionpos="b" label="lst:manovich"><code>function new_cultural_algorithm(world) 
{
    database = data = media = world
    return database
}</code></pre><p>While Manovich calls for an “info-aesthetics” <span class="citation" data-cites="Man01:The">(Manovich 2001, p. 217)</span>, as well as a poetics, and ethics of the database, neither Manovich nor the following generation of media artists and theorists could carry out an exhaustive account of an aesthetics of the database. Several authors continue to abide by Manovich’s claim that the aesthetics of the database, or the database as form, is a symptom of the uncritical use of database logic throughout the visual art world of the 1990s. It is in hindsight that his argument can be understood as grounded on the same disembodied constructions that prevent him from including human agency in his account.</p><h2 id="section:Databasing_And_The_History_Of_Databases">Databasing And The History Of Databases</h2><h3 id="databasing">Databasing: Structure, Time, Writing, And Architecture</h3><blockquote><p>The first step in working with a database is the collection and assembly of the data…. Sorting determines the sequence of presentation, while filtering gives rules for admission into the set presented [,] resulting in a database that is a subset of the “shot material” database. Editing is selecting from the database and sequencing the selections…. To go further: for a filmmaker the term “cutting,” as “editing,” loses its meaning, and “sorting,” “assembling,” and “mapping” become more apt metaphors for the activity of composition. <span class="citation" data-cites="Wei07:Oce">(Weinbren 2007, p. 71)</span></p></blockquote><p>Like Manovich, Weinbren finds a redefinition in filmmaking impulsed by the selection processes that the database calls for: data collection, generation, and assembly. Weinbren further breaks the selection process into sorting and filtering. With this new terminology, Weinbren makes a linguistic shift from ‘editing’ and ‘cutting,’ to ‘sorting,’ ‘assembling’ and ‘mapping.’ This linguistic shift is significant in the sense that it highlights the practice that is ‘under’ the filmmaker: databasing.</p><p>Databasing is a term I have chosen that best describes the practice of the database, that is, a term that includes the elements and actions of database practices, together with their temporality. The elements of databasing are the different data types and structures that build more complex database systems. The actions of databasing are, on the one hand, the type of operations that a database allows, and on the other, the bodily activity that occur before and after these operations. That is to say, since the operational level occurs below the perceptual threshold of the body, I consider the actions surrounding the immediacy of computations to be defining aspects of databasing.</p><h4 id="data-types-and-structures">Data types and structures</h4><p>Depending on the programming language, data types may or may not be part of a data structure, and they store different types of values such as <code>int, float, char</code>. These types are then interpreted in binary language by the compiler. Grouping these types into larger sets results in <code>array</code>s. For example, in the C programming language, programmers ‘declare’ variables first —e.g., <code>unsigned char age</code>— and then ‘initialize’ them with some data —e.g., <code>age=30</code>. A simple variable like one’s ‘age’ needs only one value, and given that the <code>unsigned char</code> data type only stores values from 0-255, it is safe to use in this case: no age can be negative, no human can live longer than 255 years.</p><p>A data structure is a set of data types kept generally in contiguous slots in memory space. It is built for fast allocation and retrieval. A very simple data structure can be thought of as, for example, a person’s name together with an age (See Listing <a href="#lst:person" data-reference-type="ref" data-reference="lst:person">[lst:person]</a>).</p><pre id="lst:person" data-caption="An example of a data structure in the programming language C. It is named \texttt{Person}, and it holds two variables: \texttt{age} and \texttt{name}, respectively a positive integer and a string of up to 128 characters." data-captionpos="b" label="lst:person"><code>typedef struct Person {
    unsigned char age;
    char name[128];
} Person;</code></pre><h4 id="temporality-of-databasing">Temporality of Databasing</h4><p>At this point it is important to refer to the higher or lower levels of computer software. A software that is ‘higher’ means that its simplest operations are composed of multiple smaller operations. The user can thus ‘forget’ about certain complexities that come from low-level programs, such as memory management. In this sense, low-level programs operate ‘closer’ to hardware, and programmers need to work at a more granular level. While the above data structure contains low-level features such as setting the size of the name array, it releases the programmer from thinking binary conversion. This means that unless you are changing values directly on the memory card (which is unthinkable), there will most likely be an underpinning software layer.</p><p>The speed of regular house computers is so fast that high-level operations happen below the perceptual level (generally below 1-2 milliseconds), hence, for example, the capability for real-time audio processing at high quality sample rates. Therefore, the temporality of activity before and after potentially very large computations feels almost immediate. This means that the body continues almost as if nothing had happened besides a click, or besides the pressing of a key. The immediacy of computation is a feature, certainly, for arriving at extremely fast operations in no time (or zero-time). It is what feels like ‘magic’ around computers: ask a computer to count to a 1000, and it already has….</p><p>However, it may become a bug if we consider the computer as a tool to understand the world. As Manovich claimed, the world understood with computers is not only one that is presented in binary terms, it is one constructed upon a specific set of data structures with their set of algorithmic rules. The better and more efficient the data structure is, the better and faster the algorithm. In this light, it can be argued that software development is essentially data structure development. At every software release, the software becomes more efficient, using less or more restricted memory space, etc., affecting the scope of its functionality as well as the speed at which it runs. Glancing at the evolution of software in terms of data structure efficiency, therefore, is glancing at a constantly accelerating stream of bits. Because it is immediate, software is incorporated immediately, thus narrowing the temporal window for framing.</p><p>This is why the temporality of databasing is context-dependent. As Hansen pointed out, image creation, or world creation, is not necessarily in contact with the reality that surrounds the body (or the reality of the body), but it is a result of the embodiment of a virtuality that is inherent to our senses. The world is a virtuality that is constructed with our senses and our body. The world can only appear if it appears to the body. Data structures, therefore, are very efficient storage devices that have no relation to worlds in themselves, but that are the condition for the possibility of world creating with computers. In this way, the programmer feeds into the computer a notion of world that is then returned by the computer’s performance. In each data structure there is a result of a feedback network. One one hand, this network refers to the history of software development, in the sense that each software release is a instance of the much larger event that is software in general. On the other, the network links this history with the practice at hand for which the software is being designed. The sound of a computer music oscillator, for example, even if it were programmed today from scratch, would have embedded histories of computer software design, computer music history, etc.</p><p>What is important to note here, is that these interrelations of what is <em>already there</em> in software development can be thought of as resonances colliding their way into stability; a stability that emerges not only as a ‘stable release’ of the code, but also as the condensed multiplicity of worlds that is displaced into a software package. Therefore, far from being an ontology of the world, data structures are world-making and world-revealing devices that engage with our own capacity for virtuality, and thus they are nodes in our world-making networks.</p><h4 id="databasing-and-writing">Databasing and Writing</h4><p>As with other new media, the terminology used to describe computer memory is often borrowed from earlier media practices like printed text: reading, writing, and erasing. Computer memory thus shares with writing the property of hypomnesis, that is, of displacing the role of human memory with an external non-human device. In the case of the computer memory however, the scale of this displacement is extremely large, both in terms of the amounts of data that can be stored and the speed with which it can be stored. For example, the 40-bit long 4000 numbers that Von Neumann was aiming at for their memory ‘organ’ —which was more than plenty for the computational purposes required at the time— represents around 16 Kilobytes, something which today might seem absurd in comparison to current computer storage capabilities that can be found in the case of cloud computing. In light of this fact, we might ask ourselves how is human work transformed through interaction with these massive external memories? Database practice has direct effects on temporality and on memory. Therefore, when designing computer software for art, the way in which data is structured, together with the speed and design of data flow, has significant effects on the temporality of art altogether as a practice.</p><p>I have proposed that memory and its storing of instructions and information what enables the computer as such. The simplicity of this synthesis of data and command in Von Neumann’s architecture, led to its implementation in not only the computer for which he had intended, also the regular computer as we know it today. Without this architecture, computers would only be able to perform very simple arithmetic operations (like pocket calculators). That is to say, without the computer’s ability to store data (the memory organ), the partial differential equations that Von Neumann was aiming at solving would not have been possible. In these equations, the next value of the solution depends on the present value. Therefore, when iterating through every step of the solution, the function in charge of solving the equation needs to access the present value, change it, output the next value, and finally update the present value with the outputted result (See <a href="#lst:neumann" data-reference-type="ref" data-reference="lst:neumann">[lst:neumann]</a>). Therefore, in order to provide such solutions, Neumann proposed that: “not only must the memory have sufficient room to store these intermediary data but there must be provision whereby these data can later be removed” <span class="citation" data-cites="von46:Pre">(von Neumann &amp; Burks 1946, p. 3)</span>.</p><pre id="lst:neumann" data-caption="Pseudocode showing a routine whose next value depends on the present value." data-captionpos="b" label="lst:neumann"><code>present = 0
next = 0
iteration {
    output = next = function() = present
    present = next
}</code></pre><h4 id="the-von-neumann-architecture">The Von Neumann Architecture</h4><blockquote><p>Inasmuch as the completed device will be a general-purpose computing machine it should contain certain main organs relating to arithmetic, memory-storage, control and connection with the human operator. It is intended that the machine be fully automatic in character, i.e. independent of the human operator after the computation starts <span class="citation" data-cites="von46:Pre">(von Neumann &amp; Burks 1946, p. 1)</span>.</p></blockquote><p>Data structures are the turning point of the history of the database. Their appearance enabled the performance of automated algorithms. Within the history of computer technology, data structures begin to appear since Jon Von Neumann’s designs of the computer architecture <span class="citation" data-cites="von46:Pre">(von Neumann &amp; Burks 1946)</span>. Von Neumann and his team implemented Alan Turing’s original concept for a general-purpose computing machine. Of the “certain main organs,” it is memory-storage what enables the computer’s architecture as we know it today. On one hand, the storage unit of the computer allows data to be written and erased in different locations and times. On the other, the stored data can be not only values to be used during computation, but also includes the algorithmia itself, that is, the commands —functions, operations, routines, etc.— which are used to access and process data for computation. Thus, the interaction of data and command is what defines data flow inside the computer.</p><p>Consider, for example, how curator Christiane Paul describes the database as a “computerized record-keeping system”, that is, “essentially a structured collection of data that stands in the tradition of “data containers” such as a book, a library, an archive” <span class="citation" data-cites="Pau07:The">(Paul 2007, p. 95)</span>. However, when Paul suggests that databases are simply an instance of data collection this only points to the passivity of the container, and not to the potential that it has. An good analogy would thus be a book with the capacity to read itself, if reading were going through every letter in an orderly fashion. A database can also be understood as a library with no need for librarians because all queries are immediate; or, an archive without archeion. These considerations will be developed in the next chapter. While the more general practices of collecting and classifying data are part of the practice of databasing, on some level of the computer architecture, databasing comprises data flow within the Von Neumann architecture. This fact marks a distinction that is better seen in relation to networks. Extending computers via networks like the Internet makes databasing a global performance that resonates, grows, and changes with every user. This is why I propose that databasing reconfigures the passivity of data containers such as books, libraries, and archives, with a powerful agency that resonates aesthetically.</p><p>In order to understand how databases have changed the way we think of earlier types of containers, we need to revise the differences between database models in time. By doing this, I plan to reconfigure the notion of database system. In general, database systems have been used in businesses, namely for administration and transaction. However, narrowing database systems this way raises the similarities or differences between systems to the level of the interface. I propose to delve into the structures of the models to find how the computer itself can be thought of as a database tree and user interaction —as well as programming— as database performance. The main purpose of the following account is to understand how computer-based sound practices have participated as a particularly resonant branch of the database tree.</p><h3 id="programming">A Database Tree</h3><p>The common use of the word ‘database’ within computer science came around the 1960s, when computers became available to companies throughout the United States of America. For the purpose of data processing, software developers began designing DBMS , which are still used in great demand by multiple contemporary companies. The computer’s capability for data processing and storage is inherent in the constitution of database systems. In fields such as CAC , working with computers meant being part of a system. The human operator is has been regarded, for example, as a co-operator <span class="citation" data-cites="Mat63:The">(Mathews 1963)</span>. A further approach understands humans operating with computers as another component of complex systems <span class="citation" data-cites="Vag01:Som">(Vaggione 2001)</span>. In this section, I describe the different levels of database systems as a tree (See Figure <a href="#img:dbtree" data-reference-type="ref" data-reference="img:dbtree">4.2</a>), starting from basic data structures to more elaborate database systems, and then present a brief history of how databases were designed.</p><figure><img src="../img/dbtree.jpg" alt=" A very simple sketch of a tree representing the database tree of computer evolution " id="img:dbtree" style="width:40.0%" /><figcaption> A very simple sketch of a tree representing the database tree of computer evolution <span label="img:dbtree"></span></figcaption></figure><h5 id="ground">Ground</h5><p>The tree is built on different interpretations of the Von Neumann architecture. That is to say, while this architecture went through several optimizations over the years, its three central aspects remained. Therefore, despite the fact that different industry standards for hardware construction resulted in different kinds of operating systems, the core elements of the architecture remained the same: memory (for data and program/code), central processing unit, and input/output interfaces.</p><h5 id="roots">Roots</h5><p>The below-ground level is accessed through machine and assembly code, which constitutes the core of low-level programming languages and are, to a certain extent, humanly un-readable: the world of bits. Above the ground, readability by humans is the main feature.</p><h5 id="portability">Macros</h5><p>The database tree metaphor relates to the concept of portability. The database tree only takes the form of a tree once it is instantiated as a software and it is run. That is to say, the database tree unfolds every time it is opened, and in this unfolding it emerges the possibility of dynamically adapting to different grounds. This is what is known in the programming world as defining conditions or macros. With these definitions, their programs can compile with different compilers, across a variety of hardwares and operating systems. Therefore, these database trees have as their main feature the capacity to unfold their roots in different directions upon demand.</p><h5 id="trunk">Trunk</h5><p>The trunk of the tree is composed of data types and structures that provide flow between stored (underground) data and the above-ground components. Programming languages handle data types differently, but in essence, data types and structures are usually built in layers going from the lowest (close to roots) to highest levels.</p><h5 id="branches">Branches</h5><p>These language layers, after they reach a certain level of complexity, begin to form boughs or limbs that, while being separated from each other, are linked to the same trunk and roots. I consider branches to be programs with text-based interfaces such as Bash, C, C++, python, Java, etc. Their feature is their generic functionality.</p><h5 id="twigs">Twigs</h5><p>More complex programs built on top of branches, such as Pure Data, Supercollider, R, octave, Processing, OpenFrameworks etc., are dedicated for a narrower scope of tasks. Their feature is their level of specialization for the task at hand: sound synthesis, statistics, visuals, etc. They might be more application-specific. In general, these programs are commonly considered layers on top of other languages, libraries, or software frameworks.</p><h5 id="leaves">Leaves</h5><p>User interfaces (or GUIs) are the leaves of the tree. I relate the photosynthetic quality of leaves with user input/output interaction. Despite their simple, user-friendly appearance, software leaves are highly complex systems such as multimedia editors (Adobe Creative Suite or Microsoft Office), Internet browsers, mobile apps, etc. A particular kind of leave is the DBMS , generally used in businesses for data processing and editing, for example: MYSQL , POSTGRESQL , NOSQL , COUCHDB and MONGODB .</p><h5 id="networks">Networks</h5><p>An important feature of database trees is their network capabilities. Networks can be established by connecting leaves, branches, or roots with each other, both within the same tree and with other trees. For example, software can establish a network between its graphical interface and its core program —as is the case with Pure Data, for example. Another example would be the way in which DBMS s interact with data: the MYSQL database model allows the user to load a data set in working memory, and establishes a connection between the opened memory and the input/output mechanisms. Networks of trees are data streams running by way of an IP and a client-server type of relation. Cloud storage services such as Google Drive, ICloud, OneDrive, and Dropbox are used as a networked way to store and share data. One tree can serve as data storage and processing repository, and other client trees can connect to the server tree and request data or processing of data from it. This is the essence of the internet and all the communication services that it enables, such as email services, social networking sites, and multi-user collaboration platforms like Github. This allows software like Pure Data and MySQL to have their respective core program and data sets in one computer, and their interfaces on a different one.</p><h5 id="clouds">Clouds</h5><p>Combining networked databases with computer clusters forms what is known as cloud computing. For example, most universities provide clusters for data processing —e.g., NYU’s Prince cluster— that can be accessed from remote locations. These clusters are massive server architectures made out of multiple processing and memory units joined together. These architectures began developing in the 1990s, coining terms like data mining <span class="citation" data-cites="DBLP:journals/corr/abs-1109-1145">(Kamde &amp; Algur 2011)</span>, data warehouses, data repositories <span class="citation" data-cites="ilprints81">(Silberschatz et al. 1995)</span>.</p><h3 id="models">The Realm Of Data Structures</h3><p>Data structures are the building blocks upon which the entire database model is designed. A data structure is a way to organize data so that a set of element operations are possible, such as <code>ADD</code>, <code>REMOVE</code>, <code>GET</code>, <code>SET</code>, <code>FIND</code>, etc. Data structures can be thought of in two ways: either implemented or as interfaces, what is also known as <em>abstract data types</em>:</p><blockquote><p>An interface tells us nothing about how the data structure implements these operations; it only provides a list of supported operations along with specifications about what types of arguments each operation accepts and the value returned by each operation. <span class="citation" data-cites="ods-cpp">(Morin 2019, p. 18)</span></p></blockquote><p>In other words, the abstract data type represents the idea of the structure. When abstract data types are implemented in code, the speed and efficiency of the data structure can be physically evaluated. An implementation of this sort includes “the internal representation of the data structure as well as the definitions of the algorithms that implement the operations supported by the data structure” <span class="citation" data-cites="ods-cpp">(Morin 2019, p. 18)</span>. Because of the consequences that design has on computational performance, data structures have constituted a focal research point in the database and computer science communities.</p><h5 id="array-data-structure">Array data structure</h5><p>Arrays constitute one of the oldest and most basic data structures. They are contiguously stored, same-type data elements referenced to by indices. Most programming languages have implemented arrays. Most realtime software loads sound files or images to working memory as an array (or a buffer) of contiguous samples or pixels. Arrays are use less resources when reading than when writing, since accessing their elements is achieved by pointers, but editing demands copying large portions of the array back and forth.</p><h5 id="computer:linked">Linked Lists</h5><p>One important technical shift in the use of data structures came with the concept of linked lists. A linked list is collection of data (usually a symbol table), with pointers to the ‘previous’ and/or ‘next’ item on the list. They are built to maintain an ordered sequence of elements. This functionality was only available after the FORTRAN ’77 programming language (1977) and later it became integrated in the C programming language <span class="citation" data-cites="kernighan_c_1978">(Kernighan 1978)</span>. They differ from arrays since they can hold multiple data types (including arrays and other data structures), and they are accessed by traversing the list using the ‘previous’ and ‘next’ pointers. In the programs developed during the SSSP and CAMP years, linked lists were used in the (then very recent) C programming language. <span class="citation" data-cites="icmc/bbp2372.1985.040">Ames (1985)</span> <span class="citation" data-cites="icmc/bbp2372.1985.040">(Ames 1985)</span> also used linked lists to represent melodies within an automated composition system. <span class="citation" data-cites="Row92:Int">Rowe (1992)</span> used linked lists in his <code>Event</code> data structures of his interactive music system <em>Cypher</em> (See <a href="#computer:cypher" data-reference-type="ref" data-reference="computer:cypher">4.3.3.3.7</a>) <span class="citation" data-cites="Row92:Int">(Rowe 1992)</span>.</p><h5 id="computer:audacity">Sequences</h5><p><span class="citation" data-cites="crowley98">Crowley (1998)</span> claims, however, that neither linked lists nor arrays are suitable for large text sequences, since linked lists take up too much memory, and arrays are slow because they requires too much data movement. Nonetheless, he argues, “they provide useful base cases on which to build more complex sequence data structures” <span class="citation" data-cites="crowley98">(Crowley 1998)</span>. In fact, data structures are generally built from arrays and linked lists. For example, in designing <em>Audacity</em>, Mazzoni and Dannenberg <span class="citation" data-cites="icmc/bbp2372.2001.051">(Mazzoni &amp; Dannenberg 2001)</span> implemented the concept of sequences, into a set of small arrays whose pointers were traversed in a linked list. Large audio files were loaded and edited at very fast processing times.</p><h3 id="descriptions">A Brief History Of Database Models</h3><p>I propose now to extend the concept of <em>abstract data types</em> to the concept of database <em>models</em>. Database models are the realm of data structures. These models, to be described below, constitute the abstract ways in which data can be organized within a database system. DBMS s, in turn, are a specific type of software aimed at organizations, website design, server architectures, company management, among other uses in the business sector. Since an analysis of these systems falls outside the scope of this study, I provide a glimpse of the structure of the models without entering in their implementation. Figure <a href="#tab:dbmodels" data-reference-type="ref" data-reference="tab:dbmodels">[tab:dbmodels]</a> shows a development timeline that serves as a context for the appearance of these models. Their emergence over the years goes hand in hand with hardware and programming language development. Further, several implementations of these models depended on specific language development such as DDL for structural specification of data, and a DML for accessing and updating data <span class="citation" data-cites="DBLP:books/aw/AbiteboulHV95">(Abiteboul et al. 1995, p. 4)</span>.</p><p>Angles and Gutierrez name the three most important aspects a database model should address: “a set of data structure types, a set of operators or inference rules, and a set of integrity rules” <span class="citation" data-cites="2008:graph/anglesgutierrez/survey">(Angles &amp; Gutierrez 2008, p. 2)</span>. Operators can be understood as the set of routines that constitute the query language and data manipulation. Integrity rules can be understood as data constraints preventing redundancy or inconsistencies, and checking routines preventing false queries. In a similar way, for Serge Abiteboul a database model “provides the means for specifying particular data structures, for constraining the data sets associated with these structures, and for manipulating the data” <span class="citation" data-cites="DBLP:books/aw/AbiteboulHV95">(Abiteboul et al. 1995, p. 28)</span>. However, data manipulation (operators) and constraints (integrity) are built around the data structure, which is why, Angles and Gutierrez continue, “several proposals for [database] models only define the data structures, sometimes omitting operators and/or integrity rules” <span class="citation" data-cites="2008:graph/anglesgutierrez/survey">(Angles &amp; Gutierrez 2008, p. 2)</span>.</p><p>In essence, all DBMS s share the same function: provide access to a database. This access, however, is restricted by the imperatives of the model. Database models have been thought of as collections of conceptual tools to represent real-world entities and their relationships <span class="citation" data-cites="2008:graph/anglesgutierrez/survey">(Angles &amp; Gutierrez 2008, p. 1)</span>. In this sense, the models are fit to achieve a level of specificity and efficiency that is integrated with the notions of economic success. That is to say, the quality of database access has a direct influence on the operational level of businesses. For example, if the database system in charge of airline reservations fails to update an entry or does not restrict duplicates, this might result in either empty airplanes or double-booking, an economic loss that might result in a company going out of business. In relation to data structure design within CAAC software, Christopher Ariza <span class="citation" data-cites="Ari05:Ano">(Ariza 2005a)</span> claims that design choices “determines the interaction of software components and the nature of internal system processing” <span class="citation" data-cites="Ari05:Ano">(Ariza 2005a, p. 18)</span>. Luckily, a failed database access in music might perhaps come as a minimal performative ‘bump’ that can be otherwise forgotten. However, it is imperative that these models are analyzed because of the continuum between data structures and database models, and because of the internal relations that resonate from these structures to the implementations of computer music software. Therefore, to a certain extent, database models and computer music software share the resonance of data structures, and belong to their realm.</p><h4 id="model:hierarchical">Hierarchical</h4><figure><img src="../img/hierarchical.png" alt="Diagram of the hierarchical model" id="img:hierarchical" style="width:20.0%" /><figcaption>Diagram of the hierarchical model<span label="img:hierarchical"></span></figcaption></figure><p>The hierarchical model was developed at IBM during the early 1960s, in conjunction with other American manufacturing conglomerates for NASA ’s Project Apollo, resulting in IMS <span class="citation" data-cites="2000-database-ims">(Long et al. 2000)</span>. The hierarchical model is closely linked to the architecture of data within a computer. Therefore, it interprets records as collections of single-value fields that are interconnected by way of paths. Records can have type definitions, which determine the fields it contains. As a rule of this structure, a child record can be linked upwards to only one parent record and downwards to many child records. The structure stems from a single ‘root’ record, which is the initial parent-less record that begins any traversing of the structure for retrieval.</p><p>This model is useful for nesting structures such as directory trees and path structures in most operating systems today. Their use within database systems was eclipsed by the relational model during the 1980s, but it resurfaced through relational-type implementations of hierarchical models, and with the appearance of semi-structured model in the late 1990s (See <a href="#model:semistructured" data-reference-type="ref" data-reference="model:semistructured">4.2.4.7</a>).</p><h4 id="model:network">Network</h4><figure><img src="../img/network.png" alt="Diagram of the network model" id="img:network" style="width:20.0%" /><figcaption>Diagram of the network model<span label="img:network"></span></figcaption></figure><p>Invented by Charles Bachman in 1959 and published at the CODASYL , the network model is a way of representing objects as nodes in a graph whose relationships can be represented as arcs. The programming language COBOL was designed for the implementation of network databases. The nodes in these networks are known as ‘records,’ and their relationships form ‘sets’ that have one-to-many relationships in between records, that is, one ‘owner’ and multiple ‘members.’ The main feature of a network model is that these relationships are not bounded to any hierarchical or lattice-like structures, providing a more natural way of record relation. Structurally, each node has an identity called a database ‘key’ which corresponds to the pointer to the physical address of the record on disk. This is how the network model maintains a close relationship between data structures and traversing: keys can thus be used to implement linked lists and trees for record navigation, allowing for very fast retrieval speeds due to the interlocking of the physical implementation and the internal logic of node identity and access.</p><h5 id="navigational-paradigm">Navigational Paradigm</h5><p>The advent of disk-based database systems, in contrast to magnetic tape or punched card systems, enabled a different way of thinking database navigation. Working for General Electric’s IDS , Bachman <span class="citation" data-cites="Bachman:1973:PN:355611.362534">(Bachman 1973)</span> later conceptualized and implemented a navigational paradigm within the networked model. Abandoning the “memory-centered view” of database system development, Bachman called for programmers “to accept the challenge and opportunity of navigation within an <em>n</em>-dimensional data space” <span class="citation" data-cites="Bachman:1973:PN:355611.362534">(Bachman 1973, p. 657)</span>. Therefore, he proposed data records and attributes as <em>n</em>-dimensional space. This means that a database can be traversed not only by accessing the first element and then moving sequentially to the ‘next’ record. Secondary data keys could be made into sets for navigation starting from any of its members. In other words, given a database with records and attributes, all attributes can become a new dimension thus making retrieval times much more efficient. Navigating through a database within this paradigm is achieved by following record relationships instead of record order in physical storage. Therefore, with the navigational paradigm, a new level of abstraction was thus given to database management systems, resulting in better and more efficient database retrieval.</p><p>The navigational paradigm was implemented not only in network model, also in the hierarchical model, and it is still used today. Like I described with hierarchical databases, the navigational paradigm was eclipsed by the relational model, but after the 1990s, they re-emerged with non-relational databases. For example, since DOM websites contains a hierarchicalstructure, they can be accessed using this navigational paradigm.</p><h4 id="model:relational">Relational</h4><figure><img src="../img/relational.png" alt="Diagram of the relational model" id="img:relational" style="width:20.0%" /><figcaption>Diagram of the relational model<span label="img:relational"></span></figcaption></figure><p>The relational model was first designed by E. F. Codd <span class="citation" data-cites="Codd:1970:RMD:362384.362685 Codd72relationalcompleteness">(Codd 1970, 1972)</span>. Its main feature is the table-like organization of data, together with a separation between the physical level of data storage and the query language. These features allowed, on the one hand simple data visualizations, and on the other highly complex data manipulations by way of an algebra-based query language. Data is placed into uniquely identified rows (records) which can have multiple columns (attributes). A table thus becomes a relation. The main difference between the navigational and the relational paradigms, can be seen in the way users formulate queries. In the former, users specify which steps need to be made in order to arrive at a certain record. In the latter, users specify what needs to be found in terms of an algebraic expression. The query language developed for relational databases is SQL . In recent years, object relational database have emerged such as SQLOBJECT , intepreting relations as classes in the object-oriented programming paradigm.</p><h4 id="model:nonrelational">Non-Relational</h4><p>This is a more general type of database models where the internal structure is different from the tabular kind that the relational model presents (See <a href="#model:relational" data-reference-type="ref" data-reference="model:relational">4.2.4.3</a>), and they are generally referred to as NOSQL . Within this class or group of non-relational models, some examples can be: Key-Value databases, which are centered on associative arrays (hash tables) such as python dictionaries; semi-structured databases (See <a href="#model:semistructured" data-reference-type="ref" data-reference="model:semistructured">4.2.4.7</a>), also called document-oriented databases such as XML , YAML , and JSON ; graph databases and mixed graph models such as the way in which the World Wide Web convention (W3C) structures websites, with a URL as a ‘name’ and their content as a ‘graph’ (See <a href="#model:graph" data-reference-type="ref" data-reference="model:graph">4.2.4.5</a>); object databases (See <a href="#model:object" data-reference-type="ref" data-reference="model:object">4.2.4.6</a>); and database systems using combinations of different models.</p><h4 id="model:graph">Graph</h4><p>In their survey of graph-modelled databases, Angles and Gutierrez <span class="citation" data-cites="2008:graph/anglesgutierrez/survey">(Angles &amp; Gutierrez 2008)</span> date the beginning of graph databases to the early 1980s, in conjunction with object-oriented databases. This model interprets records as ‘nodes’ and connections as ‘edges.’ Therefore, visualizations as graphs, as well as operations stemming from the mathematical theory of graphs, are features of the model. The visual programming paradigm takes advantage of graph representations of their object-oriented programming structure. In this sense, computer music software like OpenMusic, PWGL, Pure Data, MAX/MSP , Kyma, among others, present their objects as a directed graph on a canvas.</p><h4 id="model:object">Object</h4><figure><img src="../img/object.png" alt="Diagram of the object model" id="img:object" style="width:20.0%" /><figcaption>Diagram of the object model<span label="img:object"></span></figcaption></figure><p>These databases combine the object-oriented programming paradigm with database concepts. On one side, each record is treated as an object, with capability to store variables (attributes) and functions (methods) that the object can perform. This way, when an object is instantiated in the form of a record, all the attributes and methods become available to itself and to other objects, provided these are setup in a ‘public’ way, and so different interactions can occur throughout the database. Some programming languages are directly object-oriented, from which certain databases were created (See <a href="#tab:dbmodels" data-reference-type="ref" data-reference="tab:dbmodels">[tab:dbmodels]</a>). From 2004, the open source community has been developing open source object databases that are easily accessible in several object-oriented languages.</p><h4 id="model:semistructured">Semi-structured</h4><figure><img src="../img/semistructured.png" alt="Diagram of the semi-structured model" id="img:semistructured" style="width:30.0%" /><figcaption>Diagram of the semi-structured model<span label="img:semistructured"></span></figcaption></figure><blockquote><p>We call here semi-structured data this data that is (from a particular viewpoint) neither raw data nor strictly typed, i.e., not table-oriented as in a relational model or sorted-graph as in object databases. <span class="citation" data-cites="Abiteboul:semistructured:96">(Abiteboul 1996)</span></p></blockquote><p>Abiteboul <span class="citation" data-cites="Abiteboul:semistructured:96">(Abiteboul 1996)</span> comments that given the amount of data that has grown in non-standard structures, a new way of accessing data has emerged. Furthermore, access to data can take place from a variety of different platforms such as browsers, query languages, application-specific interfaces, etc., making the process of obtaining useful information increasingly more difficult since these platforms call for specifically tailored methods and languages. Abiteboul claims, therefore, that first there is a need to extract the non-standard structure from the data, so that it can be traversed afterwards. These databases constitute the semi-structured model. Some examples of this model include XML databases, JSON files, YAML files, among others <span class="citation" data-cites="Buneman:1997:SD:263661.263675">(Buneman 1997)</span>. A well known database of this kind is the IMDB .</p><h4 id="model:puredata">Pure Data as Database System</h4><p>While not technically a database system, Pure Data comprises (internally) a limited amount of data structures that are, nonetheless, different between each other. These structures are, in turn, arrays, linked lists, and symbol tables built as a layer of the C programming language. In terms of database models, Pure Data is mostly hierarchical when it comes to canvases. The windowing system that has a ‘root’, and multiple ‘subcanvases’ that can be (almost) infinitely nested. These canvases, while being hierarchic, are traversed as in the navigational model, either for a specific keyword (a query from the ‘find’ menu), or, most importantly, for signal processing. Besides this hierarchical structure, another important aspect of the GUI level is that it displays visually connected boxes with cords. Therefore, it is quite literally a directed graph where objects are nodes and edges are assigned to a node’s inlets and outlets. The <code>.pd</code> file format, written in an application-specific language, is structured in such a way that elements on a graph are listed from top to bottom until the end of the list is reached. After this, the connections between objects inlets and outlets are subsequently listed. This graph model, however, comes out of Pure Data’s internal design as an object-oriented program. Its core functionality depends on class instantiation. Every internal and external is a class made of C data structures with its own methods, that can be loaded in memory at run time and instantiated any time afterwards. Furthermore, Pure Data is already a networked environment, since in order to effectively ‘patch’ using the graphical interface, a network is established between Pure Data instance and the Tcl/Tk graphical interface. Added to this, the network capacity that Pure Data comes with, that is, the <code>pdsend</code> and <code>pdreceive</code> objects that support creation of endless TCP/IP connection sockets, literally exploding the concept of a hierarchical patch into the non-hierarchic, networked model.</p><p>A common warning that Pure Data developers have to announce is that if you open a listening port and share your port number, anyone can connect to that port, without any restriction whatsoever.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> This internet connectivity exposes users to one another in very direct ways, allowing system modifications that if used maliciously could potentially have detrimental effects. It can be argued that this loophole is a reflection of the internal openness of the source code itself. This openness enables programmers to create and load externals, but also to change the program itself. While changing something from the source code can be detrimental for the overall program, in being open, Pure Data prevents any definition to reach completion. An small gap, therefore, is left opened exposing users to the source, and to each other in a networked community.</p><p>Pure Data is just one example of many open and non-open source computer music softwares that expose such a plethora of database models for the user. Database models are what makes the realm of data structures reach any databaser: what touches any computer user that has ever pressed a key.</p><table><caption>Database model development timeline with examples.<span label="tab:dbmodels"></span></caption><thead><tr class="header"><th style="text-align: left;">Year  </th><th style="text-align: left;">Model  </th><th style="text-align: left;">Designer  </th><th style="text-align: left;">Implementation</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">1959  </td><td style="text-align: left;">Hierarchical  </td><td style="text-align: left;">IBM  </td><td style="text-align: left;">IMS</td></tr><tr class="even"><td style="text-align: left;">1960s  </td><td style="text-align: left;">Network; Navigational  </td><td style="text-align: left;">CODASYL ; General Electric; HP ; UNISYS  </td><td style="text-align: left;">IDS ; IDMS ; RDM ; TURBOIMAGE ;</td></tr><tr class="odd"><td style="text-align: left;">1960s</td><td style="text-align: left;"> Deductive</td><td style="text-align: left;"> J. Minker; L. Kuhns</td><td style="text-align: left;"></td></tr><tr class="even"><td style="text-align: left;">1960s  </td><td style="text-align: left;">Non-relational  </td><td style="text-align: left;">APACHE ; SPARSITY ;  </td><td style="text-align: left;">MONGODB ; REDIS ; CASSANDRA ; SPARKSEE ; NOSQL</td></tr><tr class="odd"><td style="text-align: left;">1970s  </td><td style="text-align: left;">Relational  </td><td style="text-align: left;">E.F. Codd; P. Chen (1976)  </td><td style="text-align: left;">MYSQL ; ORACLE ; POSTGRESQL ; ACCESS ; SQLITE</td></tr><tr class="even"><td style="text-align: left;">1975  </td><td style="text-align: left;">Semantic model  </td><td style="text-align: left;">U.S. Air force; J.H. ter Bekke (1991)  </td><td style="text-align: left;">XPLAIN</td></tr><tr class="odd"><td style="text-align: left;">1980  </td><td style="text-align: left;">Graph  </td><td style="text-align: left;">ORACLE ; APACHE ; Amazon  </td><td style="text-align: left;">NEO4J ; Oracle Spatial and Graph; ARANGODB ; Amazon Neptune; BOOST ; NETWORKX</td></tr><tr class="even"><td style="text-align: left;">1985  </td><td style="text-align: left;">Object  </td><td style="text-align: left;">Brown University; Texas Instruments; Bell Labs; APACHE  </td><td style="text-align: left;">GemStone ( SMALLTALK ); Gbase ( LISP ); COUCHDB ; SQLOBJECT</td></tr><tr class="odd"><td style="text-align: left;">1990s  </td><td style="text-align: left;">Semi-Structured  </td><td style="text-align: left;">W3C  </td><td style="text-align: left;">XML ; SEDNA</td></tr><tr class="even"><td style="text-align: left;">1995  </td><td style="text-align: left;">In-Memory  </td><td style="text-align: left;">Oracle; Sybase; Exasol AG; VMWare  </td><td style="text-align: left;">TimesTen; ASE ;</td></tr></tbody></table><h2 id="section:Databasing_Sound:_Applications_Of_Databases_In_Sound">Databasing Sound: Applications Of Databases In Sound</h2><figure><img src="../img/mir_comp_sonif_interaction.png" alt=" Database performance in relation to computer music practices and their interdisciplinary feedback. The arrows between databases (cylinders) and computers (squares) represent data flow. Left: the database is ‘visibly next’ to the computer, as is the case with MIR ; the two bottom arrows indicate the intervention of the human operator. Right: the database is ‘visibly below’ the computer as is the case with Sonification; the database feeds the computer from an external source (right arrow). Middle: the database is ‘invisibly behind’ the computer, within the softwares used for (and as) music works. The arrows in between the practices represent interdisciplinary feedback. " style="width:100.0%" /><figcaption> Database performance in relation to computer music practices and their interdisciplinary feedback. The arrows between databases (cylinders) and computers (squares) represent data flow. Left: the database is ‘visibly next’ to the computer, as is the case with MIR ; the two bottom arrows indicate the intervention of the human operator. Right: the database is ‘visibly below’ the computer as is the case with Sonification; the database feeds the computer from an external source (right arrow). Middle: the database is ‘invisibly behind’ the computer, within the softwares used for (and as) music works. The arrows in between the practices represent interdisciplinary feedback. </figcaption></figure><p><span id="img:mir_comp_sonif_interaction" label="img:mir_comp_sonif_interaction">[img:mir_comp_sonif_interaction]</span></p><p>Having discussed the current state of new media theory and the theory of databases and data structures, in this section I theorize the use of databases in relation to sound. To a certain extent, ever since the first computers were used to make music the database has been an invisible partner in the music literature. I argue that by sheding some light to this inherent aspect of computers we can arrive at a clearer notion of how databases sound. Praticularly, by placing the database along a visibility continuum, we may find a reverse relation with audibility: the more invisible the database, the more present its sound. By this I do not argue in favor of neither loudness or quietness. I am only addressing the different possibilities that come from multiple access points to computers. Here I will use the words ‘database’ and ‘computer’ somewhat interchangeably. This decision comes from the fact, as I described in earlier sections, that computers cannot exist without databases. From this, we can further ask ourselves if all computer music is database music. As I hope to demonstrate, there are overt and covert uses of the database, but the database is ubiquitous in all computer practices (See Figure <a href="#img:mir_comp_sonif_interaction" data-reference-type="ref" data-reference="img:mir_comp_sonif_interaction">[img:mir_comp_sonif_interaction]</a>). The various disciplines at the intersection of music and computers take each a different approach to databases and, thus, to database performance. In this sense I describe and discuss the scope of actions that comprise database performance within three practices using computers and sound: MIR , sonification, and computer music.</p><h3 id="mir">Music Information Retrieval</h3><p>In MIR , the database is <em>in front</em> of the programmer, <em>next</em> to the computer. This practice combines IR with Music Theory, and it has been present in academia for a while, most generally within Electrical Engineering departments. The objective of MIR is to obtain useful information from the analysis of sound signals. That is, MIR seeks to represent a complex signal with a small number of data points, thus defining a a navigable ‘information space,’ which is, quite literally, the discretized space of the database.</p><figure><img src="../img/mir.png" alt=" Diagram of database performance in MIR practices. The database is visibly next to the computer, and the two bottom arrows indicate the intervention of the human operator. " id="img:mir" style="width:30.0%" /><figcaption> Diagram of database performance in MIR practices. The database is visibly next to the computer, and the two bottom arrows indicate the intervention of the human operator. <span label="img:mir"></span></figcaption></figure><p>For instance, out of sound file containing millions of samples, information space reduces these points to a database of few ‘descriptors’ that point to certain ‘features’ of the sound file. A descriptor is, in essence, a small amount of data that identifies other larger data. In this case, a feature descriptor relates to the values of a certain characteristics of the analyzed audio file, such as spectral centroid, brightness, flatness, etc.</p><p>Over the 18 years of the ISMIR conference, more than thirty databases of this sort have been publicly created and released, as a means to classify millions of songs and musical genres. This type of database navigation has been used to perform automatic tasks such as categorization for recommendation systems <span class="citation" data-cites="DBLP:journals/corr/abs-0812-4235">(Dinuzzo et al. 2008)</span>, track separation or instrument recognition, and score transcriptions, among other uses (see below). A recent emphasis in open source database creation has gained momentum <span class="citation" data-cites="DBLP:conf/ismir/FonsecaPFFBFOPS17">(Fonseca et al. 2017)</span>, such as the FREESOUND database, or CMAM ’s TELEMETA , both collaborative database systems: the former for general use, the latter for ethno-musicological pursposes. Before sound and audio descriptor databases, however, music notation databases have been developed with a variety of file formats, such as MIDI , MUSICXML , the Humdrum <code>**kern</code> data format <span class="citation" data-cites="DBLP:conf/ismir/Sapp05">(Sapp 2005)</span>, GUIDO , to name a few. For an extensive guide on musical representations, see <span class="citation" data-cites="Selfridge-Field:1997:BMH:275928">(Selfridge-Field 1997)</span>. Some examples of these notation databases can be the Polish folksong database in the ESAC format, the electronic library for musical scores MUSEDATA , the RISM database, the Kern Scores database,<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> among others. In turn, these databases have been a fruitful area of exploration in Computational Musicology <span class="citation" data-cites="DBLP:conf/iciso/Yokl11">(Yolk et al. 2011)</span>, for which toolkits such as MIT ’s MUSIC21 have been developed. The MARSYAS library and the ESSENTIA libraries are some examples of programs written with MIR techniques for a variety of purposes rooted in audio analysis and synthesis. There different applications of databases are endless and so varied that would extend the scope of this study.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a></p><p>In the following section, more specific uses of these and other audio databases will be mentioned. Some of the uses that MIR has given to the database have been:</p><ul><li><p>to create digital libraries <span class="citation" data-cites="DBLP:conf/ismir/Dunn00">(Dunn 2000)</span></p></li><li><p>to store actual music notation <span class="citation" data-cites="DBLP:conf/ismir/Good00">(Good 2000)</span></p></li><li><p>for audio classification and clustering <span class="citation" data-cites="ilprints489 DBLP:conf/ismir/HomburgMMMW05">(Homburg et al. 2005, Yang 2001)</span></p></li><li><p>for the evaluation of multiple-source, fundamental frequency estimation algorithms <span class="citation" data-cites="DBLP:conf/ismir/YehBR07">(Yeh et al. 2007)</span></p></li><li><p>to describe performance expression <span class="citation" data-cites="DBLP:conf/ismir/HashidaMK08">(Hashida et al. 2008)</span></p></li><li><p>for genre recognition and classification <span class="citation" data-cites="Tza02:Mus DBLP:conf/icmc/XuZY05 DBLP:conf/ismir/SillaKK08 icmc/bbp2372.2010.003 DBLP:journals/corr/abs-1803-04652 DBLP:journals/corr/WangH17a DBLP:journals/corr/MitraS14 2010NJPh:12e3030C DBLP:journals/corr/abs-0812-4235">(Correa et al. 2010, Dehkordi &amp; Banitalebi-Dehkordi 2018, Dinuzzo et al. 2008, Jr. et al. 2008, Mitra &amp; Saha 2014, Sanden et al. 2010, Tzanetakis &amp; Cook 2002, Wang &amp; Haque 2017, Xu et al. 2005)</span></p></li><li><p>for structural analysis <span class="citation" data-cites="DBLP:conf/ismir/SmithBFRD11">(Smith et al. 2011)</span></p></li><li><p>for contextual music listening pattern detection using social media <span class="citation" data-cites="DBLP:conf/ismir/HaugerSKT13">(Hauger et al. 2013)</span></p></li><li><p>to train models for phoneme detection <span class="citation" data-cites="DBLP:conf/ismir/ProutskovaRWC12">(Proutskova et al. 2012)</span></p></li><li><p>for schenkerian analysis <span class="citation" data-cites="DBLP:conf/ismir/Kirlin14">(Kirlin 2014)</span></p></li><li><p>for tonal music analysis using GTTM <span class="citation" data-cites="DBLP:conf/ismir/HamanakaHT14">(Hamanaka et al. 2014)</span></p></li><li><p>for counterpoint analysis <span class="citation" data-cites="DBLP:conf/ismir/AntilaC14">(Antila &amp; Cumming 2014)</span></p></li><li><p>for emotion recognition and color associations in the listener <span class="citation" data-cites="DBLP:conf/ismir/PesekGPSGSPM14">(Pesek et al. 2014)</span></p></li><li><p>for multimodal mood prediction <span class="citation" data-cites="DBLP:journals/corr/abs-1809-07276">(Delbouys et al. 2018)</span></p></li><li><p>for melody <span class="citation" data-cites="DBLP:conf/ismir/BittnerSTMCB14">(Bittner et al. 2014)</span> and singing voice <span class="citation" data-cites="DBLP:journals/corr/abs-1711-00048">(Stoller et al. 2017)</span> extraction</p></li><li><p>for harmonic analysis <span class="citation" data-cites="DBLP:conf/ismir/DevaneyACN15">(Devaney et al. 2015)</span></p></li><li><p>for the evaluation of tempo estimation and key detection algorithms <span class="citation" data-cites="DBLP:conf/ismir/KneesFHVBHG15">(Knees et al. 2015)</span></p></li><li><p>for orchestration <span class="citation" data-cites="DBLP:conf/ismir/CrestelEHM17">(Crestel et al. 2017)</span></p></li><li><p>for computational musicology<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> <span class="citation" data-cites="DBLP:conf/ismir/Parada-Cabaleiro17">(Parada-Cabaleiro et al. 2017)</span></p></li><li><p>for forensic analysis as a complement of video analysis <span class="citation" data-cites="serizel:hal-01393959">(Serizel et al. 2016)</span></p></li><li><p>for training and evaluating chord transcription algorithms <span class="citation" data-cites="DBLP:conf/ismir/EremenkoDBS18">(Eremenko et al. 2018)</span></p></li><li><p>for training querying methods such as humming <span class="citation" data-cites="DBLP:journals/corr/Brzezinski-SpiczakDLP13 DBLP:journals/corr/NagaviB14 DBLP:journals/corr/abs-1301-1894">(Brzezinski-Spiczak et al. 2013, Nagavi &amp; Bhajantri 2013, 2014)</span></p></li><li><p>for multi-instrument recognition <span class="citation" data-cites="DBLP:conf/ismir/HumphreyDM18">(Humphrey et al. 2018)</span></p></li><li><p>for adversarial audio synthesis <span class="citation" data-cites="2018arXiv180204208D">(Donahue et al. 2018)</span></p></li></ul><p>For further reference, the following citations point to different audio databases which have been created over the years: <span class="citation" data-cites="DBLP:conf/ismir/GotoHNO02 DBLP:conf/ismir/GotoHNO03 DBLP:conf/ismir/WustC04 DBLP:conf/ismir/MaxwellE08 DBLP:conf/ismir/Bertin-MahieuxEWL11 DBLP:conf/ismir/Karaosmanoglu12 Jaimovich:2012 Mital:2013 bbortz:2015 jjaimovich:2015 Nort2016 DBLP:conf/ismir/DefferrardBVB17 DBLP:conf/ismir/VigliensoniF17 DBLP:conf/ismir/Meseguer-Brocal18 DBLP:conf/ismir/DonahueMM18 DBLP:conf/ismir/XiBPYB18 DBLP:conf/ismir/WilkinsSWP18">(Bertin-Mahieux et al. 2011, Bortz et al. 2015, Defferrard et al. 2017, Donahue et al. 2018, Goto et al. 2002, 2003; Jaimovich et al. 2012, Jaimovich &amp; Knapp 2015, Karaosmanoglu 2012, Maxwell &amp; Eigenfeldt 2008, Meseguer-Brocal et al. 2018, Mital &amp; Grierson 2013, Nort et al. 2016, Vigliensoni &amp; Fujinaga 2017, Wilkins et al. 2018, Wüst &amp; Celma 2004, Xi et al. 2018)</span>.</p><h3 id="sonification">Sonification</h3><figure><img src="../img/sonif.png" alt=" Diagram of database performance in sonification practices. The database is visibly below the computer, and it feeds the computer from an external source represented by the right-most arrow. " id="img:sonif" style="width:30.0%" /><figcaption> Diagram of database performance in sonification practices. The database is visibly below the computer, and it feeds the computer from an external source represented by the right-most arrow. <span label="img:sonif"></span></figcaption></figure><p>The database is the ground floor of sonification. The sonified data is very likely to be digital,<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> which means that data needs to be stored in a structured way for fast access by computers, and the role of the sonifier is to acoustically translate the database’s inner relationships <span class="citation" data-cites="WalkerNees2011-TOS">(Walker &amp; Nees 2011, p. 9)</span>.</p><p>According to <span class="citation" data-cites="WalkerNees2011-TOS">Walker &amp; Nees (2011)</span> there are three types of sonification: event-based, model-based, and continuous. I see these types of sonification as ways of performing a database. Continuous sonification (audification) consists of directly translating waveforms of periodic data into sound, that is, reading non-audio data as if it were audio data <span class="citation" data-cites="WalkerNees2011-TOS">(Walker &amp; Nees 2011, p. 17)</span>. Model-based sonification consists of distributing data points in such a way that enables data exploration. Generally, these models are interactive interfaces with which users navigate the database to find relationships <span class="citation" data-cites="WalkerNees2011-TOS">(Walker &amp; Nees 2011, p. 17)</span>. Event-based (parameter mapping) sonification is aimed at representing changes in a database as acoustic saliences or tendencies. In this sense, dimensions of the data need to be translated (mapped) into acoustic parameters (frequency, periodicity, density, etc.), so as to listen how the generated sound behaves over time and interpret these changes within the database <span class="citation" data-cites="WalkerNees2011-TOS">(Walker &amp; Nees 2011, p. 16)</span>.</p><p>Sonification depends on databases, on the interaction between databases, and on their traversing, but also on the human body’s perceptual limits. In sonification, the data comes first, and it needs to be pre-processed so that it can be adapted to the sound synthesis engines of choice. Sonification is a subset of auditory display techniques, and it belongs to the broader scope of information systems and visualization practices <span class="citation" data-cites="WalkerNees2011-TOS">(Walker &amp; Nees 2011, p. 10)</span>. Therefore, since sonification belongs to the process of information, as a practice it has taken into account the auditory system’s ability to extract biologically relevant information from the complex acoustic world <span class="citation" data-cites="Carlile2011-P">(Carlile 2011)</span>. What this emphasis on sound perception and cognition abides to, however, is the fact that there is no one-to-one correspondence between sound parameters (frequency, amplitude, spectral content) and how these are perceived (pitch, loudness, timbre). Therefore, the success of a sonification is the result of the play between, on the one hand a rigid link between data and sound, and on the other, the perceived acoustic relations. From these acoustic relations, then, information can be obtained of the data. In other words, in sonification practices there is no communication unless the data has been acoustically shaped, and perceived as information (<em>in</em>-formed) by the listener.</p><p>In what follows, I present some instances of sonification practices as described by their authors.</p><h4 id="sonification:parametermapping">Parameter mapping</h4><h5 id="dow">DOW</h5><p>David Rossiter and Wai-Yin Ng <span class="citation" data-cites="icmc/bbp2372.1996.085">(Rossiter &amp; Ng 1996)</span> sonified the Dow Jones financial stock market data with Csound. Since the Csound program depends on two separate files (orchestra and score), they implemented another program to control the data flow. Within this second program, the Csound score was automatically generated based on a ‘configuration’ file which was used to map the ‘data file’ holding the stock market data, as it was read in separate window frames into the Csound-formatted score.<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a></p><h5 id="medical-images">Medical Images</h5><p>Cadiz et al <span class="citation" data-cites="DBLP:conf/icmc/CadizCMMATI15">(Cádiz et al. 2015)</span> proposed a sonification approach based on statistical descriptors of ROI selected from medical images. In their study, they focused on enhancing breast cancer symptom detection in mammograms by mapping statistical descriptors, such as mean, minimum, maximum, standard deviation, kurtosis, skewness, among others, to different synthesis techniques in various ways. They then surveyed the usefulness and pleasantness of the sonifications to different subjects in order to better adjust the technique to the task. What is novel of their approach is on the creative use of statistical curves obtained from pixel distributions within computer music techniques.</p><h4 id="sonification:model">Model-based sonification</h4><h5 id="space">Space</h5><p>One example of model-based sonification is the <em>Data Listening Space</em> project by Vogel and other members of the QCD-AUDIO project <span class="citation" data-cites="icmc/bbp2372.2012.096">(Vogt et al. 2012)</span> at the IEM of the University of Music and Performing Arts in Graz. Within this installation, they proposed a three dimensional, navigable space holding a Monte Carlo simulation of the theory of QED . Within this QED <em>lattice</em>, a walking participant holding sensors —<span class="math inline"><em>x</em></span>, <span class="math inline"><em>y</em></span>, and <span class="math inline"><em>z</em></span> coordinates— could explore the simulated data by way of sonification.</p><h4 id="sonification:artistic">Artistic sonification</h4><h5 id="wolves">Wolves</h5><p>Judy Klein composed in 1998 a piece called <em>The Wolves of Bays Mountain</em>, using a set of recordings she took along the Bays Mountain Park in Kingsport, Tennessee, for a period of six months. In this period she researched the sonic activity of a pack of wolves, and in her recordings she achieved a level of intimacy with the pack that, as a result, translated into a strong animal rights activism. Therefore, her compositional choice was to treat the sound file in a non-destructive and non-intrusive way, thus analyzing spectral contours of extremely precise frequency bandwidths of the data and resynthesizing into the soundscape in almost unnoticeable ways.<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a></p><h5 id="selva">Selva</h5><p>Natasha Barrett <span class="citation" data-cites="icmc/bbp2372.2000.123">(Barrett 2000)</span> composed an electroacoustic work called <em>Viva La Selva</em><a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a> using 14-hour long recordings taken from a forest<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a>, with an array of four microphones. From these recordings, she extracted location (by difference in arrival time) and timestamps (by manual logging) of different animal sounds, and long-term energy distribution in various frequency bands, to describe various environmental sounds such as airplanes, wind, insects, etc. While the spatio-temporal data of the animal sounds was used for sound spatialization of sounds within the electroacoustic work, the long-term energy distribution was scaled down to 20 minutes so as to constitute the form of the piece.</p><h5 id="ocean">Ocean</h5><p>Bob L. Sturm <span class="citation" data-cites="icmc/bbp2372.2002.056">(Sturm 2002)</span> sonified ocean wave conditions of the USA Pacific coast obtained by the CDIP since 1975. The database until 2002 contained over 50 GB of spectral and directional content of the wave-driven motions at the location of the sensing buoys. By scaling to hearable range and then performing an IFT of the data, Sturm composed a piece called <em>Pacific Pulse</em>, on which frequency sweeps indicate storms beginnings (rising) and endings (falling).</p><h5 id="rivers-and-molecules">Rivers and Molecules</h5><p>More recent examples of artistic sonification include Nichols et al <span class="citation" data-cites="icmc/bbp2372.2014.065">(Nichols et al. 2014)</span> with their sonification of river data as a multimedia collaboration. Falk Morawitz <span class="citation" data-cites="icmc/bbp2372.2016.002">(Morawitz 2016)</span> used molecular sonification in his piece <em>Spin Dynamics</em><a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a>, by two audification processes (direct audification and via a straightforward additive synthesis process) applied to the HMDB , a database holding NMR spectroscopies of molecules.</p><h5 id="gender-distribution">Gender Distribution</h5><p>Emma Frid <span class="citation" data-cites="Fri17:Son">(Frid 2017)</span> derived a database of gender distribution by applying the python module <code>genderize</code> to author names in three main computer music conference proceedings databases: ICMC , NIME , and SMC . By assigning polar frequency ranges for each group (male and female), her sonification emphasizes the significant inequality of gender in the resulting acoustic stream segregation into male backround (continuous drone-like sound) and female foreground (fewer and sparser sounds). Her conclusion, therefore, is that “there is a need for analysis of the existing environments and social relations that surround music technology and computer music. If we identify the challenges that women are facing in our research community, we will be able to create more initiatives towards changing practices” <span class="citation" data-cites="Fri17:Son">(Frid 2017, p. 238)</span>.</p><h4 id="sonification:installations">Sonification Installations</h4><h5 id="ip-based-soundscape">IP-based soundscape</h5><p>Mark Ballora et al <span class="citation" data-cites="icmc/bbp2372.2010.117">(Ballora et al. 2010)</span> sonified a database of HTTP requests at Penn State’s NC2IF . This database contained entries with four fields such as timestamp, location (latitude-longitude), IP address, and response type. Using parameter mapping, Ballora controlled rhythm and spatialization with the first two, and pitch and timbre with IP data. However, the latter ranged from the more concrete ( IP to frequency) to the more abstract ( IP as formant and highpass filters for brown noise), thus resulting in a soundscape with different but simultaneous sonifications of the data. This multi-layered approach to sonification stems from his PhD dissertation on cardiac rate sonification <span class="citation" data-cites="Ballora/2000/phdthesis">(Ballora 2000)</span>.</p><h5 id="earthquakes">Earthquakes</h5><p><span class="citation" data-cites="icmc/bbp2372.2017.033">Lindborg (2017)</span> sonified real-time earthquake data as a sound sculpture <span class="citation" data-cites="icmc/bbp2372.2017.033">(Lindborg 2017)</span>. Within , he used data from the IRIS Data Services, which transmits seismographic data packets updated every thirty minutes from multiple observation sites. He spatialized this data using coordinates of the events and using a four-speaker array located at the center of the gallery space, and mapped the rest of the data to FM synthesis parameters.</p><h5 id="gpu-based-waveforms">GPU-based waveforms</h5><p>Schlei and Yoshikane <span class="citation" data-cites="icmc/bbp2372.2016.056">(Schlei &amp; Yoshikane 2016)</span> proposed a novel way to generate waveforms by populating an array using vertex data obtained from the GPU . In order to carry this out, they used the Metal API<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a>, and intervened on the processing pipeline to output CPU accessible data. The audio engine running on the CPU was able to interpret as waveforms the values of the vertex and fragment shaders, thus sonifying the position data related to a rendered shape and the pixel values respective to its display. Therefore, they obtained simultaneous visualization and audification of the rendered three dimensional shape. In their installation <em>The Things of Shapes</em><a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a>, they used the generated waveforms as a database, composing each waveform together with their visual generators as a collage.</p><h5 id="ucanny-faces">Ucanny Faces</h5><p>Simonelli et al <span class="citation" data-cites="fdch/installation/spectral">(Simonelli et al. 2017)</span> designed <em>Hally</em>, an installation based on face-tracking and real-time sonification of spectral features present in both pixel information containing the face, and the <span class="math inline"><em>x</em></span> and <span class="math inline"><em>y</em></span> coordinates of the moving data points of the face mesh used for tracking. Furthermore, by video-based audio convolution, <em>Hally</em> aims to simulat a theory of perception based on IFT <span class="citation" data-cites="connes:shapes">(Connes 2012)</span>. Parting from previous work by <span class="citation" data-cites="Sch07:How">Thiebaut et al. (2007)</span> on simultaneous sonification and visualization <span class="citation" data-cites="Sch07:How">(Thiebaut et al. 2007)</span>, <em>Hally</em> explores the role of both sound and image in the definition of the self, by immersing the participant in an uncanny spectrality <span class="citation" data-cites="fdch/papers/spectral">(Cámara Halac 2018a)</span>.</p><h4 id="sonification:software">Sonification Software</h4><h5 id="sonart">SonArt</h5><p>Originally intended for sonification purposes, SONART <span class="citation" data-cites="icad/2002/ben-tal">(Ben-Tal et al. 2002)</span> was an open-source platform that enabled users to map parameters to sound synthesis, and later <span class="citation" data-cites="icmc/bbp2372.2004.128">(Yeo et al. 2004)</span> to obtain cross-correlated image and sound synthesis. In other words, users were able to easily translate a database into sound parameters, or image and sound data into one another. The program acted in a modular way, that is, it was networked with other software via OSC connections. This software enabled Berger and Seung Yeo <span class="citation" data-cites="DBLP:conf/icmc/YeoB05">(Yeo &amp; Berger 2005)</span> to generate novel image sonifications, by combining two methods of sonification into one interface: sonified data in a fixed, non-modifiable order (<em>scanning</em>) and sonified selected data points (<em>probing</em>).</p><h5 id="dataplayer">DataPlayer</h5><p>In his CADDC environment called <em>DataPlayer</em> programmed as a standalone MAX/MSP application, Nardelli <span class="citation" data-cites="icmc/bbp2372.2015.072">(Nardelli 2015)</span> sonified data from the AFLOWLIB . His sonification intent was aimed towards data navigation by means of a unique mapping that would convey an overall trend (a gist) of each material compound. Furthermore, this environment allowed for artistic remixing and exploration of the sonification procedures, simultaneously touching on the scientific and the artistic uses of the environment.</p><h5 id="madbpm">madBPM</h5><p>Hamilton et al <span class="citation" data-cites="icmc/bbp2372.2017.087">(Fox et al. 2017)</span> devised MADBPM , a data-ingestion engine suitable for database perceptualization, that is, sonification and visualization. This modular C++ software platform enables data loading from CSV files, multiple mapping via tagging, several traversing algorithms and units, and networked connectivity to SuperCollider for sound and OFX for visual output. Their approach is innovative since they provide features for database behaviors. By ‘behavior’ they mean ways of structuring, traversing and perceptualizing the database. These behaviors define the dual purpose of the software: finding relationships among the inputted data and interpreting them artistically. Furthermore, users can structure and re-structure potentially any type of data set <span class="citation" data-cites="icmc/bbp2372.2017.087">(Fox et al. 2017, p. 504)</span>. However, in order to design new behavior objects the user needs to implement them in the source code and compile them. Thus, besides real-time data streaming and networking functionality, in their future work the authors aim at designing a DSL that would enable extending the functionality of these behaviors in real-time.</p><p>For further sonification software, see SONDATA and the following references: <span class="citation" data-cites="Wil96:Lis pauletto04 Lod98:MUS Bei09:Aes Her14:Aso DBLP:conf/icad/2007/Worral DBLP:conf/icad/2003/Walker">(Beilharz &amp; Ferguson 2009, Hildebrandt et al. 2014, Lodha et al. 1998, Pauletto &amp; Hunt 2004a,b; Walker &amp; Cothran 2003, Worrall et al. 2007)</span></p><h3 id="computer_music">Computer Music</h3><p>Delimiting constraints to data structures is one of the key aspects of software design. The first choice is generally the programming language, after which the database tree unfolds its way up to the leaves. Among these leaves is where computer music programs reside. At this level of ‘leaves’ software users are certainly aware that there is a ‘tree’ in front of them. However, their awareness does not necessarily extend to the branches, trunk, or the roots of the tree. There is endless music that can be made with leaves just as it can with paper. However, neither music quanitity nor music quality are the point here. My argument is that working with data structures changes how we think and perform music making. I claim that composers using these leaves of computer music software are working indirectly with data structures, and unless they engage with programming, they remain unaware of data structures and their constraints. ‘Indirectly,’ because there exist the twigs and the branches that connect the leaf to the trunk. These links become invisible to the non-programmer composer <em>by design</em>. Like a phantom limb of the tree, the database remains invibibly <em>behind</em>. Therefore, in this section I present ideas from composers and programmers that show different approaches on how music concepts change with the presence of the database.</p><figure><img src="../img/comp.png" alt=" Diagram of database performance in computer music practices. The database is invisibly behind the computer, within the softwares used for (and as) music works. " id="img:comp" style="width:20.0%" /><figcaption> Diagram of database performance in computer music practices. The database is invisibly behind the computer, within the softwares used for (and as) music works. <span label="img:comp"></span></figcaption></figure><h4 id="hierarchical-environments">Hierarchical environments</h4><h5 id="computer:sssp">Reducing cognitive burden</h5><blockquote><p>One of the most important aspects in the design of any computer system is determining the basic data types and structures to be used…we have been guided by our projection of the interaction between the tool which we are developing, and the composer. <span class="citation" data-cites="icmc/bbp2372.1978.012">(Buxton et al. 1978b, p. 119)</span></p></blockquote><p>In William Buxton’s survey of computer music practices <span class="citation" data-cites="Bux77:Aco icmc/bbp2372.1978.012 DBLP:conf/icmc/BuxtonPRB80">(Buxton 1977, Buxton et al. 1978b, 1980)</span>, he distinguished between <em>composing programs</em> and <em>computer aided composition</em>, arguing that they both failed as software, the former on account of their personalization and formalization, and the latter on their lack of interactivity. On his later interdisciplinary venture called SSSP , he focused on HCI —a field in its very early stages in 1978—<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a>. Buxton’s concern throughout SSSP was to address the“problems and benefits arising from the use of computers in musical composition” <span class="citation" data-cites="DBLP:conf/icmc/BuxtonFBRSCM78">(Buxton et al. 1978a, p. 472)</span>. His solution was to reduce the cognitive burden of the composer, who “should simply not have to memorize a large number of commands, the sequence in which they may be called, or the order in which their arguments must be specified” <span class="citation" data-cites="DBLP:conf/icmc/BuxtonFBRSCM78">(Buxton et al. 1978a, p. 474)</span>. He argued that reducing the amount of information given to composers helped them focus on music making. Therefore, in SSSP , the composer’s action was reduced to four main selection tasks: timbres, pitch-time structure, orchestration, and playback. Timbres were assigned by defining waveforms for the table lookup oscillators, and pitch-time structure consisted on pitches and rhythms on a score-like GUI program called SCRIVA <span class="citation" data-cites="youtube/buxton10">(Buxton 2016a)</span>. Orchestration consisted in placing the previously chosen timbres on the score, and playback meant running the score or parts of it. With this simple but very concise structure, Buxton delimited the scope of action of the composer.</p><h5 id="a-hierarchical-representation">A Hierarchical Representation</h5><p>Buxton based his research on differing approaches to composition: Iannis Xenakis’s score-as-entity approach <span class="citation" data-cites="Xen92:For">(Xenakis 1992)</span> (the 1971 publication of ), an unpublished 1975 manuscript by Barry Vercoe at MIT studio for Experimental Music, where Buxton found a note-by-note approach, and Barry Truax’s computer music systems <span class="citation" data-cites="Tru73:The">(Truax 1973)</span> which was located somewhere in between, without providing a solution for “the problem of dealing with the different structural levels of composition —from note to score—” <span class="citation" data-cites="icmc/bbp2372.1978.012">(Buxton et al. 1978b, p. 120)</span> (See <a href="#computer:balance" data-reference-type="ref" data-reference="computer:balance">4.3.3.1.6</a>). Buxton, however, condensed these different approaches into what he called a “chunk-by-chunk” composition, where ‘chunk’ represented anything from notes to entire scores, and thus it became a scalability issue. Furthermore, he writes, “the key to allowing this ‘chunk-by-chunk’ addressing lies in our second observation: that the discussion of structural ‘levels’ immediately suggest a hierarchical internal representation of scores” <span class="citation" data-cites="icmc/bbp2372.1978.012">(Buxton et al. 1978b, p. 120)</span>. That is to say, his solution for the scalability problem came with a hierarchical representation of scores.</p><p>In Buxton’s SSSP , the hierarchical design depended on a data structure called <em>symbol table</em>, which he subsequently divided in two objects called <code>score</code> and <code>Mevent</code> (musical events). The <code>score</code> structure had a series of global fields (variables) together with pointers to the first (head) and last (tail) <code>Mevent</code>s. In turn, <code>Mevent</code>s had local fields for each event together with pointers to the next and previous <code>Mevents</code>, so as to keep an ordered sequence (See <a href="#computer:linked" data-reference-type="ref" data-reference="computer:linked">4.2.3.0.2</a>) and enable temporal traversing of the tree. In turn, <code>Mevents</code> could have two different types: <code>MUSICAL_NOTE</code> and <code>Mscore</code>, the former relating to terminal nodes editable by the user —what he referred to as ‘leaves’ of the tree structure—, and the latter consisting of nested <code>score</code> objects that added recursivity to the structure. Buxton’s model was thus hierarchic (a tree structure) implemented in nested and doubly-linked symbol tables.</p><p><span class="citation" data-cites="icmc/bbp2372.1978.012">Buxton et al. (1978b)</span> gave a detailed exposition of the data structures and their functionality in the paper <span class="citation" data-cites="icmc/bbp2372.1978.012">(Buxton et al. 1978b)</span> . In light of this transparency (and, perhaps, because of it), however, Buxton’s general purpose in his HCI philosophy is to make the software work in such a way that it becomes invisible to the user. This is also known as a black-box approach. His innovations in this and other projects, however, have had enormous resonances in computer science, and the concept of reducing cognitive burden of the user developed as a standard of HCI <span class="citation" data-cites="youtube/buxton16">(Buxton 2016b)</span>.</p><h5 id="black-boxing">Black-boxing</h5><p>Vílem Flusser <span class="citation" data-cites="Flu11:Int">(Flusser 2011)</span> described our ability to envision as the power to visualize beyond the surface of the image, and to bring the technical image into a concrete state of experience. The ‘image,’ in Flusser’s case is the television screen in its abstract state of “electrons in a cathode ray tube.” Therefore, he argues, “if we are asking about the power to envision, we must let the black box remain —cybernetically— black” <span class="citation" data-cites="Flu11:Int">(Flusser 2011, p. 35)</span>. By seeing past the abstract quality of media we bring an image into experience. The black box is the possibility condition for envisioning to take place. Thus, by seeing past the hidden complexities of the software, composers are able to create music with unrestrained imagination. However, as I have shown before, Hansen makes a divergent point claiming that virtuality inherent in the body is the creative potential of image in-formation (See <a href="#embodiment" data-reference-type="ref" data-reference="embodiment">4.1.5</a>).</p><p>Understanding the process of information as the experience of technical images, it follows that virtuality and envisioning can be considered complementary. On one hand, there is the technical device, whose multidimensionality is as complex as it is hidden from the envisioner. On the other, the human body with its capacity to create and embody. Flusser’s point is, however, paradoxical: “The envisioner’s superficiality, to which the apparatus has <em>condemned</em> him and for which the apparatus has <em>freed</em> him, unleashes a wholly unanticipated power of invention” [emphasis added] <span class="citation" data-cites="Flu11:Int">(Flusser 2011, p. 37)</span>. Therefore, the black-box is what condemns and frees the envisioner to a state of superficiality. However, Flusser continues, “envisioners press buttons to inform, in the strictest sense of that word, namely, to make something improbable out of possibilities” <span class="citation" data-cites="Flu11:Int">(Flusser 2011, p. 37)</span>. In other words, Flusser’s text in 1985 justifies the invisibility of the technological device in favor of its most useful consequence, that is, its ability to make the user create something “out of possibilities.” Composers, therefore, are given these possibilities to create, at the cost of a limited performance of the database.</p><h5 id="computer:free">Generality and Portability</h5><blockquote><p>Music data structures must be general enough so that as many styles of music as possible may be represented. This implies that the data structures (or the application’s interface to them) should not enforce a musical model (such as equal temperament) that is inappropriate for the musical task at hand. <span class="citation" data-cites="icmc/bbp2372.1987.046">(Free 1987, p. 318)</span></p></blockquote><p>The SSSP lasted until 1982 due to lack of funding, and in the mid-1980s its research re-emerged with John Free <span class="citation" data-cites="icmc/bbp2372.1987.046">(Free 1987)</span>, under Helicon Systems’ CAMP . Free’s programming philosophy thus called for generality, portability, and simplicity. Due to SSSP ’s many hardware dependencies, the code had to be completely re-written <span class="citation" data-cites="DBLP:conf/icmc/FreeV86">(Free &amp; Vytas 1986)</span>. Hardware development would demand higher levels of software abstractions, so that software continued to live on in newer hardware. This issue refers to the portability of software (See <a href="#portability" data-reference-type="ref" data-reference="portability">4.2.2.0.3</a>), which became a crucial aspect of Free’s programming concerns. Besides portability, Free developed SCRIVA into extensible data structures for music notation arguing for generality. Software had to be general enough so that composers could work in multiple styles. The larger implication in the Free’s argument is that enforcing musical concepts in data structures limits the style that the program can achieve. Therefore, if the program fails to provide a certain level of generic functionality, the composer’s output will be modelled by the data structure. On the one hand, it can be argued that this implication is, simultaneously overestimating the agency of the database, and underestimating that of the composer. However, the programming philosophy here is that of reducing the burden of the user by taking care of the more tedious task. The cost of this, nonetheless, is that by working for the composer, the database guides and hides: it guides the composer through certain paths and hides the composer from other paths. That is to say, if composers take the paths given by the database as givens, then those become the only possible paths.</p><h5 id="computer:vanilla">Simplification</h5><p>Hardware-independence led Free to also imagine a <em>vanilla</em> synthesizer, with which students in “a music lab with multiple users on a networked computer system” <span class="citation" data-cites="DBLP:conf/icmc/FreeV88">(Free &amp; Vytas 1988, p. 127)</span> could seamlessly use the timbre world offered by various synthesizers made by different manufacturers. Software needed to interact simultaneously with different types of hardware. Free achieved this type of interaction with the <em>Music Configuration Database</em>. It consisted of an intermediate program between the physical MIDI input devices (such as the Yamaha DX7 or Casio CZ101), and the computers in the network, so that “rather than have the user tediously specify the MIDI device properties for each synthesizer” <span class="citation" data-cites="DBLP:conf/icmc/FreeV88">(Free &amp; Vytas 1988, p. 133)</span> (channel management, control mapping, etc), these processes were handled by an intermediary database. Free’s approach, in comparison to Buxton’s, is not entirely black-boxed, since the database is open to modification by a specific set of commands provided to the user. The user can edit the database with a library of database access subroutines such as open/close, create/delete items, querying fields/keys, and loading/storing property items. With this library, Free simultaneously simplified user’s interaction and reduced the “chance of corrupting the database” <span class="citation" data-cites="DBLP:conf/icmc/FreeV88">(Free &amp; Vytas 1988, p. 137)</span>.</p><h5 id="computer:balance">Balance</h5><figure><img src="../img/truax_generality_b.png" alt=" Barry Truax’ “Inverse Relation Between Generality and Strength” 51(Truax 1980, p. 51). Another version of this graph can be found in 38(Laske &amp; Tabor 1999, p. 38). " style="width:70.0%" /><figcaption> Barry Truax’ “Inverse Relation Between Generality and Strength” <span class="citation" data-cites="Tru80:The">(Truax 1980, p. 51)</span>. Another version of this graph can be found in <span class="citation" data-cites="laske_otto_1999">(Laske &amp; Tabor 1999, p. 38)</span>. </figcaption></figure><p><span id="img:truax_generality_b" label="img:truax_generality_b">[img:truax_generality_b]</span></p><blockquote><p>…all computer music systems both <em>explicitly and implicitly embody a model of the musical processes that may be inferred from the program and data structure of the system</em>, and from the behavior of user working with the system. The inference of this model is independent of whether the system designer(s) claim that the system reflects such a model, or is simply a tool. [emphasis added] <span class="citation" data-cites="Tru76:ACo">(Truax 1976, pp. 230–31)</span></p></blockquote><p>Barry Truax (<span class="citation" data-cites="Tru73:The Tru76:ACo Tru80:The">(Truax 1973, 1976, 1980)</span>, <span class="citation" data-cites="Emm86:The">(Emmerson 1986 Chapter 8)</span>), often compared grammatical structures of natural language to the structures of computer music systems, claiming that in both cases one can find certain constraints and facilitations for thought <span class="citation" data-cites="Emm86:The">(Emmerson 1986, p. 156)</span>. Arguing for balance between generality of applicability and strength of embedded knowledge within models for computer music systems (See Figure <a href="#img:truax_generality_b" data-reference-type="ref" data-reference="img:truax_generality_b">[img:truax_generality_b]</a>), he writes:</p><blockquote><p>In a computer music system, the grouping of data into larger units such as a sound-object, event, gesture, distribution, texture, or layer may have a profound effect on the composer’s process of organization. The challenge for the software designer is how to provide powerful controls for such interrelated sets of data, how to make intelligent correlations between parameters, and how to make such data groupings <em>flexible according to context</em>. [emphasis added] <span class="citation" data-cites="Emm86:The">(Emmerson 1986, p. 157)</span></p></blockquote><p>Truax’s notion of balance speaks of a ‘meeting halfway’ between the system and the user on account of the programmer’s capability to embed a more complex conception of hierarchy in the system. Balance refers precisely to flexibility among data structures. Since data structures can embody models of musical processes, they have an effect on the composer’s overall <em>performance</em> of the database in music composition. By ‘database performance’ I do not mean the quality of musical output, or the dexterity of the composer’s programming activity. By database performance I refer to the behavioral activity that comprises the scope and quality of the composer’s actions, together with the agency of this behavior within the results.</p><h4 id="music-notation-software">Music Notation Software</h4><h5 id="computer:notation"> DARMS </h5><p>Other programming approaches for music notation software were developed during the 1980s, specifically using the DARMS notation project. The DARMS project started in 1963 by Stefan Bauer-Mengelberg and it is one of the first programming languages for music engraving <span class="citation" data-cites="icmc/bbp2372.1983.002 10.2307/30204239">(Brinkman 1983, Erickson 1975)</span>. Peter J. Clements <span class="citation" data-cites="icmc/bbp2372.1980.020">(Clements 1980)</span> joined together the DARMS data structures with those used in Max Mathews’ synthesis program MUSIC V, in a first attempt to obtain sonic feedback out of a notation system. However, Clements’ attempt was not as successful as Leeland Smith’s famous SCORE <span class="citation" data-cites="smith1971">(Smith 1972)</span>. Smith’s program consisted of a character scanner interpreting rhythmically complex musical input into MUSIC V output. Thus, it was an intermediary between music notation and computer music synthesis. With the appearance of vector graphics in the 1970s, however, SCORE shifted solely to music printing and later became commercially available with the appearance of the PostScript format in the 1980s.<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a></p><h5 id="computer:computer">Computer Scores</h5><p>Alexander Brinkman <span class="citation" data-cites="icmc/bbp2372.1981.018">(Brinkman 1981)</span> modelled Smith’s input format into <em>Score-11</em>, adapting it to Barry Vercoe’s MUSIC-11 . Written in Pascal, <em>Score-11</em> used circular linked lists traversed by an interpreter, and it results in MUSIC-11 -formatted output. Thus, the user creates a text file with blocks dedicated to individual instruments, and specifies parameters such as rhythm, pitch, movement (glissandi, crescendo), amplitude, etc., that are then re-formatted to fit the less musically-oriented notation of the MUSIC-N programs. Brinkman argues that such a software would result in faster and less arduous performance on the composer’s end:</p><blockquote><p>A crescendo over several hundred very short notes requires several hundred different amplitude values representing the increasing volume. <em>Typing in several hundred note statements each with a slightly larger amplitude number would take forever</em>. If the computer could be instructed to gradually increase the amplitude value over twenty seconds then <em>life would be much simpler</em>. This is the type of job that a note list preprocessor is designed to accomplish. [emphasis added] <span class="citation" data-cites="score11manual">(Brinkman 1982)</span></p></blockquote><p>Brinkman emphasized, as well, on the program’s extensibility by users, and it inspired Mikel Kuehn’s recent <em>nGen</em> program which is a version of Brinkman’s program for the currently available Csound <span class="citation" data-cites="csoundMethods">(McCurdy et al. 2015)</span>. Brinkman, however, designed an interpreter for the DARMS language <span class="citation" data-cites="icmc/bbp2372.1983.002">(Brinkman 1983)</span>, which became useful for obtaining computable data structures for automated music analysis <span class="citation" data-cites="icmc/bbp2372.1984.033">(Brinkman 1984)</span>.</p><p>J. Stephen Dydo <span class="citation" data-cites="icmc/bbp2372.1987.045">(Dydo 1987)</span> worked on an interface to the DARMS language called the <em>Note Processor</em>, which became one of the earliest commercially available music notation systems. Dydo’s data structures, however, were not publicly released when he presented his software at the ICMC in 1987. He later released it commercially in the early 1990s at a significantly lower price than other notation software, namely <em>Finale</em> which is still available today by MakeMusic, Inc. <span class="citation" data-cites="10.2307/941442 10.2307/940555">(Skinner 1990a,b)</span>.</p><h5 id="computer:nutation">N<em>u</em>tation</h5><p>Another approach to music notation was carried out at CCRMA , when Glendon Diener <span class="citation" data-cites="icmc/bbp2372.1988.020 10.2307/3680043">(Diener 1988, 1989)</span> deviced a “pure structure” devoted to the “hierarchical organization of musical objects into musical scores:” the <em>TTree</em> <span class="citation" data-cites="icmc/bbp2372.1988.020">(Diener 1988, p. 184)</span>. Stemming from his PhD research on formal languages in music theory <span class="citation" data-cites="diener1985">(Diener 1985)</span>, this data structure was based in the hierarchic structures of the SSSP project. The change Diener introduced to these structures was their capability of sustaining links between not only the previous and the next data records, but to the ‘parent’ or ‘child’ data records to which it was related. This is known as ‘inheritance,’ and it enabled “any event in the [structure] to communicate with any other event” <span class="citation" data-cites="icmc/bbp2372.1988.020">(Diener 1988, p. 188)</span>.</p><p>While Diener implemented this data structure in the object-oriented programming language SMALLTALK , he later developed it into <em>Nutation</em> <span class="citation" data-cites="DBLP:conf/icmc/Diener92">(Diener 1992)</span>, a visual programming environment for music notation. <em>Nutation</em> was written in OBJECTIVE-C , and it combined the previously developed <em>TTree</em> structure with glyphs and a music synthesis toolkit called <em>Music Kit</em> that the NEXT computer provided. This resulted in an extremely malleable CAC environment, which enabled fast manipulation and sonic feedback at the cost of limiting timbre to a predefined, hardware-specific set of digital instruments.</p><h5 id="computer:theoretical">Theoretical Performance</h5><p>What notation software is most often criticised for is the way in which sonic feedback often comes to be equiparated to (human) music performance. When Leeland Smith presented SCORE as “not a ‘performer’s’ instrument, but rather a ‘musician’s’ instrument,” for example, he claimed that ”theoretically, any performance, clearly conceived in the mind, can be realized on [the computer]” <span class="citation" data-cites="smith1971">(Smith 1972, p. 14)</span>. It is indeed a fact that computers can offer automated tasks to an unimaginable extent. However, to translate this type of automation into music composition and performance, results in a disembodied music conception. In other words, an algorithmically generated stream of notes may result in physically impossible tasks for a performer, or for the listener. This is the point of inflexion when envisioning goes beyond the threshold of embodiment. It can be argued, however, that further developments in musical performance techniques can be achieved by pushing the limits of bodily skills. Nonetheless, what I am stressing here is the extent to which music composition can be reconfigured by the possibilities data structures have brought to the field.</p><h4 id="enter-objects">Enter Objects</h4><h5 id="computer:realtime">Max and data structures for realtime</h5><p>Composers and programmers in the 1980s began focusing, however, on real-time performance of computer music.<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a> In a joint venture between MIT and IRCAM, the software MAX was being developed by Miller Puckette. Within this software, Puckette’s emphasis was on a different aspect of the use of database: time and its scheduling. For example, the main concern in the design of the software is located in the following idea regarding complexity:</p><blockquote><p>…complexity must never appear in the dealings between objects, only within them. Three other features currently in vogue seem unnecessary. First, there is no point in having a built-in notion of hierarchy; it is usually a hindrance. Second, I would drop the idea of continuously-running processes; they create overhead and anything they do can be done better through [input, output] related timing. Third, there should be few defaults. Rather than hide complexity I would keep it visible as an incentive to avoid it altogether. <span class="citation" data-cites="DBLP:conf/icmc/Puckette86">(Puckette 1986, p. 43)</span></p></blockquote><p>In yet another turn of the screw of Buxton’s concept of reducing the user’s cognitive burden, Puckette keeps complexity “visible” within the concept of the programming <em>object</em>. Furthermore, he removes the notion of hierarchical programming which was also present in Buxton’s view, and proposes an light-weight, on-the-spot programming practice based on discontinuous processes. The structure of the database was placed <em>horizontally</em>, that is, along the time axis, and Puckette’s efforts were dedicated to optimizing the handling of the internal timing of the processes:</p><blockquote><p>The scheduler keeps the runnable-message pool in the form of a separate queue for each latency. The scheduler always sends the first message in the lowest-latency nonempty queue. When the associated method returns the scheduler sends another message and so on. The only situation in which we need to interrupt a method before it is done is when I/O (including the clock) causes a lower-latency message to appear…In this case the scheduler causes a software interrupt to occur by pushing a new stack frame onto the stack and executing the lower-latency method. When this method returns …we pop the stack back to the prior frame at latency <span class="math inline"><em>d</em><sub>2</sub></span> and resume the associated method. <span class="citation" data-cites="DBLP:conf/icmc/Puckette86">(Puckette 1986, p. 46)</span></p></blockquote><p>What this means, is that the concept of linked lists is used to keep track of the order of processes that are run, and that each process is scheduled according to its temporality (latency). Thus, the entire network of processes that can be run is maintained in a dynamic list (stack) that can be changed at any time by adding or removing elements (push/pop). The way in which these processes (methods) are called is by messages that can be sent (input/output) by the user or objects themselves. This way of thinking programming in terms of objects is known as object-oriented programming, and it was already in use in the MUSIC-N programs. However, in this case, the scheduling system that Puckette implemented consisted in a ground-breaking application of the technique that changed the real-time computer music performance scene: “…rather than a programming environment, MAX is fundamentally a system for scheduling real-time tasks and managing intercommunication between them” <span class="citation" data-cites="DBLP:journals/comj/Puckette02">(Puckette 2002a)</span>.</p><h5 id="computer:puredata">Pure Data</h5><p>Because of this emphasis on process, when Puckette developed Pure Data <span class="citation" data-cites="icmc/bbp2372.1997.060">(Puckette 1997)</span>, he made it so data structures were a more accessible feature for the user to define and edit. To this day this Max paradigm <span class="citation" data-cites="DBLP:journals/comj/Puckette02">(Puckette 2002a)</span> can still be found in both widely used programs MAX/MSP <span class="citation" data-cites="DBLP:conf/icmc/Zicarelli98">(Zicarelli 1998)</span> and Pure Data. What is important to note here, moreover, is the emphasis on Puckette’s end to provide a musical instrument without stylistic constraints:</p><blockquote><p>The design of MAX goes to great lengths to avoid imposing a stylistic bias on the musician’s output. To return to the piano analogy, although pianos might impose constraints on the composer or pianist, a wide variety of styles can be expressed through it. To the musician, the piano is a vehicle of empowerment, not constraint. <span class="citation" data-cites="DBLP:journals/comj/Puckette02">(Puckette 2002a)</span></p></blockquote><p>Puckette, therefore, aims to a certain stylistic neutrality, which he represents by the way in which the user opens the program: a blank page: “no staves, time or key signatures, not even a notion of ’note,’ and certainly none of instrumental ’voice’ or ’sequence”’ <span class="citation" data-cites="DBLP:journals/comj/Puckette02">(Puckette 2002a)</span>. While acknowledging that even the ’blank page’ is a culturally loaded symbol referring to the use of paper in Western Art Music (much in the same way that it is favoring complexity in the above described design), Puckette reconfigured computer music design, composition, and performance with great conscience on the way in which the structure of the program resonates aesthetically.</p><h5 id="computer:datastructures">Data structures for graphic scores</h5><p>Puckette also implemented a feature within Pure Data to enable the creation of graphic scores for electronic music <span class="citation" data-cites="DBLP:conf/icmc/Puckette02">(Puckette 2002b)</span>. In order to do this, he contextualized his research with the SSSP original project to include graphic scores within the composition environment, the <em>Animal</em> project by Lindemann and de Cecco which allowed users to “graphically draw pictures which define complex data objects” <span class="citation" data-cites="DBLP:conf/icmc/Lindemann90a">(Lindemann 1990)</span>, and three other cases of graphic scores used to model electroacoustic music: Stockhausen, Yuasa, and Xenakis. Puckette’s data structures derive from those of the C programming language, and they can be used in relation to any type of data. Following his notion of neutrality within musical style, he resolved in avoiding graphic predeterminations, namely, the fact that the <span class="math inline"><em>x</em></span>-value within the graphical canvas is left unlinked with time, without intervening in the user’s conception of time. Despite this significant programming decision, Puckette provided the user with a sorting function, “on the assumption that users might often want to use Pd data collections as x-ordered sequences” <span class="citation" data-cites="DBLP:conf/icmc/Puckette02">(Puckette 2002b)</span>.</p><h5 id="computer:rtcmix">RtCMIX and the heap</h5><p>In the same ICMC conference of 1997, two object-oriented languages were presented. Brad Garton and David Topper presented RTCMIX <span class="citation" data-cites="DBLP:conf/icmc/GartonT97">(Garton &amp; Topper 1997)</span>, a real-time version of the CMIX program by Paul Lansky. What they described as innovative in this project is, in a similar way to the data structures for time management that Puckette presented, the scheduling capabilities of the program. In contrast to the CMIX language, which assumes a non-realtime access of objects, the</p><blockquote><p>RTcmix event scheduling is accomplished through a binary tree, priority-queue dynamic heap…<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a> The heap is also designed to do “scheduling-on-the-fly,” allowing notes to be scheduled at run-time (usually triggered by an external event, such as a MIDI note being depressed). <span class="citation" data-cites="DBLP:conf/icmc/GartonT97">(Garton &amp; Topper 1997)</span></p></blockquote><p>What this means, virtually, is that the real-time problem became a scheduling problem of computing tasks. However, in the case of RtCMIX, the instruments that are instantiated “on-the-fly” can also establish their own TCP/IP connection sockets in order to allow for networked access to the individual synthesizers <span class="citation" data-cites="DBLP:conf/icmc/GartonT97">(Garton &amp; Topper 1997)</span>.</p><h5 id="computer:openmusic">OpenMusic</h5><p>The other object-oriented language was a visual programming environment for non-realtime composition called OpenMusic <span class="citation" data-cites="DBLP:conf/icmc/AssayagAFH97">(Assayag et al. 1997)</span>. While not a synthesis engine, the strength of this Lisp-based graphic language developed as a collaboration at IRCAM, resides in its ability to provide the composer access to a variety of sound analysis tools for composition <span class="citation" data-cites="icmc/bbp2372.2004.004 icmc/bbp2372.2010.129">(Bresson &amp; Agon 2004, 2010)</span>, as well as the possibility to generate algorithmic streams that output directly into a traditionally notated score. For example, OpenMusic introduced the concept of a <em>maquette</em>, which is a graphic canvas upon which a heterogenous set of elements as varied as audio waveforms, scores, or piano-roll type notation can be displayed.</p><h5 id="computer:kyma">Kyma</h5><p>Another powerful example is the case of an object-oriented language for music composition is Kyma <span class="citation" data-cites="DBLP:conf/icmc/Scaletti87">(Scaletti 1987)</span>. It was developed by Carla Scaletti at CERL in 1987, and it was intended to use as an interactive non-realtime composition environment with the Platypus digital signal processor. Scaletti’s language was hierarchical in its structure which, as I have described above, enabled the data records to be linked, that is, to be grouped vertically and horizontally. These data structures formed together objects, enabling the composer to treat as objects any set of sounds within the composition, starting from the composition itself as an object. In such a way: “…the composer could create a ‘sound universe,’ endow the sound objects in this universe with certain properties and relationships, and explore this universe in a logically consistent way” <span class="citation" data-cites="DBLP:conf/icmc/Scaletti87">(Scaletti 1987, p. 50)</span>” Therefore, and given the “vast amounts of data required for sound synthesis” <span class="citation" data-cites="DBLP:conf/icmc/Scaletti87">(Scaletti 1987, p. 50)</span>, the overall concept of Kyma was to fit the conjunction of timbre creation and temporal event lists into the same traversable database that the program proposed. What is important, however, is Scaletti’s intention. In much the same way as Puckette, for Scaletti “the language itself would not impose notational or stylistic preconceptions” <span class="citation" data-cites="DBLP:conf/icmc/Scaletti87">(Scaletti 1987, p. 50)</span>.</p><h5 id="computer:cypher">Cypher</h5><p><span class="citation" data-cites="Row92:Int">Rowe (1992)</span>’s interactive music system <em>Cypher</em> is an object-oriented program aimed at machine listening and composition in real-time <span class="citation" data-cites="Row92:Int">(Rowe 1992)</span>. It is constituted by two MIDI -based interconnected agents, a <em>listener</em> and a <em>player</em>. The player outputs musical material that results from generative or transforming processes on the (machine) listened input. The listener interprets incoming streams of MIDI data with MIR techniques (central pitch detection, beat tracking, among others) grouping <code>Note</code>s into larger <code>Event</code>s, and then into larger musical phrases. Both <code>Note</code> and <code>Event</code> are objects with specific data structure: the former closely linked to the MIDI message, the latter forming a circular linked list that enables traversing between neighbouring <code>Event</code>s. Attached to these <code>Event</code>s, however, reside intermediary agents that each store musical information that is locally relevant to the parent <code>Event</code>. The attached information, therefore, is fundamental to the system: “The feature space representation …tends to treat parameters of the sound-pressure waves carrying musical percepts as central. Register, loudness, and density are all primary components of the representation” <span class="citation" data-cites="Row92:Int">(Rowe 1992 Chapter 7)</span>. This constitutes Rowe’s implementation of the object-oriented model. Upon deciding which analytical model to apply to the <em>listener</em> agent, however, Rowe finds a coexistence of two virtually opposing models for music analysis: a hierarchical one (Shenker, Forte, Lerdahl) and a networked one (Narmour). While extending an analysis of database models to music theory is beyond the scope of this study, it is interesting to note how the versatility of the object model can integrate two very different ways of thinking musical relationships: “Cypher’s listener and player are organized hierarchically, though these hierarchies tend toward Narmour’s network ideas rather than the more strictly structured trees of Lerdahl and Jackendoff” <span class="citation" data-cites="Row92:Int">(Rowe 1992 Chapter 4.3)</span>.</p><h5 id="computer:supercollider">SuperCollider and nodes</h5><p>The literature on computer music software for composition alone would extend beyond the scope of this dissertation. However, there are important features to acknowledge from yet another object-oriented language for music synthesis that was developed at the end of the 1990s, namely, James McCarntney’s SuperCollider <span class="citation" data-cites="DBLP:conf/icmc/McCartney96 DBLP:conf/icmc/McCartney98">(McCartney 1996, 1998)</span>. This high-level language provides the user with a different paradigm to handle audio processes, their ordering, and —most importantly— their switching. The innovation that this language implemented is the “garbage collection” of each process. McCartney took the hierarchic structure of the object-oriented paradigm and defined ‘nodes’ in a tree-like structure, each with its own capability of nesting groups of other nodes, but most importantly, with its own initial and expiration times. In other words, in contrast to the constantly running audio processes that Pure Data and MAX/MSP , SuperCollider only consumes CPU resources whenever it needs to. This economy of resources that is enabled by the data structure of the language, together with its high-level quality, make it quite remarkable.</p><p>For further reference in other sound synthesis data structures, see: the Diphone synthesis program <span class="citation" data-cites="DBLP:conf/icmc/RodetDP88 Rodet1989 DBLP:conf/icmc/DepalleRGE93 DBLP:conf/icmc/RodetL96 DBLP:conf/icmc/RodetL97">(Caraty et al. 1989, Depalle et al. 1993, Rodet et al. 1988, Rodet &amp; Lefèvre 1996, 1997)</span>; FORMES <span class="citation" data-cites="DBLP:conf/icmc/BoyntonDPR86">(Boynton et al. 1986)</span>; the Otkinshi system <span class="citation" data-cites="icmc/bbp2372.2002.039">(Osaka et al. 2002)</span>. For an overview of existing audio software up to 2004, see Xamat’s PhD Dissertation <span class="citation" data-cites="Amatriain/2004/phdthesis">(Amatriain 2004 Chapter 2)</span>. See also the Integra project <span class="citation" data-cites="Bullock2009 Bullock2011">(Bullock &amp; Coccioli 2009, Bullock et al. 2011)</span>, Ariza’s work on python’s data structures <span class="citation" data-cites="Ari05:Ano">(Ariza 2005a)</span>, and Rowe’s <span class="citation" data-cites="Row92:Int Row01:Mac">(Rowe 1992, 2001)</span></p><h3 id="applications">Applications</h3><p>It is important to point to, at this point, that one of the central concepts of the object-oriented programming is extensibility. The list of objects that can be added to the main program tends to grow exponentially as a function of its use. Furthermore, for open-source programs like Pure Data and Supercollider the case is more extreme, since every user has access to the source code. Thus, a list covering all extensions would require a research project of its own. However, I would like to focus on those extensions that enable further and more specific use of databases in the context of music composition. In addition to program extensions, I will also provide some examples of the artistic possibilities that the type of data structure access that is provided to composers by means of computer music software sets forth. The following examples provide a glimpse of the major trends.</p><h4 id="applications:synthesis">Sound Synthesis</h4><p>Diemo Schwarz developed the concept of data-driven concatenative sound synthesis in his PhD thesis at IRCAM <span class="citation" data-cites="Schwarz2000 icmc/bbp2372.2003.099 Sch06:How">(Schwarz 2000, 2003, 2006a)</span>: “Concatenative sound synthesis methods use a large database of source sounds, segmented into units, and a unit selection algorithm that finds the units that match best the sound or musical phrase to be synthesised, called the target” <span class="citation" data-cites="Sch06:How">(Schwarz 2006a)</span>. In contrast to rule-based approaches in which sound synthesis is arrived at by models of the sound signal, concatenative synthesis joins together recorded samples thus preserving even the smallest details of the signal. Scwharz designed CATART as a concatenative synthesis toolkit <span class="citation" data-cites="Sch06:Rea">(Schwarz 2006b)</span>, and later contextualized information space as a musical instrument <span class="citation" data-cites="Schwarz:2012">(Schwarz 2012)</span></p><p>Ryoho Kobayashi <span class="citation" data-cites="icmc/bbp2372.2003.052">(Kobayashi 2003)</span> used a database of STFT analysed sounds in a very original way. Upon calculating the distances between the results of these analysis he was able to define a database of similarity between his original database which he then re-synthesized. Kawahara <span class="citation" data-cites="Kawahara:2004">(Kawahara et al. 2004)</span> demonstrated the morphing techniques of his software STRAIGHT <span class="citation" data-cites="icmc/bbp2372.1999.411">(Katayose &amp; Kawahara 1999)</span> by analysing the RWC database, which will be mentioned below.</p><p>Christopher Ariza <span class="citation" data-cites="icmc/bbp2372.2003.030">(Ariza 2003)</span> was able to implement a model for heterophonic texture by pitch-tracking the highly ornamented music of the Csángó<a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a> music into a database that enabled him to present a data structure of the ornament. While not strictly used as computer synthesis, his implementation of analysis and subsequent algorithmic rule extraction can be thought of as a form of analysis-based sound generation.</p><h4 id="applications:navigation">Navigation</h4><p>Insook Choi <span class="citation" data-cites="icmc/bbp2372.2000.146">(Choi et al. 2000)</span> designed an interactive installation at the Dorsky Gallery in NYC, in which she prototyped a “sensory information retrieval system where the acquisition of information is an acquisition of an experience” <span class="citation" data-cites="icmc/bbp2372.2000.146">(Choi et al. 2000)</span>.<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a> By creating what she termed a <em>sensorial network</em> made out of a database of semantic units describing speeches by famous leaders, she enabled participants of the installation to explore the information space of the database of audio recordings by walking. A motion tracking system using computer vision enabled the users to traverse the database, not in an event-triggering fashion (interpreting space as a boolean switch for each audio file), but in such a way that the sound was modulated as a function of the different ‘clouds’ of pixel data where gradually changing values as participants moved across the sensing area: “pixels do not switch on and off, they fade in and out forming clusters in the 2D camera plane according to the degree of movement projected from the corresponding floor positions” <span class="citation" data-cites="icmc/bbp2372.2000.146">(Choi et al. 2000)</span>. Furthermore, she included hysteresis, that is, the recorded history of the observer’s interaction with a system within the system, thus enabling condition-dependent events to occur as participants’ interaction lasted longer.</p><p>Robert Hamilton <span class="citation" data-cites="icmc/bbp2372.2006.123">(Hamilton 2006)</span> used bioinformatic data taken from galvanic skin sensors attached to a cellist’s toes within a live performance environment. The GSR activity was correlated with intervallic distance between adjacent musical notes in a score —i.e., a database of cell nodes: short fragments of pitch phrases— previously written by the composer. However, such score, according to Hamilton, acts as a “filter for the autonomic control signals generated by the performer” <span class="citation" data-cites="icmc/bbp2372.2006.123">(Hamilton 2006, p. 601)</span>. What this means is that the music fragment database, involuntarily navigated by the performer, becomes a parameter against which the live-generated and voluntarily performed score is eventually built upon.</p><p>Loviscach <span class="citation" data-cites="Loviscach2008">(Loviscach 2008)</span> proposed data mining of sound libraries for music synthesizers in order to obtain statistical analysis that was used for the creation of intelligent parameter settings. Christian Frisson <span class="citation" data-cites="Frisson2010">(Frisson et al. 2010)</span> managed to navigate a database by way of similarities between the elements using a very fast interface prototyped in Pure Data. Frisson’s PhD dissertation <span class="citation" data-cites="Frisson2015">(Frisson 2015)</span> provides an overview of multimedia browsing by similarity, and his approach in building a new multimedia manager is centered on open-source tools for audio and video information retrieval. Cartwright and Pardo <span class="citation" data-cites="mcartwright:2014">(Cartwright &amp; Pardo 2014)</span> implemented querying of a database of computer synthesizer parameter presets by vocal input, enabling users to mimic sounds with their voices in order to obtain the parameter setup needed for the synthetic instrument to generate a similar sound.</p><p>Park et al <span class="citation" data-cites="icmc/bbp2372.2010.002">(Park et al. 2010)</span> created an interface called <em>COMPath</em><a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a> (Composition Path) which enabled users to draw paths on a map, sonifying data points which represented information (e.g., traffic, weather, culture events) along the points of the path. They used major commercial web services (e.g, Amazon, Google, and Yahoo) offering public <span data-acronym-label="api" data-acronym-form="plural+short">apis</span> so that each geo-location inputted on the path acted as queries. The returned data from these services was then mixed together (<em>data mashup</em>) and mapped with a virtual synthesized via MIDI .</p><p>William Brent’s research on timbre analysis <span class="citation" data-cites="Brent/2010/phdthesis">(Brent 2010a)</span> developed into a timbre description library for Pure Data called <em>timbreID</em> <span class="citation" data-cites="icmc/bbp2372.2010.044">(Brent 2010b)</span>. Within this library users are able to analyze sound files using most available timbre descriptors. In his dissertation, for example, he explored the relationships between perceptual dimensions of percussive timbre and those obtained by the timbre description algorithms in <em>timbreID</em>. He concluded that in order to identify percussion timbres, the BFCC performed on multiple successive analysis windows was the most efficient way to do so. Thus, a database of percussive sounds could be navigated by performing this type of analysis, enabling a fast and CPU -inexpensive content-based querying. Brent’s <em>timbreID</em> library, however, since it enables users not only to analyze sounds but to gather descriptors into clusters within a database, allows for much more applications, one of them being concatenative synthesis.</p><h4 id="application:performance">Performance</h4><p>Melucci and Orio <span class="citation" data-cites="icmc/bbp2372.1999.355">(Melucci &amp; Orio 1999)</span> proposed a musical information retrieval system aimed at query-by-content navigation of a musical collection based on melodic segmentation. In their research, they implemented a LBDM to perform the automatic segmentation of melodic information taken from MIDI files of Baroque, Classic and Romantic music. They then proceeded to normalize and index the melodic phrases into separate files for querying.</p><p>Hugues Vinet’s CUIDADO project, which developed into the <em>Semantic Hi-Fi</em> system at IRCAM <span class="citation" data-cites="DBLP:conf/ismir/VinetHP02 DBLP:conf/icmc/VinetHP02 DBLP:conf/icmc/Vinet05">(Vinet et al. 2002a,b; Vinet 2005)</span>, consists of a database system aimed at content-based querying of audio files. Vinet’s project enabled <span data-acronym-label="dj" data-acronym-form="plural+short">djs</span> to browse through files, apply beat-synchronized transitions between them, and many other automated tasks during performance. Gerard Assayag and Shlomo Dubnov’s OMAX was another IRCAM project dedicated to realtime co-improvisation. This project was based on a dictionary “universal prediction algorithm that provides a very general and flexible approach to machine learning in the domain of musical style” <span class="citation" data-cites="DBLP:conf/icmc/AssayagDD99">(Assayag et al. 1999)</span>. OMAX later was extended to video and audio features <span class="citation" data-cites="DBLP:conf/icmc/BlochD08">(Bloch &amp; Dubnov 2008)</span></p><p>Norman and Amatriain <span class="citation" data-cites="icmc/bbp2372.2007.117">(Norman &amp; Amatriain 2007)</span> developed a performance oriented interface called <em>Data Jockey</em>. It consisted of a software with an integrated capability to generate databases of audio file descriptors, together with beat recognition and synchronization, that the user could query by content, tags or metadata. Nakamoto and Kuhara <span class="citation" data-cites="Nakamoto2007">(Nakamoto &amp; Kuhara 2007)</span> deviced a networked performance system using a MYSQL database to store and retrieve vocal parts enabling users to sing together in canon form. Price and Rebelo <span class="citation" data-cites="Price2008">(Price &amp; Rebelo 2008)</span> developed an installation that consisted of an interface to a database of percussive sounds. In their project, they used a MAX/MSP library called <em>net.loadbang-SQL</em> to query and import data for the communication with SQL databases. This database contained information from some audio descriptors such as The brightness (spectral centroid), noisiness, and loudness of the beginning of each analyzed sound file. In this way, the users were able to navigate a bank of percussion timbres based on basic spectral content.</p><p>Price and Rebelo had based their research on the concepts set forth by the Semantic Hi-Fi project (described above), and on Casey and Grierson’s <em>SoundSpotter</em> <span class="citation" data-cites="DBLP:conf/icmc/CaseyG07">(Casey &amp; Grierson 2007)</span>, the latter a software system dedicate to real-time matching of audio or video input. The underlying concept of <em>SoundSpotter</em> was that of audio input as control, that is, given the spectral similarities between the incoming signal from a microphone, a database of audio segments was navigated. In other words, the user selected fragments of a large bank of audio files by means of sound. This approach, paired with a very low latency engine that, provided real-time capabilities. The innovation of their approach resided in a joint use of a similarity matching technique called audio shingling<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a> with LFCC for pitch information.</p><p>Benjamin Carey <span class="citation" data-cites="Carey:2012">(Carey 2012)</span> integrated a database within a real-time improvisation system designed in MAX/MSP . Liu et al <span class="citation" data-cites="Liu:2013">(Liu et al. 2013)</span> created an audiovisual environment for live data exploration. They implemented simultaneous sonifications and visualizations of networked database queries made by participants using IOS devices. Carthach, Jorda and Herrera <span class="citation" data-cites="Nuannicode225in2016">(Nuanàin et al. 2016)</span>, for example, implemented a model for real-time rhythmic concatenative synthesis. Vogl and Knees <span class="citation" data-cites="rvogl:2017">(Vogl &amp; Knees 2017)</span> trained a computer model using a database of commercially available drum rhythm patterns in order to provide an intelligent algorithm for the variation of drum patterns intended for EDM .</p><h4 id="application:gesture">Gesture</h4><p>Schoner et al <span class="citation" data-cites="DBLP:conf/icmc/SchonerCDG98">(Schöner et al. 1998)</span> proposed an intermediate synthesis technique between sampling and physical modeling, by training a compute model with sensor data of a violin performer paired with its respective sound signal. The resulting data-driven inference was carried out by CWM , a technique “based on probability density estimation of a joint set of feature (control) and target (spectral/audio) data” <span class="citation" data-cites="DBLP:conf/icmc/SchonerCDG98">(Schöner et al. 1998)</span>. Kawahara’s above mentioned STRAIGHT system <span class="citation" data-cites="icmc/bbp2372.1999.411">(Katayose &amp; Kawahara 1999)</span> utilizes sensor data —such as breath input, head movement, and finger positioning— so as to enhance the sound analysis engine of the system, thus achieving more degrees of freedom when carrying out the sound synthesis. At CCRMA , Serafin et al <span class="citation" data-cites="icmc/bbp2372.2001.071">(Serafin et al. 2001)</span> managed to invert the concept of physical modeling by estimating violin bow position, pressure, and speed using LPC coefficients of violin audio recordings.</p><p>Schloss and Driessen <span class="citation" data-cites="icmc/bbp2372.2001.103">(Schloss et al. 2001)</span> used audio analysis to obtain gesture features from the non-audio signals obtained from the Radio Drum<a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a> —such as peak detection for determining mallet strokes. Later, Jones, Lagrange, and Schloss <span class="citation" data-cites="DBLP:conf/icmc/JonesLS07">(Jones et al. 2007)</span> created a dataset of hand drumming gestures using data from a two-dimensional pressure sensor that could be compared to the membrane of a drum. Their intention was to provide physical model designers with a collection of six techniques of hand drumming, recorded as matrices at a slow rate (100 Hz, the maximum rate of the sensor) suitable for non-realtime synthesis by way of interpolation into a waveguide<a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a> mesh.</p><p>Andrew Schmeder <span class="citation" data-cites="icmc/bbp2372.2009.005">(Schmeder 2009)</span>, stemming from the research at CNMAT on the OSC format, proposed a POSTGRESQL database for efficient storage and retrieval of gestural data aimed for real-time application. Schmeder’s paper presents a technical overview of database practices, focusing on relational databases.</p><p>Young and Deshmane <span class="citation" data-cites="Young2007">(Young &amp; Deshmane 2007)</span> created a web-accessible database of gestural and audio data concerning violin bow strokes. Hochenbaum, Kapur and Wright <span class="citation" data-cites="Hochenbaum2010">(Hochenbaum et al. 2010)</span> developed a gestural and audio joint database that enabled identification of a given performer between a group of performers, gaining insight on musical performance itself. Caramiaux, Bevilacqua and Schnell <span class="citation" data-cites="Caramiaux2011">(Caramiaux et al. 2011)</span> succeeding in proposing a query-by-content type of database navigation by way of gestural input. They used gesture-to-sound matching techniques based on the similarities of temporal evolution between the gesture query and the sound target. Garcia et al <span class="citation" data-cites="Garcia2011">(Garcı́a et al. 2011)</span> constructed a multimodal database of sound and sensor data —e.g., blowing pressure on a recorder— for the purpose of designing a synthesis model for recorders with different blowing profiles. Visi et al <span class="citation" data-cites="fvisi:2017">(Visi et al. 2017)</span> also designed a multimodal database, using sensor information from listening subjects who were asked to move as if creating the sound, resulting in an innovative way to train a computer model for gestural-based synthesis.</p><h4 id="application:sharing">Resource Sharing</h4><p>Important research has been done in file formats suitable for data interchange. For example, the SDIF and the GDIF , widely used in audio analysis software like SPEAR , OpenMusic <span class="citation" data-cites="icmc/bbp2372.2004.004">(Bresson &amp; Agon 2004)</span>, among others. Bresson and Schumacher <span class="citation" data-cites="icmc/bbp2372.2004.004">(Bresson &amp; Agon 2004)</span> used SDIF format for the encoding and interchange of spatialization data. Bullock and Frisk <span class="citation" data-cites="icmc/bbp2372.2009.012">(Bullock &amp; Frisk 2009)</span> implemented within their Integra project a data format for sharing between different multimedia environments. Based on previous work on file formats<a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a>, they developed the IXD format which is capable of containing sequences, tags and meta-data, and presets. Their argument for an XML format resided in the semantic richness that can be allocated in opposition to the binary format only readable by machines.</p><p>Roberts et al <span class="citation" data-cites="croberts:2014">(Roberts et al. 2014)</span> implemented within Gibber (a real-time live coding web-based environment) a centralized database for the storage and quick access of digital instruments that can be prototyped in the environment. Taylor et al <span class="citation" data-cites="btaylor:2014">(Taylor et al. 2014)</span> also implemented a centralized database within their platform for mobile-device performance, so that user-created interfaces could be saved and shared. Xambó et al <span class="citation" data-cites="nime18-Xambo-b">(Xamb et al. 2018)</span> provided a live coding system within SuperCollider to enable access to CC sound databases, such as FREESOUND or user-made databases, enabling content-based querying by pitch or tapping.</p><h1 id="chapter:Database_Aesthetics">Database Aesthetics</h1><p>Delineating the agency of the Database in the practice of music composition, I discuss the aesthetics of Database Music, developing the concepts of listening, memory, and performance.</p><p>First, I analyze the extent to which the Database can be a listening subject which promotes illusions of style and authority. I consider style and authority as central aspects of the sphere of aesthetic agency of the Database. I then focus on a form of collective ‘listening’ and I arrive at my conception of the Database as an inherently deterministic system. This system is shaped as a network of nonhuman agents, whose ‘resonance’ is fundamental to its definition. I use this resonant network to further analyze the agency of the Database, in terms of how authorial qualities percolate through the network. I use Jean-Luc Nancy’s ontology of sound to understand how the database can be a listening subject. In Brian Kane’s reading <span class="citation" data-cites="Gra15:The">(Gratton &amp; Morin 2015, pp. 143–44)</span> of Nancy’s work <span class="citation" data-cites="Nan07:Lis">(Nancy 2007)</span>, he presents the this ontology —i.e., what Nancy calls <em>resonance</em>—, considering it as a process constitutive of a phenomenology of the self.</p><p>Second, in order to narrow the gap between human and nonhuman agency, I assess the extent to which computer memory resembles human memory. On the one hand, I compare memory and writing with digital information storing, and thus arrive at databasing as a form of memory. On the other hand, I consider archives as collective memory, which serves to to explain how the Database can also be a form of collective memory.</p><p>Finally, I focus on the performativity of the database. On the one hand, I claim that the database is gendered. I argue that the notion of ‘style’ is what promotes the illusion of a gendered subject in the Database. I argue that since both the performance and the directionality of the ‘styling process’ remain strictly on the virtual skin of the database, the database’s authorial subject, like the gendered self, remains in the spectrum of the illusory. On the other hand, I claim that the limit of the Database resides on its performativity. I consider the technical aspects of databases and define computer systems as networks of interconnected-but-independent databases. This definition serves to extend the performatic limit of databases to computers, and therefore to link the performance of the database to the performance of the computer. My goal in this final section is to lead the way to the connection between Database performance and Music Composition: the performatic limit of the Database is also the limit of Music Composition.</p><p>In search of understanding the political in Database and Composition practices, I question the established concept of music composition and arrive to new definitions of the music work, practice, and authorship.</p><p>First, I consider the concepts developed in the previous chapter to understand Music Composition as Database Performance. I propose that the ontology of Composition needs to be redefined in terms of the agency of the Database. My goal in this section is to reveal that the Database agency, when contextualized within Music Composition, has the form and the politics of a music listening to itself.</p><p>Second, I use Nancy’s concept of inoperativity to redefine the music object. I argue that the inoperativity of the listening experience, which resides on the delay between sense and sensuality, provides insight on the type of unworking that affects music composition. I thus redefine the outcome of music composition as the <em>severed music object</em>, emphasizing its inoperative status of suspension, withdrawal, and its inherent state non-completeness. I then consider how this state of suspension of the severed music object can be analyzed in terms of a Community of artists, database performers, composers, etc., mutually exposed to each other (Nancy 1991). Therefore, in order to understand the dynamics of this transversal community of Database and Composition, I analyze the paradox of anarchy and reflect on the consequences of both the anarchic and the inoperative in Database and Composition practices.</p><p>Finally, I present my view on collaboration, and propose a redefinition of the term uprooting it from the traditional union of forces forming a whole. I claim that the new form of collaboration can be understood as a form of collective, or <em>trans-inoperation</em>, consisting in the mutual exposure of the limits of singular, performing beings. As a consequence of this form of collective inoperance, I claim that a new politics of authorship needs to be analyzed, particularly in terms of the spectral in the Database. I question the power of this illusory figure in terms of the effectiveness of the archontic principle that is present in <em>trans-inoperant</em> works of art. I believe the specter of the author loses the sensuality and the sense of the listening subjects in state of trans-inoperance, and thus the power of the author ceases to take place.</p><h2 id="section:Listening_Databases">Listening Databases</h2><h3 id="resonance_of_a_return">The Resonance Of A Return</h3><blockquote><p>To be listening is thus to enter into tension and to be on the lookout for a relation to self: <em>not</em> it should be emphasized, a relationship to ‘me’ (the supposedly given subject), or to the ‘self’ or the other (the speaker, the musician, also supposedly given, with his subjectivity), but to the <em>relationship in self</em>, so to speak, as it forms a ‘self’ or a ‘to itself’ in general, and if something like that ever does reach the end of its formation. Consequently, listening is passing over to the register of presence to self, it being understood that the ‘self’ is precisely nothing available (substantial or subsistent) to which one can be ‘present,’ but precisely the resonance of a return [<em>renvoi</em>]. <span class="citation" data-cites="Nan07:Lis">(Nancy 2007, p. 12)</span></p></blockquote><h5 id="sonorous-presence">Sonorous presence</h5><p>Jean-Luc Nancy <span class="citation" data-cites="Nan07:Lis">(Nancy 2007)</span> brings forth an ontology of sound that is based on the performativity of listening. Linking an embodied theory of listening with a phenomenology of the self, this ontology begins by defining the ‘sonorous presence.’ For Brian Kane <span class="citation" data-cites="Gra15:The">(Gratton &amp; Morin 2015)</span>, Nancy’s ‘sonorous presence’ is given by the combination of both the listening body as being part of the medium and the body’s sense perception linked to that medium. I understand medium here as the transmission medium upon which sound propagates, such as a space filled with gas, liquid, or solid particles of matter. Under this definition, all bodies are part of media, that is, both human and nonhuman bodies. Sound reaches, enters, and traverses bodies within media. Thus, for Nancy, sound immerses all bodies within itself. This means that sound includes all bodies within its oscillation, making listeners vibrate. Therefore, the listening subject, understood as the one that is listening (a singular listener) is always already part of sound.</p><h5 id="an-a-priori-filter">An a priori filter</h5><p>In being already part of sound, bodies change sound even before listening. On a mechanical level, the body is an a priori physical filter. Sound is filtered differently and uniquely within each body: my body changes the incoming sound for me, just as well it does for others. For instance, a longitudinal wave passing through a body affects how it will arrive at other points in space. Sound propagation is conditioned by the qualities of the medium. That is to say, while the combination of density, pressure, temperature, and motion affect its speed, viscosity within media affects its attenuation rate. This means that within hot and humid climates sound will move slower, and if there is wind blowing in the same direction of a sound it will travel faster. What is important here, is that this also means the listening body changes how sound moves both inside and outside of itself. On the one hand, bodies filter sounds towards one another. On the other, even before longitudinal waves reach the tympan, the same body already affects their movement. Waves change direction by way of reflection or refraction, and they fade out by way of attenuation. This means that waves are affected in different ways according to different media, some being more (concert halls) or less reflective (anechoic chambers). Since the listener’s body itself refracts, reflects, and attenuates waves, the singular filter that is the body changes wave propagation not only for itself and its own listening experience, also for the listening experience of other subjects in different places in space. This explains why empty concert halls sound more reverberant than filled concert halls.</p><h5 id="sonorous-presence-in-an-attack">Sonorous presence in an attack</h5><p>Sonorous presence, therefore, can be understood as follows. Since listeners are singularities in the presence of sound, and since sound itself is the singularly exposed presence, the sonorous presence is an exposition of an in-between-ness, or a resonant state of a self being exposed to itself and to one another. The experience of this exposure, however, points to the presence of sound as a sensing experience in itself (the body listening to itself listen), and not to what a given sound might signify. As Kane writes, to be listening in the sonorous present constitutes “a mode of listening that exposes itself to sense” <span class="citation" data-cites="Gra15:The">(Gratton &amp; Morin 2015, pp. 143–44)</span>. This means that in the sonorous present, the listening body emerges as a creation of itself as sense. Therefore, in the sonorous present the first image is that of the body. In this sense, the body is given form by itself: it is self-in-formed during the sonorous present. Furthermore, the duration of this sonorous presence is none other than an instant, or what Nancy refers to as an ‘attack.’ All mechanical waves require an initial energy input. In the case of sound, particularly in musical contexts, this input is generally referred to as attack. Nancy, however, takes this notion of the attack to another plane. He refers to it as the exact moment when a sound arrives and simultaneously leaves the body: the instantaneous appearance of sound within the body. An attack therefore instantiates the sonorous presence.</p><h5 id="referrals-and-deferrals">Referrals and Deferrals</h5><p>The structure of the listening experience is one of infinite referrals and deferrals.<a href="#fn28" class="footnote-ref" id="fnref28"><sup>28</sup></a> Inasmuch as the sensing body is aware of its own multiplicity of sense, this multiplicity is itself dislocated spatially and temporally. Thus, the distances in both time and space, between all points of the listening experience, of the singular listener and the plurality of listeners, create a web of references that is instantiated in the attack of the sonorous presence. By way of listening, Nancy approaches the notion of meaning. That is to say, for him, meaning “is made of a totality of referrals: from sign to a thing, from a state of things to a quality, from a subject to another subject or to itself, all simultaneously” <span class="citation" data-cites="Nan07:Lis">(Nancy 2007, pp. 4–9)</span>. Therefore, since sound “is also made of referrals: it spreads in space, where it resounds while still resounding ‘in me’’ <span class="citation" data-cites="Nan07:Lis">(Nancy 2007, pp. 4–9)</span>, the result is an understanding of listening as a process that intertwines sense and signification. As a consequence of meaning within the listening experience, the self comes along resounding, emerging out of a resonating plurality.</p><h5 id="a-loop">A Loop</h5><p>The condition of repetition, oscillation, or circularity explains the ‘infinite’ quality that Nancy gives to the structure. To put this differently, the constant oscillatory motion that is present throughout the listening experience has the structure of a feedback circuit, or a loop. For example, I listen to myself as resonant subject, while creating meaning from a certain quality of a sound. I do this in simultaneity with another subject, who is also creating itself while giving meaning to other sound waves. In listening, the vibrating link in between ourselves is also simultaneously changing the way we are listening. Thus, every singularity is in a state of being exposed to one other, that is, in resonance or in touch with on other. Within this loop, not only sound enters and leaves the body, also the sensing body and the resonant self emerge and re-emerge infinitely. Therefore, this infinitude becomes the presence of the self, in the sense that the self becomes present to itself.</p><h5 id="an-approach-to-self">An Approach to Self</h5><p>It is important to note that the self resonates to itself coming <em>in</em>. This must be distinguished from the self understood as an expressive substance inherent to bodies, or already <em>in</em> the body, as if it were some originary essence that appears out of resonance. Quite the contrary, for Nancy, the phenomenality of the self comes as a result of the resonance, in the form of a return. In other words, the self is something that appears to itself, at the limit of itself, very much like sound does. This is why, for Nancy, to be listening [<em>être à l’écoute</em>] engages resonant subjects with an approach to self. This approach, however, is neither to the self, not to the self of another, but to the structure of resonance as understood in terms of a <em>relationship in self</em> from itself. The quote at the beginning of this section (“if something like that ever does reach the end of its formation”) points precisely to the infinite resonant process with which Nancy builds his concept of listening, but specifically, it is how he sets forth an image of a self coming from this ontology of sound.<a href="#fn29" class="footnote-ref" id="fnref29"><sup>29</sup></a></p><h3 id="network">Resonant Network</h3><blockquote><p>…there is an actor whose definition of the world outlines, traces, delineate, limn, describe, shadow forth, inscroll, file, list, record, mark, or tag a trajectory that is called a network. <em>No net exists independently of the very act of tracing it, and no tracing is done by an actor exterior to the net. A network is not a thing but the recorded movement of a thing</em>. [emphasis added] <span class="citation" data-cites="Lat90:On">(Latour 1990, p. 14)</span></p></blockquote><p>Nancy’s resonance points to instrumental music listening, specially because of his references to composers like Wagner or Berlioz. However, the case of listening to music with computers can also be understood together with Nancy’s resonance. The same principles apply, namely because of the practice of sound recording and reproduction, and how it was developed to replicate wave conditions by way of transducers. In other words, considering modern transducers and digital technology only, sound waves can be reconstructed in such a way that the illusion of sources that are physically absent in one place, can be felt as if they were exciting the medium and body without much complications. This fact alone brings out a plethora of concepts that have been widely accounted for in the literature. However, in order to account for the presence of the database within listening, I focus here on one way of understanding Nancy’s resonance that comes from Bruno Latour’s actor-network theory <span class="citation" data-cites="Lat90:On Lat93:We">(Latour 1990, 1993)</span>.</p><h5 id="an-illusory-violin">An Illusory Violin</h5><p>Consider, for example, an acousmatic concert in which one of the music works is made with pre-recorded violin samples. Thus, when this violin begins playing sounds, an illusion may very well begin to emerge, that is, as listeners, we can imagine a violin player. Furthermore, if the imaginary player continues to play sounds and move them in space, this illusion continues in the direction of physical but illusory motion <em>in-space</em>, that is, a virtual perception of an actual violin, and an actual violin player. Therefore, this virtuality may very well project itself throughout the complete music work, thus grounding the music work on an imaginary force that is only alive because of the listener’s virtuality. The ghostly qualities of this force will be addressed further down this text (See <a href="#spectrality" data-reference-type="ref" data-reference="spectrality">5.2.4</a>). Most presently is the fact that this magic show —happening in front and because of the listener’s body-sensing mind— can be understood in terms of a resonating linkage between the human and the nonhuman: a network of interconnected objects that refer to each other.</p><h5 id="virtuality">Virtuality</h5><p>As I described in earlier sections, virtuality is our brain’s capacity to create images from the world. In listening, the virtuality of the human mind engages with the attack of the sonorous presence, and with the relationship in self. Therefore, the body listening to itself listening results not only in the self-image of the body, it also creates an image of the listened to the point of embodying a violin player altogether. That is to say, the illusory violin, however imaginary, can be listened to and, thus, it can enter into the infinite game of resonance. In this listening process, therefore, the listening subject exposes itself to itself and to the ‘virtual’ self of the violin. The ‘virtual’ in this context does not mean in opposition to the real. Quite the contrary, the virtual comes as the affective presence of the real, and it becomes the possibility condition for the reality of images. From this, it follows that the self is already an image of itself and, as such, it is a virtuality that comes out of the process of listening.</p><h5 id="performativity-of-networks">Performativity of Networks</h5><p>Latour understands ‘networks’ as made of interconnected frames of reference. He refers to these frames as ‘semiotic actors’ as well as their accounts of each other. In this sense, the network is comprised entirely of motion and activity. The performativity of semiotic actors is the network’s very own movement reflected back onto itself. That is to say, the network itself is the set of links that are being established as nodes, and these nodes are in constant reference to each other. Within a universe of actors, or what Latour calls ‘ontological hybrids’, or world-making <em>etceteras</em>, only meaning and connectivity is present, and there is nothing that falls outside the network. The network encompasses its own actors and its own performance. Thus, performance is the defining gesture of networks. Latour’s actor-network theory, therefore, is a way of thinking the complex ways in which things are connected between each other. It is an image of a world made out of ontological hybrids which constitute the bare nodes on a decentralized web of meaning. These actors/hybrids build their frames of reference by way of navigating from node to node, thus traversing a network. Within this network, the emphasis is placed on performativity.</p><h5 id="a-resonant-movement-of-a-thing">A Resonant Movement of a Thing</h5><p>Considering this concept of the network as one grounded on movement, and, precisely, on the movement of meaning, there exists the possibility of thinking this movement under the scope of Nancy’s ontology of sound. That is to say, given that sound is also composed of the oscillatory motion of particles in space, and, given that this structure of infinite referral and deferrals, then Latour’s phrase can be reformulated as follows: <em>the network is not a thing, but resonant movement of a thing</em>. Considering the concept of a resonating network of humans and nonhumans, the database not only enters as a node (semiotic actor) in the network, it enters as a resonating subject in its own right. If semiotic actors in Latour’s network are in constant reference to each other, it can be argued that they are in infinite resonance with each other, in a permanent state of vibration, or simply, <em>listening</em>. Therefore, these listening actors may be not only human, they are listening things that engage with resonance just as much as Nancy’s resonant subject. This is the crucial leap that comes out of the idea of a resonant network: the moment the nonhuman in the network is comprehended as resonating, it is the moment that they engage with an approach to self. In other words, when the database of samples used by our virtual violin begins to sound, it is not only being listened to by the audience in the hall, it also begins to listen to itself listening. When considering the database as a resonant subject in itself, the database is granted with creative agency. In other words, the database engages within an emergent (hybrid) community of the human and the nonhuman. Our virtual violin, made of samples in RAM , makes the network resonate while resonating itself to itself. The hierarchical links between the human and the non begin to disappear in favor of a multiplicity of edges in a networked condition of resonance.</p><blockquote><p>The surface ‘in between’ networks is either connected —but then the network is expanding— or non-existing. Literally, a network has no outside. <span class="citation" data-cites="Lat90:On">(Latour 1990, p. 6)</span></p></blockquote><h5 id="positive-feedback">Positive Feedback</h5><p>Connection and expansion are the mode of being of what I am calling resonant networks. Networks exist by the constant growth of their nodes and edges. Therefore, given the self-propagating quality of networks, the notion of a network unlinking itself until extinction is utterly impossible. Although it would be rational to think this way, the case of the network would imply that once a connection is disconnected, another new connection must refer to the unlinked status of the affected nodes. This new connection would, in turn, unfold a new set of connections into newer and yet unexpected directions. Therefore, a sharp distinction with sound arises: while the network is expanding in redundancy and self-reference, sound can be understood as a system that, by its very same propagation attenuates towards an imperceptible threshold. Notwithstanding the infinitesimal motion of media which prevents conceptualizing sound as fading into nothingness, the embodied presence of sound does fade away into a perceptual nothingness. In other words, coupling ‘resonant’ and ‘network’ results in a sort of positive feedback, that unless intentionally built into an electronic circuit serving that purpose, simply falls out of the mechanical aspect of waves. Thus, sonic entropy plays against network expansion.</p><h5 id="the-work-of-actors">The Work of Actors</h5><p>The notion of network is to a certain extent mathematical. The spatial metaphors that are generally used, such as “close and far, up and down, local and global, inside and outside,” come to be replaced by “associations and connections” <span class="citation" data-cites="Lat90:On">(Latour 1990, p. 6)</span>. For example, consider the case of a person writing on a laptop computer. The two actors (user, computer) have to perform what Latour calls “enormous supplementary work” <span class="citation" data-cites="Lat90:On">(Latour 1990, p. 6)</span>. While the computer has to display characters correlating glyphs to keys, the user has to visualize letters out of pixel data on screen. Therefore, the conjunction of the keyboard-to-character database with the user’s ability to create images out of a flickering lights results in an inverted proximity: letters on screen appear closer to the eyes than they are to the fingers. Distance and proximity are two concepts based on geography, a concept that within networks tends to give way to connectivity.</p><h3 id="inoperativity">The Unworking Network</h3><blockquote><p>Community necessarily takes place in what Blanchot has called ‘unworking,’ referring to that which, before or beyond the work, withdraws from the work, and which, no longer having to do either with production or with completion, encounters interruption, fragmentation, suspension. Community is made of the interruption of singularities, or of the suspension that singular beings are. Community is not the work of singular beings, nor can it claim them as it works, just as communication is not a work or even an operation of singular beings, for community is simply their being —their being suspended upon its limit. <em>Communication is the unworking of work that is social, economic, technical, and institutional</em>. [emphasis added] <span class="citation" data-cites="Nan91:The">(Nancy 1991, p. 31)</span></p></blockquote><p>The idea of <em>un</em>working relates to <span class="citation" data-cites="Nan91:The">Nancy (1991)</span>’s previous text <span class="citation" data-cites="Nan91:The">(Nancy 1991)</span>, on which he developed the idea of <em>in</em>operativity as the grounds for a theory of ‘community.’ Inoperativity and community are intertwined, and I will describe them in the following paragraphs.</p><h5 id="community-as-unwork">Community as unwork</h5><p>Referring to Maurice Blanchot’s concept of <em>desoevrement</em>, Nancy sets forth a concept of community that is based and depends on the notion of the inoperative. Nancy’s argument for the possibility of community to occur is grounded on a reconfiguration of the concept of work. Work within a community, understood by Nancy, comes to be a form of withdrawal. That is to say, in a community, withdrawal is a form of interruption and suspension of both production and product. Therefore, if work is understood as the means by which a community arrives at the production of any given product, then withdrawal comes to place this system of production into a halt. If the process of production was thus interrupted, the system of production leading to complete formation, and any idea of wholeness, or completeness, is truncated and never completed. Therefore, within this logic of production, if community itself is thought of as product, that is, as the objective of the community itself (the process which composes itself as process), then the concept of community is dismantled and broken. In other words, when community is thought of as work, the work of community can never be achieved, and community as its product can never exist. Nancy’s conclusion is that community can never result out of a work, but it is only something that unfolds as unworking. In this sense, the system of production is rendered inviable for a relation to exist between selves, and only an inoperative force can arrive at the common exposure of selves.</p><h5 id="resonant-inoperativity">Resonant Inoperativity</h5><p>Given that Nancy thinks of community as an exposure of selves towards one another, we can understand this movement of unworking as the movement of resonant networks. Furthermore, the exposure that occurs in listening can, in turn, allow a comparison between resonance and inoperativity. In this sense, the distance between the resonant subject and the sonorous presence becomes a limit upon which community is suspended. Nancy’s concept of resonance has two dimensions, one relating the body sensing itself and the other to the structure of infinite referrals and deferrals. On the one hand, the sonic medium encompasses the concept of resonance with those of exposure, immersion, and openness. Listeners are exposed to one another and in contact with themselves through the medium. Resonance exposes thus a liminality. This is also understood in terms of the reaching of the limits of the listening body. The listening subject exposing itself to a limit which comes as a form of sharing, exchange, and ultimately community.</p><h5 id="space-of-community">Space of Community</h5><p>This space of community is an exposure to fragmentation. Fragmentation, in this sense, means the inability for a thing to complete itself. The opening of a wound that precludes the unity. As the fragile, liminal state of fracture that this fragmentation points to, however, it maintains itself in suspension. That is to say, the contact that exists between selves is not conclusive. Therefore, if this touch, in the sense that touching permits being in common with the other, is the mark of community, it follows that it is impossible to arrive at it by means of a work. The concept of work comes from the necessity to finish things, to close objects, to sever a beginning and an ending out of a temporal and spatial continuum. The activity of work is aimed at effectively arriving at a result, applying certain effort for the purpose of a given task. Labor itself is both related to the application of forces and to creation itself, to giving birth. Art traditionally comes in the form of work. Community comes from the form of unwork.</p><h5 id="at-the-limit">At the Limit</h5><p>Nancy’s concept of community is exemplified by resonance and his later ontology of sound. Given the fact that the ontology of sound points to the distance between sense and signification, and, thus, to the emergence of a resonant subject during the sonorous presence, this distance can be thought of as suspended at the limit. A limit, in the sense that it constitutes an edge between two objects (actors). Using Nancy’s conceptualization of community, this limit exposes selves to themselves and to one another. Therefore, by understanding resonant networks in terms of community, the result is a resonant self-exposure of the human and nonhuman at the limit. Thus, the instance of inoperativity: because of this (resonant) suspension, there is no possibility for completion, only expansion. Within this quality of incompleteness, which relates to suspension, but also to fracture, fragility, instability, and unpredictability, is how the notion of community as product can never be realized.</p><h5 id="reticulated-skin">Reticulated Skin</h5><p>Since there is nothing outside of community, and, since there is only exposure, propagation, repetition, and expansion, there is room for thinking of the resonant network as an inoperative agent of community itself. What this amounts to is that the human and the nonhuman resonate as community. The human and the nonhuman unfold their relations towards each other, suspending themselves in between one another. This in-between-ness is not to mean a gap between selves, but their connectedness and the same network of associations and referrals that exists between them. To put this differently, this liminality can be thought of as a skin, not in the sense of a layer that separates the interior form the exterior of a body, or, for that matter, as a surface under which or over which two selves can connect. This skin is not a surface, but a texture; it is not a layer, but an interweaving of minuscular threads that, in their own locality are fragile, but in their state of being reticulated, expand into a redundancy of fragilities that prevent concepts such as unity, concentration, or purity, to enter into the picture. This constitutes Latour’s “material resistance argument,” for example, one that refers to the heterogeneous, disseminated, and careful “plaiting of weak ties” <span class="citation" data-cites="Lat90:On">(Latour 1990, p. 3)</span>.</p><h5 id="resistance-in-database-music">Resistance in Database Music</h5><p>The resistance of the skin represents, thus, the resistance of connectivity itself, that is, the resistance of a community. Therefore, by substituting, on one hand, the human with the database performer, that is, the database<em>r</em> and, on the other, the nonhuman with the database, the resonant network, as an instantiation of a process of unworking, enables the thought of a <em>database community</em> to emerge. With this concept of database community, the notion of database music can be further understood as a hybridly social and communicative event. This is to say that, following Latour’s hybridity of objects in his understanding of society <span class="citation" data-cites="Lat90:On">(Latour 1990, p. 2)</span>, database music is a social practice that comes as a result of databasers and databases in resonance with each other. Furthermore, database music is an instance of community, in the sense that it is an event of communication, understanding the communicative as “the unworking of work that is social, economic, technical, and institutional” <span class="citation" data-cites="Nan91:The">(Nancy 1991, p. 31)</span>. Therefore, the database community emerges as —but also, from, through, during, etc.— the unworking of databasers and databases, that is, the human and nonhuman. Finally, database community can be considered as a skin upon which the human and the nonhuman resonate, which amount to —but never finalize in— a musical event, that is, an instance of database music.</p><h2 id="section:Databases_And_Memory">Databases And Memory</h2><h3 id="funeslude">Interlude: Embodied Memory</h3><blockquote><p>I suspect, nevertheless, that he was not very capable of thought. To think is to forget differences, to generalize, to abstract. <span class="citation" data-cites="Bor42:Fun">(Borges 1942, p. 2)</span></p></blockquote><p>The importance of memory —and forgetfulness— can be represented by Jorge Luis Borges’s famous 1942 short story, <em>Funes, the memorious</em> <span class="citation" data-cites="Bor42:Fun">(Borges 1942)</span>. Due to an unfortunate accident, the young Irineo Funes was —“blessed or cursed” as Hayles points out <span class="citation" data-cites="Hay93:The">(Hayles 1993, p. 156)</span>— with an ability to “remember every sensation and thought in all its particularity and uniqueness ” <span class="citation" data-cites="Hay93:The">(Hayles 1993)</span>. A blessing, since a capacity to remember with great detail is certainly a virtue and a useful resource for life in general; a curse, because he was unable to forget and, as a consequence, he was unable to think, to remember, to dream, to imagine. Throughout the years, he became condemned to absolute memory, and so to its consequence, insomnia:<a href="#fn30" class="footnote-ref" id="fnref30"><sup>30</sup></a> he was secluded in a dark and enclosed space so as not to perceive the world.<a href="#fn31" class="footnote-ref" id="fnref31"><sup>31</sup></a> Hayles focuses on one aspect of the story, namely, the fact that Funes invented —and begun performing— the infinite task of naming all integers, that is, of giving a unique name —and sometimes, last name— to each number without any sequential reference. According to how Hayles describes it, by carrying out his number scheme, Funes epitomizes the impossibilities that disembodiment brings forth, to the point that:</p><blockquote><p>If embodiment could be articulated separately from the body —an impossibility for several reasons, not least because articulation systematizes and normalizes experiences in the act of naming them— it would be like Funes’s numbers, <em>a froth of discrete utterances registering the continuous and infinite play of difference</em>. [emphasis added] <span class="citation" data-cites="Hay93:The">(Hayles 1993, pp. 156–59)</span></p></blockquote><p>Therefore, the point that she is touching is that of the limits and fragility of embodied memory. In that Manovichian world which “appears to us as an endless and unstructured collection of images, texts, and other data records” <span class="citation" data-cites="Man01:The">(Manovich 2001, p. 219)</span>, this idea would be perfectly viable. Indeed, data banks have already been growing exponentially much in the same way as Borges’ 1942 character’s mind was aiming at. This capability of accumulation without the need of erasure is enabled by the database structure inherent in computers.<a href="#fn32" class="footnote-ref" id="fnref32"><sup>32</sup></a> However, the distinction that Hayles presents —which has been discussed before (See <a href="#bodiless_information" data-reference-type="ref" data-reference="bodiless_information">4.1.4</a>)— is crucial: data is not information because information needs to be embodied. Therefore, on one hand, a disembodied data bank can have all the uniqueness and difference that is available by the sum of all cloud computing and storage to date; however, on the other hand, an embodied memory is only available by the human capacity to forget.</p><p>Matías Borg Oviedo <span class="citation" data-cites="Ovi19:Mem">(Oviedo 2019)</span> relates this incapacity for thought precisely to the negation of narrativity itself, thus finding in the image of Funes a hyperbole for contemporary subjectivity <span class="citation" data-cites="Ovi19:Mem">(Oviedo 2019, p. 5)</span>, where there is no room for narration, only accumulation of data. In this sense, narrativity can be seen as that which resides in the threshold between knowledge (i.e., memory) and storage (i.e., archives, databases). I believe this distinction stems precisely from the difference between information and data. The process of information, of giving form, requires a certain temporality that is not that of the immediate and extremely operative zero-time of the (computer) processor. Within the zero-time of computer operations, there simply is no time for narrative, only for addition, for an increment. With this in mind, I would like to question Manovich’s opposition of narrative and database, precisely on the grounds that narrative is temporal —happening as a historical process— and algorithms are atemporal —operating in an effervescent now. Therefore, Funes’ accumulative memory represents the overflow of the now that precludes narration: neither data structures nor algorithms can forget to count.</p><p>Studies in cognitive psychology might have something to add here. In Wessel and Moulds’ commentary <span class="citation" data-cites="Wes08:How">(Wessel &amp; Moulds 2008)</span> on Paul Connerton’s <em>Seven Types of Forgetting</em>, the authors consider forgetting to be the “failure” of certain search processes on account of an inability to recall information from memory. While pointing to current psychological models of memory which consider forgetting to be an adaptive and functional activity, the authors acknowledge the mystery of certain aspects of memory: “In human memory, it is unclear what really happens to old, disused or deliberately ignored memory traces —they might be retrievable, they might be lost, but no-one can tell” <span class="citation" data-cites="Wes08:How">(Wessel &amp; Moulds 2008, p. 292)</span>.</p><p>Thus, considering this distinction between embodied and disembodied memory, I propose an imaginary experiment, one that I believe was missing from Borges’ short story, however utterly fantastic his writing was.</p><p>One thing that can be read from the story is that, in order to seclude himself from perceiving the world, or better, in order to forget the world altogether, Irineo stayed in the dark. This is how he cancelled light, a quite powerful stimuli if memory-space is to be optimized —for the purpose of, say, getting some sleep.<a href="#fn33" class="footnote-ref" id="fnref33"><sup>33</sup></a> However, there is little to no mention of the sonic environment in which Funes was embedded —probably in the outskirts of the quiet Uruguayan city of Fray Bentos. In fact, the only sonic references are focused on the narrator’s perspective, referring to Funes’ high-pitched and —due to his being in the darkness— acousmatic voice.<a href="#fn34" class="footnote-ref" id="fnref34"><sup>34</sup></a> Therefore, focusing on Funes’ listening, by locking himself inside a room he would have managed to attenuate sound waves coming in from outside. Notwithstanding his isolation —or, better, his self-imprisonment—, sound waves are actually very difficult to cancel. An interesting experiment would have been to have John Cage take Irineo to an anechoic chamber and ask him what he can remember then. From Cage’s own experience, we can guess that Funes would effectively remember his own sounding body.</p><p>(It is interesting to compare Funes’ search for filtering out the world with John Cage’s search for silence. Kim Cascone writes that “[Cage’s] experience in an anechoic chamber at Harvard University prior to composing 4’33” shattered the belief that silence was obtainable and revealed that the state of ‘nothing’ was a condition filled with everything we filtered out” <span class="citation" data-cites="Cas00:The">(Cascone 2000, p. 14)</span>. It is interesting to place an 80 year-old Irineo in David Tudor’s premiere at Maverick Concert Hall in Woodstock, NY, infinitely listening to 4’33”)</p><p>However, it is very unlikely —but nonetheless possible— that Borges was aware of American acoustician Leo Beranek’s research for the US Army during World War II, that is, when the first anechoic chamber was built.<a href="#fn35" class="footnote-ref" id="fnref35"><sup>35</sup></a> Furthermore, even if he managed to isolate himself perfectly from the world, cancelling perception altogether, Funes would have been with his memories, which are not discrete, but continuous iterations of the world he had accumulated over the years. What this means is that all the sounds he had listened to would be available to his imagination.</p><p>As far as we can learn from the narrator, while <em>smell</em> is referenced to in the story, <em>sound</em> was completely out of Funes’ concerns. Therefore, the question is how would the world sound for Irineo Funes? The task is not difficult to imagine: the world would be inscribed in poor Irineo’s memory in such an infinitely continuous way that each fraction of wave oscillation would be different, unique, leaving no space for repetition of any kind. All sounds would be listened completely, with every infinitesimal fraction of oscillation of the waves pointing to the most utterly complete scope of imaginable references. It would not be inaccurate to compare this type of memory saturation with CPU saturation, for example, the way a computer would —even the most gigantic multi-core imagined—, if it was commanded to compute, with accuracy, the wave equation. In this complete state of listening, there would be no possibility for thought, no processing of any kind, only infinite accumulation and storage.</p><p>In this sense, an infinitesimal incorporation of sound is unthinkable. This is not to be confused with the infinite structure of referrals and deferrals that difference is made of. The problem here —and this is evident in the story itself— is in the intersection of the finite with the infinite. While the structure of sound itself is infinite, in the sense that it is an ongoing process —i.e., circular loop— of difference, the singularity of the listening subject is finite: its limit exists as its possibility condition. This is to say that, given such an ontology of sound, the emergence of a resonant subject occurs <em>at</em> the limit, that is, at the liminality of an exposure to itself, to others, to waves, etc. In the case of the story, while Funes’ nonhuman qualities correspond to dynamics of the infinite, his human body is just like any other that was thrown in the world. Therefore, no matter what the narrator has the reader believe, Funes is not deprived of this liminality. Throughout the story, Funes’ liminality grows more and more evidently, all the way until the end —an ending that, despite all his nonhumanly infinite qualities, is, nonetheless —be it a blessing or a curse—, utterly human.</p><p>Less than focusing on literary analysis, in this interlude I take the concept of an absolute memory within a human being to be at an intersection between disembodied theories of information and, precisely, the concept of an embodied memory. The aim is to differentiate between human and nonhuman in terms of memory and databases, so as to provide a link between Latour’s ‘recorded movement’ of the network, and Derrida’s concept of the archive.</p><h3 id="human">The Effraction Of The Trace</h3><blockquote><p>Lo cierto es que vivimos postergando todo lo postergable; tal vez todos sabemos profundamente que somos inmortales y que tarde o temprano, todo hombre hará todas las cosas y sabrá todo.<a href="#fn36" class="footnote-ref" id="fnref36"><sup>36</sup></a> <span class="citation" data-cites="Bor42:Fun">(Borges 1942)</span></p></blockquote><blockquote><p>All these differences in the production of the trace may be reinterpreted as moments of deferring…Is it not already death at the origin of life which can defend itself against death only through an <em>economy</em> of death, through deferment, repetition, reserve? <span class="citation" data-cites="Der78:Wri">(Derrida 1978, p. 202)</span></p></blockquote><p>I would like to take a brief, but necessary, psychoanalytic detour, so as to set some context for the concept of memory. For this purpose, I take Derrida’s reading of Freud’s conceptualization of memory as a starting point towards distinguishing between human and nonhuman memory.</p><h5 id="memory-as-breaching">Memory as Breaching</h5><p>According to Derrida <span class="citation" data-cites="Der78:Wri">(Derrida 1978)</span>, Freud understood memory as the essence of the psyche: “Memory, thus, is not a psychical property among others; it is the very essence of the psyche: resistance, and precisely, thereby, an opening to the effraction of the trace” <span class="citation" data-cites="Der78:Wri">(Derrida 1978, p. 201)</span>. In this sense, the perceived world enters as a force of effraction into the resisting unconscious, resulting in the inscription of a trace, that is, a memory. By definition, this is a violent process of impression (pressing <em>in</em>), which is only possible by the notion of resistance. Thus, in order for something to leave a mark, there has to be some force acting against an other. In this case, one force is the world with its constantly changing images; another, the unconscious with its resistance to change. In this sense, Freud describes memory as breaching, or better, a state of being opened to this effraction. Memories are inscribed with incredible violence, one that can define the extent to which the inscription can be recalled later on, for instance, the case of repression, which is not forgetfulness but the deferred case of a force of containment. Furthermore, this breaching can be equally thought of as a fracture, hence the notion of effraction, which speaks of a the violent rupture. Despite, however, this violent image of path-breaking, Derrida writes of memory as an opening, in a paradoxical game between the resistance of the unconscious and the unavoidable (unclosing) state of being innocently ready for the next perception.</p><h5 id="breaching-and-différance">Breaching and <em>différance</em></h5><p>Derrida points to one issue in Freud’s opposing forces: the case where resisting forces meet equally strong forces, which would result in a paralysis of memory. Therefore, he proposes that it is “the difference between breaches which is the true origin of memory, and thus of the psyche” <span class="citation" data-cites="Der78:Wri">(Derrida 1978, p. 201)</span>. In other words, Derrida reconfigures the psyche with the interplay of <em>différance</em>, that is, a structure of infinite referrals and deferrals: “trace as memory is not a pure breaching that might be reappropriated at any time as simple presence; it is rather the ungraspable and invisible difference between breaches” <span class="citation" data-cites="Der78:Wri">(Derrida 1978, p. 201)</span> Therefore, since the essence of the psyche (memory) is breaching (tracing) and the space and temporal dislocation of traces (<em>différance</em>), a link between human and nonhuman can be established: writing.</p><h5 id="hypomnesis-and-the-mystic-pad">Hypomnesis and the Mystic Pad</h5><p>As Derrida points out, writing as <em>hypomnesis</em> (as an externalization of memory) has been considered since Plato <span class="citation" data-cites="Der78:Wri">(Derrida 1978, p. 221)</span>. However, Freud’s metaphor for the perceptual system found yet another place: the Mystic Pad. There were many derivations of this device, but it consists in something like a writable surface board. When you write on it, a thin layer on top sticks to a sort of wax on the back, thus leaving a trace; when you lift the upper layer, the traces vanish completely. This special device came to represent, for Freud, the structure of the perceptual apparatus itself, or as Derrida says, it is where “the psychical is caught up in an apparatus, and what is written will be more readily represented as a part extracted from the apparatus and ‘materialized’” <span class="citation" data-cites="Der78:Wri">(Derrida 1978, p. 222)</span>. Therefore, this new (1925) hypomnesic device allowed Freud to shift from considering regular writable surfaces (paper), to a combination of resisting textures in a device which allowed for “a perpetually available innocence and an infinite reserve of traces” <span class="citation" data-cites="Der78:Wri">(Derrida 1978, p. 223)</span>. Derrida, however, reconceptualized this differently. The crucial distinction he finds on this writing device is the notion of erasure, but most pressingly, that of repetition. In this sense, traces “produce the space of their inscription only by acceding to the period of their erasure” <span class="citation" data-cites="Der78:Wri">(Derrida 1978, p. 226)</span>. This means that tracing constitutes a process whose only possibility is its own negation, that is, its own undoing of itself. Furthermore, these traces are, from the first moment, that is, from the beginning of the process of impression, “constituted by the double force of repetition and erasure, legibility and illegibility” <span class="citation" data-cites="Der78:Wri">(Derrida 1978, p. 226)</span>. Hence, the spatio-temporal duality of the concept of <em>différance</em>, that is, the interplay between spacing and deferments, which comes to be the “work of memory” itself <span class="citation" data-cites="Der78:Wri">(Derrida 1978, p. 226)</span>.</p><blockquote><p>The ‘subject’ of writing does not exist if we mean by that some sovereign solitude of the author. <em>The subject of writing is a system of relations between strata</em>: the Mystic Pad, the psyche, society, the world. Within that scene, on that stage, the punctual simplicity of the classical subject is not to be found. In order to describe the structure, it is not enough to recall that one always writes for someone; and the oppositions sender-receiver, code-message, etc., remain extremely coarse instruments. We would search the ‘public’ in vain for the first reader: i.e., the first author of a work. [emphasis added] <span class="citation" data-cites="Der78:Wri">(Derrida 1978, p. 227)</span></p></blockquote><h5 id="nonhuman-authors">Nonhuman Authors</h5><p>Since the structure of memory, as I outlined above, can be comprehended as path breaking and <em>différance</em>, the concepts of resistance, referrals, and deferrals play an important role in its definition. Furthermore, the externalization of memory comes as an instantiation of the very structure of not only our perceptual machine, but also of the structure of the psyche itself. This hypomnesis allows for a materialization of the psyche that is constituted as a tool, that is, as an apparatus to be handled. With this conceptualization of memory as writing, Derrida reconfigures the notion of the self of writing, that is, of an author. Therefore, when memory is thought of as writing, the classical notion of self begins to disappear, opening up the space for the nonhuman. In what sense can this disappearance of the self be accounted for if we substitute writing for databasing? How does the databasing self emerges in this non-origin of the originary moment of writing that Derrida describes above? How is this “system of relations between strata” to be understood in terms of the work of databasers? This is how a further step into the conceptualization of memory can be of aid, one that considers memory as resonance, and writing as databasing. I have already described above how resonance and memory constitute processes of <em>différance</em>, that is, how the structure of sound, on the one hand, and traces, on the other, relate to spatiality and temporality. This is to say that, while the infinite situations of reference create a space of multiple situations, connections, associations, etc., which constitute an instance of signification, simultaneously, the ongoing process of deferral creates the oscillatory condition of perception, which constitutes the infinite return, the repetition, and the reverberation of a self. This self, however, is not an essential one, that is, it is not a substance, but it is understood as a resonating subject, <em>the resonance of a return</em>, which, like Derrida’s “subject of writing”, does not exist in itself, and only appears as a result of a resonating “system of relations between strata.”</p><h5 id="database-as-agents">Database as Agents</h5><p>Therefore, if this resonating self can only emerge out of this system —or better, network— of relations, then, every resonating point of the network must be considered as an agent in the constitution of a self. This means not only that the database, in this particular case of database music, becomes an agent of self-hood —and, for that matter, an agent of authorship relating to the resulting work of database music. It also means that, as an instance of hypomnesis, that is, as technology that externalizes memory, the database appropriates the qualities relating to memory itself that were described above: breaching and <em>différance</em>. Thus, not only can the nonhuman be reconceptualized within these qualities, also the human itself becomes reconfigured when faced upon the situation that memory, as breaching and <em>différance</em> can also be found in the nonhuman. Therefore, given that the nonhuman and the human are engaged in this resonating network that cancels the classical notion of self, then, distinguishing between the human and the nonhuman cannot be carried out in classical terms, that is, in terms of substance, essence, etc., since they do not apply anymore. The only thing that remains is, basically, the body, the singular instance of a resonating skin, whether it be of a human or a nonhuman, of a databaser or a database; a skin, but also an open resistance to the forces of change.</p><h3 id="archontic">The Archontic Principle</h3><h5 id="archives-and-memory">Archives and Memory</h5><p>For Derrida, the archive cannot be reduced to memory, it is is neither a form of rememoration nor a “conscious reserve,” but simply a place where “the origin speaks by itself” <span class="citation" data-cites="Der95:Arc">(Derrida &amp; Prenowitz 1995, p. 60)</span>. In this definition, the word ‘origin’ refers to the greek root of the word ‘archive’ [arkhē], whose meaning is twofold: on one hand, its definition is topological (space) on the other, it is nomological (law). In the topological sense, <em>arkhē</em> is related to the greek word arkheion, which, in turn, refers to “a house, a domicile, an address, the residence of the superior magistrates, the <em>archons</em>, those who commanded” <span class="citation" data-cites="Der95:Arc">(Derrida &amp; Prenowitz 1995, p. 9)</span>. In the nomological sense, <em>arkhē</em> refers to the ruling, to authority, to the command or commandment, i.e., the law. Thus, the magistrates [archons] are those who “have the power to interpret the archives,” and they indeed reside inside this place called <em>archeion</em> <span class="citation" data-cites="Der95:Arc">(Derrida &amp; Prenowitz 1995, p. 9)</span>. Therefore, considering the fact that these magistrates actually reside in place of the archive, Derrida refers to an “institutional passage from the private to the public” which is constitutive of the archive itself <span class="citation" data-cites="Der95:Arc">(Derrida &amp; Prenowitz 1995, p. 9)</span>.</p><h5 id="hierarchies">Hierarchies</h5><p>From this definition of the archive, what is alluded is the hierarchical structure of civilization itself, that is, of government and legislation. Going further into this aspect of the concept of the archive would extend the limits of this text. Derrida, with this conceptualization of the archive, focused on the exponential growth of archives that spawned during the 20th century, defining it as an impulse, or better, as a ‘fever’ and a drive. Thus, he proceeded to perform a psychoanalysis of this symptomatic condition of mid-1990 society, beginning with the archivization of the house of the <em>father</em> of psychoanalysis, Sigmund Freud. Therefore, I would like to focus on one principle that Derrida described as belonging to the concept of the archive, what he calls the <em>archontic</em> principle.</p><h5 id="archontic-principle">Archontic Principle</h5><p>The archontic principle is a type of authority that the archive projects, which can be understood as powerful dictating rule that is before anything else. Hence, its categorization as principle, which is also related to the origin (e.g., the latin root <em>principium</em> which refers to the beginning) and to the figure of the ruler (e.g., principal, prince, etc.). For Derrida, this principle is constitutive of all words deriving from <em>archē</em>, which is why he understands the archive, for example, as being patriarchic. Since the archontic principle is present in the etymology of the word ‘patriarchy’ —which refers, likewise, to ‘lineage,’ ‘father,’ and ‘I rule’—, therefore, he argues that the archontic is embedded first with a sense of filiation, that is, with fatherhood and the relationship between father and child. Thus, the archontic is “paternal and patriarchic” <span class="citation" data-cites="Der95:Arc">(Derrida &amp; Prenowitz 1995, p. 60)</span>.</p><h5 id="patriarchy">Patriarchy</h5><p>What follows is that this patriarchy is grounded in a domicile (house) or an institution (family). Within this domiciliation or institutionalization is from where rules are prescribed, and where the ruling takes place. In the case of the patriarchic concept of family, the father is the ruler; in the case of civilization, the governor is the ruler. Therefore, this is what Derrida means when he performs a psychoanalysis of the archive: the topo-nomological aspect of the archive comes precisely from a —strategically male-centered— concept of fatherhood. In this sense, Derrida discovers that the archontic has the form of Freud’s oedipus complex. An oedipus complex constitutes a desire of the child’s unconscious hatred towards a parent. It is itself based in Sophocles’ drama <em>Oedipus Rex</em>, in which such desire results in eventual parricide. Derrida notes that this complex has the form of an infinite loop between father and child, which is bound to repeat itself, just as is the case with Freud’s definition of the complex, which, according to the greek drama, is articulated by the figure of the parricide. In this sense, Derrida claims that Freud “has shown how this archontic, that is, paternal and patriarchic, principle only posited itself to repeat itself and returned to re-posit itself only in the parricide” <span class="citation" data-cites="Der95:Arc">(Derrida &amp; Prenowitz 1995, p. 60)</span>.</p><h5 id="institutional-passage">Institutional Passage</h5><p>What is the case when this patriarchic principle is found on archives? I mentioned above the passage from the private to the public that Derrida recognized in the concept of the archive. This fact resonates with the plurality that is condensed in the place of the archive, which is opposed to the singularity that is condensed in the plurality of memory. In other words, while archives are a singular place where documents —made by a plurality of authors, that is, by different people, technologies, etc— are singularly kept, in the case of human memory, the reverse occurs. While the psyche is singular, that is, while there is only ‘myself’ remembering, the difference between each trace of memory is indeed a plurality. While I remember, the memory I rememorate is composed out the set of differences of traces that I have effracted in the moment of remembering.</p><p>The following pseudocode may help in this distinction:</p><pre><code>function make_an_archive() {
    public      = PRIVATE
    singular    = PLURAL
    place       = COMMUNITY
    archive     = place = singular = public
    return archive
    }

function make_a_memory() {
    private     = PUBLIC
    plural      = SINGULAR
    trace       = SELF
    memory      = trace = plural = private 
    return memory
}</code></pre><h5 id="authorities">Authorities</h5><p>For example, the case of making an archive can be exemplified with the passing of a law or the signing of a contract. Derrida speaks of the act of consignation as constitutive of the archontic principle, since it is an act of “gathering together signs” <span class="citation" data-cites="Der95:Arc">(Derrida &amp; Prenowitz 1995, p. 10)</span>, as is the case of the signatures on a bill or a contract. One’s signature is private, therefore, the moment one signs a document one makes it public. Furthermore, in making a contract, multiple signatures need to be gathered into the same space: the plurality of the community needs to be condensed in the singularity of the document. Finally, the document itself comes to be a place, but it itself needs yet another place where it is stored, which comes to be the archive. What this act of consignation entails is, precisely, the archontic principle, since the contract itself now becomes an authoritative presence that emerged out of this function of making an archive. The structure of this presence will be discussed in the following section (See <a href="#spectrality" data-reference-type="ref" data-reference="spectrality">5.2.4</a>). For now, let us continue with the case of making a memory. The moment one perceives the world, one makes it private, inasmuch as one engages with remembering it. When one begin remembering, oneself begins the process of pathbreaking and effraction of traces —and of forgetting, as I will continue to develop below–, which results in the plurality of the condition of traces, that is, on the difference between traces constitutive of memory.</p><p>So, given that if this constitution of archive and memory are indeed reflections of each other, that is, one being the reverse of the other, how is the archontic present in the making of a memory? What would a reversed archontic principle look like? How would it act? These questions deserve a few paragraphs because they will explain the relationship between database, memory, and archive.</p><h5 id="anarchic-memory">Anarchic Memory</h5><p>What is important to note here, before continuing, is that just as memory is in a state of fracture and rupture, an archive is also in such state of discontinuity, and thus it is this condition of being in the form of disconnected gaps that makes memories and archives so alike. Spieker notes is that of discontinuity and rupture: “Like all kinds of data banks, [the archive] ‘forms relationships not on the basis of causes and effects, but through networks’” <span class="citation" data-cites="Ern13:Dig">(Ernst 2013, p. 113)</span>. From these two qualities of archives (filtering and fracture), their resemblance to memory can be drawn. However, while the archive is indeed patriarchic, memory, on the other hand, in terms of the archontic principle, it can only be described as an-archic. While there is indeed oneself remembering, there is no possibility of ruling over the plurality of traces that one has in memory. There is no place to go to remember things, one may try to trick the body into feeling similar things as when one was remembering so as to make a memory resurface, but in the end, memories remember themselves. One has no control over neither remembering nor forgetting. Memories forget themselves.</p><h5 id="collective-memory">Collective Memory</h5><p>In the fantastic case of Funes (See <a href="#funeslude" data-reference-type="ref" data-reference="funeslude">5.2.1</a>), for example, forgetting is a mysterious lack that cannot be reduced to a simple loss of information. It is also a necessary condition for memory to be considered as trace, given that the moment a trace begins is when its own erasure begins. Thus, every memory comes with its own forgetting mechanism, a mechanism that is triggered on its own, and, further, that it is still not fully understood <span class="citation" data-cites="Wes08:How">(Wessel &amp; Moulds 2008, p. 292)</span>. However, in the case of an archive or, what some (perhaps wrongfully) refer to as ‘collective’ memory, the opposite occurs: data loss consists of plain and simple erasure, that is, a destruction that cannot be considered an instance of forgetting: “in collectivistic memory, where the database has a tangible form, it is more apparent that permanent loss is a possibility. In archives, ink may fade, paper may crumble and entire files may end up in the shredder. <span class="citation" data-cites="Wes08:How">(Wessel &amp; Moulds 2008, p. 292)</span>”</p><h5 id="writing-code">Writing Code</h5><p>Since writing can function as a link between human and the nonhuman memory (See <a href="#human" data-reference-type="ref" data-reference="human">5.2.2</a>), several instances of the metaphor of writing need to be explained in relation to databasing. For example, not only programming languages imply writing in terms of symbols (words and characters), also data structures appropriate the concepts of writing and erasing. Furthermore, in resonance to the Derridean trace, erasure is embedded in the structure of writing. This is to say, that C++ classes include within their own data structure a call to their <code>destructor</code>. This means that, whether explicitly or implicitly, all classes —i.e., all data structures which correspond to instantiated objects— have a way to self-erase, or self-destruct after the object is no longer needed. This self-destruction means, precisely, releasing the object’s resources, that is, to free the physical memory space that it has occupied throughout its lifetime.<a href="#fn37" class="footnote-ref" id="fnref37"><sup>37</sup></a></p><h5 id="anarchic-computer-memory">Anarchic Computer Memory</h5><p>This comparison between <code>destructor</code>s and forgetting serves as a starting point to determine the extent to which computer memory —i.e., data structure handling in restricted, discrete space— can be thought of as human memory itself, and, if so, the extent to which it also constitutes an instance of an-archic structure. (The first thing that comes to mind is an an-archic program written in C++ with self-destructing classes that fire at will, in complete unpredictability, rendering the software utterly anarchic, but utterly useless.) Therefore, there has to be a different way to think of an-archy in software. In what follows, I address the extent to which databases can be understood in terms of memory and anarchy, taking German media theorist Wolfgang Ernst’s concept of the <em>anarchoarchive</em> to a different dimension.</p><h3 id="spectrality">The Spectral Database</h3><blockquote><p>The structure of the archive is <em>spectral</em>. It is spectral <em>a priori</em>: neither present nor absent “in the flesh,” neither visible nor invisible, a trace always referring to another whose eyes can never be met… <span class="citation" data-cites="Der95:Arc">(Derrida &amp; Prenowitz 1995, p. 54)</span></p></blockquote><h5 id="computer-memory-and-writing">Computer Memory and Writing</h5><p>Despite the multiplicity of elements that constitute software programming, such as compiler instructions, hardware stipulations, collaboration platforms, etc., the concepts of inscription and erasure (writing) are still in place. Because of this, the concept of the Derridean trace applies to programming. This fact can be linked further back to the conception of the computer itself, as it was previously discussed (See <a href="#databasing" data-reference-type="ref" data-reference="databasing">4.2.1</a>). In his architecture, Von Neumann proposes that the storage unit of the computer allowed data to be written and erased in different locations and times. In fact, he was following Turing’s conceptualization of the <em>a-machine</em> —i.e., the <em>Turing machine</em>—, which was a mathematical model for computation, that can be represented by a symbol scanner and an infinite tape, where the scanner gets, sets, or unsets a symbol on the tape, and the tape moves to the next slot accordingly. Therefore, these setting and unsetting movements represent inscription and erasure, to the point that, as Kittler notes, quoted by Ernst: “the two most important directing signals which link the central processing unit of the computer to external memory are being called <code>READ</code> and <code>WRITE</code>” <span class="citation" data-cites="Ern13:Dig">(Ernst 2013, p. 131)</span>.</p><h5 id="memory-replacement">Memory Replacement</h5><p>However, an important distinction needs to be made here. While I am arguing for the similarities that exist between memory and database, Ernst proposes that databases —i.e., what he refers to as digital an-archives— enter as a form of replacement. This is to say that, given the convergence of all media into digital media, ‘reading’ is rendered null, giving way to mathematical processes that come to interpret the data. In Ernst’s words, “signal processing replaces <em>pure</em> reading” [emphasis added] <span class="citation" data-cites="Ern13:Dig">(Ernst 2013, p. 130)</span>. This statement is only valid within the Kittlerian, disembodied worldview (See <a href="#convergence" data-reference-type="ref" data-reference="convergence">4.1.3</a>), which would also allow to convey the following: signal processing replaces <em>listening</em>. Thus, in such a world where data structures and algorithms perform our own capacities to create and, by doing so, remove our bodies from ourselves, there would be no need for neither reading nor writing. Since, if the database reads itself, it also writes itself, and, in the case of music, if it listens to itself, it also sounds itself, removing listening altogether. Therefore, in order to arrive at the point of resonance that enables both the nonhuman and the human to coexist, a reconceptualization of the anarchic in relation to databases needs to be made; specifically, one that is grounded not on substitution, but on difference, and one that explains how authority enters into the sphere of databases.</p><h5 id="anarchic-records">Anarchic Records</h5><p>In his conceptualization of the <em>anarchoarchive</em>, Ernst <span class="citation" data-cites="Ern13:Dig">(Ernst 2013)</span> opposes technical recording with symbolic transcription. Given the fact that a microphone captures the entire sonic environment, this involuntary memory —of “past acoustic, not intended for tradition: a noisy memory” <span class="citation" data-cites="Ern13:Dig">(Ernst 2013, p. 174)</span>— comes to be a form of anarchic archive, or <em>an-archive</em>. Therefore, for example, he claims that Bela Bartok’s transcriptions to musical notation of Milman Parry’s Serbian epic song recordings<a href="#fn38" class="footnote-ref" id="fnref38"><sup>38</sup></a> becomes an archivization process, that is, a process by which symbolic transcription leads to an ordered archive, i.e., a score.<a href="#fn39" class="footnote-ref" id="fnref39"><sup>39</sup></a> In Ernst’s sense, a sound file storing samples of the recorded world is anarchic because of the unfiltered (‘pure’) way in which the world is inscribed by the recorder. He bases this idea on another media theorist, Sven Spieker, who claims that, following Derrida’s conceptualization of the archive, a central feature of archives is not memory, but a need to “discard, erase, eliminate” that which is not intended for archivization <span class="citation" data-cites="Ern13:Dig">(Ernst 2013, p. 113)</span>. In other words, the possibility condition of an archive is filtering, or better: framing. The problem is that, the moment Ernst deposits on the recording technology the disappearance of the body, he dislocates framing altogether, and thus is how the concept of ‘pure’ recording comes in. Therefore, if for Ernst, Parry’s audio recordings are anarchic, this is because they are constructed upon a Kittlerian idea of purity that leaves the human out of the equation.</p><h5 id="memory-and-framing">Memory and Framing</h5><p>If we consider the body’s capacity to create images from the world of images, then framing is also a possibility condition for human memory. In fact, we have seen with the Derridean trace that it is a resisting force what first enables the violent rupture of traces, and thus, this force can also be considered as an instance of framing itself. Resistance of the psyche as creativity taking action as the moment of framing. In the an-archic memory graph that I am conceptualizing here, framing can be thought of as the edge (the arrow) that thus connects the public to the private. Furthermore, framing can also be inversely considered as the arrow between the private and the public in the case of archives, since, for example, in the case of a contract, only a limited amount of signatures are needed, thus a frame needs to be an active part of the process of archivization.</p><h5 id="nonhuman-tympans">Nonhuman Tympans</h5><p>Therefore, given that framing is in between the public and the private, in order to consider the case of audio recording as either memory or archive, these two categories, privacy and publicness need to be taken into account in relation to nonhumans. In other words, given that the world can be considered public, because it is in a constant state of availability at any time, then, a microphone can be considered an actor of privacy, since it deprives some sounds from being recorded —e.g., because it has not been designed for certain frequency bands— while recording other sounds. Therefore, if transducers have a filtering capacity, they engage with the passage from the public to the private —and vice versa, since both speakers and microphones are transducers. Consider, for example, Jonathan Sterne’s definition of the ‘tympanic’ function of transducers, as quoted by Cathy Van Eyck in her PhD dissertation on microphones and loudspeakers: “every apparatus of sound reproduction has a tympanic function at precisely the point where it turns sound into something else…and when it turns something else into sound” <span class="citation" data-cites="Eck13:Bet">(Eck 2013, p. 107)</span>. Therefore, considering these nonhuman tympans as actors of privacy and publicness, audio reproduction technology can be compared to the structure of memory and archives. For example, audio recording can be conceived as a form of memory, only to the extent that its inscription is singular yet reproducible. This is because a magnetic tape or a hard drive cannot be considered in the same (plural) way as Derridean traces, since once data is stored, it exists only once in discrete, limited space, unless copied to another location, in which case it becomes a duplicate, an identical (in-different) clone of itself. Furthermore, the case of audio playback can be a form of archive, since it consists of the passage from the private —the stored air pressure waves— to the public —the reproduced air pressure waves in space—, only to the extent that the latter is not considered space as such, but resonance within space. In this sense, Ernst’ consideration of the Parry’s recordings as anarchic needs to be reconfigured.</p><h5 id="spectrality-of-archives">Spectrality of Archives</h5><p>Given that these nonhuman tympans constitute the limit between sonic —but also tactile <span class="citation" data-cites="Eck13:Bet">(Eck 2013, p. 223)</span>— world and the binary world of databases, their comparison to memory and archives renders a hybrid object: one that, on the one side, becomes a private and singular ‘trace’, and, on the other, becomes a public, resonant ‘space.’ Thus, databases represent neither a trace nor a space. At this point it is important to address the quote at the beginning of this section, that is, the structure of the archontic that Derrida assigned to archives: spectrality. Derrida claims that, addressing a phantom is a “transaction of signs and values, but also of some familial domesticity” <span class="citation" data-cites="Der95:Arc">(Derrida &amp; Prenowitz 1995, p. 55)</span>, meaning, on the one hand, that in the uncanny encounter with a ghost, there is familiarity, that is, there emerge feelings of what is known to be close to us, but also that which composes the authority of that closeness. Therefore, embedded in this familiarity is the archontic, the oedipal, etc., and thus the expression of power that this apparition brings forth. On the other hand, the familiar is also related to an economy —Derrida points to the greek root <em>oikos</em>, meaning ‘house’—, that is, to the passing through (trans-action) of signs, but also de translation —or better, the ‘transduction’ of things. This is why Derrida considers any encounter with the spectral to be an instance of addressing, that is of transaction. Finally, what this uncanniness of the ghost entails is nothing other than the haunting itself, as Derrida writes: “haunting implies places, a habitation, and always a haunted house” <span class="citation" data-cites="Der95:Arc">(Derrida &amp; Prenowitz 1995, p. 55)</span>. To bring back our database, the hybridity that the database projects when compared to memory or archives points to a certain uncanniness, that is, precisely to the hauntedness that comes from its spectrality. Furthermore, it can be argued that considering the database in such way is plain and simple delusion, that is, insanity at its best. Not surprisingly, this is the point exactly; within this delusion exists truth:</p><blockquote><p>…it resists and <em>returns</em>, as such, as the spectral truth of delusion or of hauntedness. It <em>returns</em>, it belongs, it comes down to spectral truth. Delusion or insanity, hauntedness is not only haunted by this or that ghost…but by the specter of the truth which has been thus repressed. The truth is spectral, and this is its part of truth which is irreducible by explanation…<span class="citation" data-cites="Der95:Arc">(Derrida &amp; Prenowitz 1995, pp. 54–56)</span></p></blockquote><h5 id="spectrality-of-databases">Spectrality of Databases</h5><p>Therefore, given that Derrida considers the structure of the archive to be indeed spectral, I can bring this spectrality to the database itself, and consider it just as spectral but in a different sense. The spectrality of the database comes not from its hauntedness, that is, it is not domiciled since, as humans, we have no access to data space (address space) directly with our bodies. As humans, we cannot engage in transaction with the specter directly: we need transducers. In the case of audio playback, we need loudspeakers because we need to create, with our bodies, the image that was recorded in the first place. In consequence, while embodying stored data, we embody its specter. Therefore, the hauntedness needs to be ‘transduced’ into space, and with this transduction the agency of the database can be effectively felt. Likewise, the uncanniness of the case of audio recording can be felt as the ghost that will ‘remember us,’ because of this computer ‘memory’ that will keep (to its own privacy) the sonic environment that attests to our presence in space —because we sing, we make sounds, etc. Hence, the haunting that resides in-memory, together with the stored data and pointers.</p><h5 id="agency-of-the-uncanny">Agency of the Uncanny</h5><p>In recognizing this presence, which is the archontic specter of the database, comes the recognition of the agency of the database itself, and, furthermore, of the quality of the aesthetic experience that we encounter whenever there is a database in art. As Timothy Morton <span class="citation" data-cites="Mor13:Hyp">(Morton 2013)</span> writes in relation to what he calls hyperobjects:</p><blockquote><p>Recognition of the uncanny nonhuman must by definition first consist of a terrifying glimpse of ghosts, a glimpse that makes one’s physicality resonate (suggesting the Latin <em>horreo</em>, I bristle): as Adorno says, the primordial aesthetic experience is goose bumps. Yet this is precisely the aesthetic experience of the hyperobject, which can only be detected as a ghostly spectrality that comes in and out of phase with normalized human spacetime. <span class="citation" data-cites="Mor13:Hyp">(Morton 2013, p. 169)</span></p></blockquote><p>To the point that databases are spectral, they can be considered hyperobjects in Morton’s sense, and thus, agents translating through aesthetic networks. If we consider the “recorded movement of a thing” with which Latour identified his concept of the network, databases are agents not only of recording, also of motility, and of thing-hood itself. This is to say that, in the constitution of networks, the spectrality of the database expands in multiple directions. Bringing back the illusory violin of the acousmatic concert I mentioned earlier (See <a href="#network" data-reference-type="ref" data-reference="network">5.1.2</a>), it exemplified Hansen’s concept of the creation of images our brain’s capacity for virtuality has, that is, our imagination. The sound of a violin can be recorded —but also synthesized— into the privacy of a database. Then, it can be played back with loudspeakers located in such a way that they emulate the location of an actual violin player. As a result, the listener could very likely imagine a physically present violin in the room, that is, a ghost. This ghost comes in as the phantom of a human player; of the violin itself; of the histories and traditions that those two elements bring forth; of the presence of the nonhuman that the database implies; of the privacy that is not human but that it is still uncannily private; of the plurality that is embedded in the construction of databases; of the hauntedness of the archontic that the above sets forth; and so on. In this way, the spectrality of the database attests to its relation to memory and archives, and, thus, to its aesthetic resonance within our experience.</p><p>In what follows, a crucial aspect of the database will be addressed, one that defines the condition of possibility of this hauntedness to be indeed instantiated into appearance, not only in the form of authority, as I have shown in the case of its archontic presence, but also in the form of style, and most important, gender: the performativity of the database.</p><h2 id="section:Performativity_Of_Databases">Performativity Of Databases</h2><h3 id="gender">Gendered Database</h3><blockquote><p>Gender is not passively scripted on the body, and neither is it determined by nature, language, the symbolic, or the overwhelming history of patriarchy. Gender is what is put on, invariably, under constraint, daily and incessantly, with anxiety and pleasure, but if this continuous act is mistaken for a natural or linguistic given, power is relinquished to expand the cultural field bodily through subversive performances of various kinds. <span class="citation" data-cites="But88:Per">(Butler 1988, p. 531)</span></p></blockquote><p>Judith Butler <span class="citation" data-cites="But88:Per">(Butler 1988)</span> distinguishes between an expressive and performative self. The former comes from an essentialist view from the self as being ‘inside’ and displaying itself on the outside. The latter is an illusory self, strictly outside and unrelated to the “natural or linguistic given.” She understands gender within this performativity of the self. Like the self, gender emerges temporally, at the surface level of the skin of the body. This notion of gender relates with Jean-Luc Nancy’s notion of resonance and the self (See <a href="#section:Listening_Databases" data-reference-type="ref" data-reference="section:Listening_Databases">5.1</a>).</p><h5 id="skin-of-the-database">Skin of the Database</h5><p>In the performativity of databasing resides the possibility for the skin of the database to emerge. On the one hand, this skin is the spectral surface of the database’s illusory self. On the other, it is the limit towards which the human and the nonhuman engage in resonance. The skin of the database carries the mark of a style. That is to say, in defining style as a repetition of acts, it is a form of embodiment that is ascribed to databases. Because the self of the database is inscribed on its skin, we can assign yet another quality of the database: an authorial subject. This subject relates to the uncanny, not only because of its nonhuman spectrality, also because of its gendered appearance which comes to redefine our own social categories such as reality itself. Therefore, I claim that, given that databasing is the performative condition of databases, the database becomes gendered.</p><h5 id="expressing-nothing">Expressing Nothing</h5><p>Butler sets forth a critical genealogy of gender which relies on a “phenomenological set of presuppositions, most important among them the expanded conception of an ‘act’ which is both socially shared and historically constituted, and which is performative…” <span class="citation" data-cites="But88:Per">(Butler 1988, p. 530)</span>. Furthermore, the difficulty Butler recognizes in this view of gender, is that “we need to think a world in which acts, gestures, the visual body, the clothed body, the various physical attributes usually associated with gender, <em>express nothing</em>” <span class="citation" data-cites="But88:Per">(Butler 1988, p. 530)</span>. Therefore, how can the database itself be conceived in this terms of performativity, to the point that, while having the capacity to store millions of data, a database can in deed express nothing?</p><h5 id="a-historical-situation">A Historical Situation</h5><p>Butler defined gender identity as a historical situation, distinguishing between physiological facticity of the body (sex) and the cultural significance of such facticity in terms of gender. Added to this distance between body and identity, Butler speaks of the body as performative process of embodying cultural and historical possibilities. These possibilities, which are delimited by historical conventions, are thus materialized on the body: “one does one’s body differently from one’s contemporaries and from one’s embodied predecessors and successors” <span class="citation" data-cites="But88:Per">(Butler 1988, p. 521)</span>. Therefore, the body comes to be a “historical situation” that results from the performativity of embodiment itself. In other words, the actions related to what Butler calls the “structures of embodiment” constitute an ontological sphere of present participles, such as ‘doing,’ ‘dramatizing,’ and ‘reproducing.’ Furthermore, what this structure of embodiment entails is the constitution of not only gender, but also style. Since gender is constituted temporally, it is necessarily historical:</p><blockquote><p>to be a woman is to have <em>become</em> a woman, to compel the body to conform to an historical idea of ’woman,’ to induce the body to become a cultural sign, to materialize oneself in obedience to an historically delimited possibility, and to do this as a sustained and repeated corporeal project. <span class="citation" data-cites="But88:Per">(Butler 1988, p. 521)</span></p></blockquote><h5 id="subversive-repetition">Subversive Repetition</h5><p>Far from being a prescribed given, the constitution of gender on the body is itself a result of mediated history. In other words, gender is a creative act of interpretation and reinterpretation that reveals itself on the body, not as an expression that comes from within, but as the sedimented layerers that deposit themselves in time. Furthermore, within this notion of temporality there is the need for repetition, but a repetition that is susceptible to breakage, or what Butler refers to as “subversive repetition” <span class="citation" data-cites="But88:Per">(Butler 1988, p. 520)</span>. In being a temporal identity which reveals itself through a “stylized repetition of acts” gender constitutes an “illusion” of a gendered self. These acts take place <em>on</em> the body, by the mundane instantiation of bodily gestures, movements, and enactments. Furthermore, the these acts are necessarily discontinuous, and it is because of this discontinuity that exists the possibility of gender transformation. In this sense, gender performance is neither linear nor nonlinear. It resides along an anarachic temporality that replaces teleology with the multiplicity of resonant nows. It is an inline iterative function with random breaks.</p><h5 id="gendered-database">Gendered Database</h5><p>The database is a collection of facts. It is facticity itself. This is what Butler’s gendered self can teach about databases: in performing the database, the database appears like gender, as a historical situation. Its body is felt neither as the database body, as if the materiality of the computer’s architecture could come as a proxy for the nonhuman body; nor as the extension of the embodying databaser, that is, as a prosthesis that expands the databaser in an expressive way. The body of the database emerges as a phantom, as spectrality itself, and it is this nonhuman presence that engages in the publicness of performative acts. The specter of the database must not be understood spiritually, or as a <em>deus ex machina</em>, or as a soul, or singularity that begins to act <em>as</em> human and, by extension, supersedes human. It is simply a nonhuman fabrication of selfhood: there, around, making its way through the rupture of the permanent condition of performativity to which we (humans and nonhumans) are phenomenologically bound. That is the how the style of the database appears. This nonhuman self, like Butler’s gendered self, is equally ‘outside,’ that is, “constituted in social discourse” <span class="citation" data-cites="But88:Per">(Butler 1988, p. 528)</span>. That is to say, the skin of the database is open for perception outside of itself, and in fact, nothing of the database can be considered expressive. Inside the database there is literally nothing but zeros and ones, nothing but data; in the same way, nothing is inside of the body but flesh, bones, and veins. When considered as internal, inherent, or essential, the classical notion of the self, in its heteronormativity, is seen as a “publically regulated and sanctioned form of essence fabrication” <span class="citation" data-cites="But88:Per">(Butler 1988, p. 528)</span>. In this state of being fabricated, expressivity serves as the foundation for what Butler refers to as the ‘punitive’ aspects of wrong gender performance. In this sense, the social quality of acts that fall outside the regulated binary gender construction work their way into punishing the body, incarcerating it, severing it, as is, for example the famous case of Turing himself:</p><blockquote><p>Turing’s later embroilment with the police and court system over the question of his homosexuality played out, in a different key, the assumptions embodied in the Turing test. His conviction and the court-ordered hormone treatments for his homosexuality tragically demonstrated the importance of <em>doing</em> over <em>saying</em> in the coercive order of a homophobic society with the power to enforce its will upon the bodies of its citizens. <span class="citation" data-cites="Hay99:How">(Hayles 1999 xii)</span></p></blockquote><h3 id="limits">Towards The Limits</h3><h5 id="exposure">Exposure</h5><p>The performativity of databasing can be understood in terms of what Nancy calls exposure <span class="citation" data-cites="Nan91:The">(Nancy 1991)</span>. Exposure is the appearance of a limit and the finitud of a singularity. With this limit instantiated in the (public) moment of the performative act, is how communication emerges as that which is in common among singularities. That is to say, because it is itself nothing (“neither a ground, nor an essence, nor a substance” <span class="citation" data-cites="Nan91:The">(Nancy 1991, p. 31)</span>) Nancy considers finitud to just appear in the form of communication: “it presents itself, it exposes itself, and thus it exists as communication” <span class="citation" data-cites="Nan91:The">(Nancy 1991, p. 31)</span>. His emphasis on communication as exposure marks a crucial distinction on the concept of community. For Nancy, as I have described above (See <a href="#inoperativity" data-reference-type="ref" data-reference="inoperativity">5.1.3</a>), community cannot come from an instance of work: it emerges as an instance of the communicative action which is “the unworking of a work that is social, economic, technical, and institutional” <span class="citation" data-cites="Nan91:The">(Nancy 1991, p. 31)</span>. In other words, the performativity of this communicative act, the publicness and dramatic qualities with which it unfolds, result in exposure. This is why, in the case of databasing, what is exposed at the limit of its performance is the finitud of the database itself. Through this exposition of the limit is how the singularity of the database can be communicated; or, better, through this exposure is how communication expands our concept of community towards one that includes the database as an agent of community itself.</p><h5 id="anarchic-touch">Anarchic Touch</h5><p>As Nancy writes, “a singular being does not emerge or rise up against the background of a chaotic, undifferentiated identity of beings” <span class="citation" data-cites="Nan91:The">(Nancy 1991, p. 28)</span>. This is to say that, like Butler’s gendered self, there is no substance within singularity. The appearance of a database as finitud comes not from an originary <em>archē</em> which would impose its archontic power as is the case of archives. Further, the limit of the database is not instantiated out of the one, a “unitary assumption” <span class="citation" data-cites="Nan91:The">(Nancy 1991, p. 28)</span>, or the wholeness of a single one. This finitud does not come from intentionality or any essentialist notions: it simply appears, for Nancy, in the form of touch: “…as finitude itself: at the end (or at the beginning), with the contact of the <em>skin</em> (or the heart) of another singular being, at the confines of the same singularity that is, as such, always other, always shared, always exposed…” [emphasis added] <span class="citation" data-cites="Nan91:The">(Nancy 1991, p. 28)</span>. The temporality of this touch, like that of gender, is anarchic.</p><h5 id="communities-of-skin">Communities of Skin</h5><p>The limit of the database, as performative, spectral skin, is the condition for community to emerges between the human and the nonhuman. This means that the agency locus of the database needs to be placed precisely on its skin, because it is what becomes public of itself. In other words, given that this skin is available to the perception of others, it becomes touchable, it reaches our own limit as databasers. By doing so, that is, by exposing our own limits to ourselves and to each other, the database changes our definition, or, better, delimits the extent of our own singularity. However, this does not mean that it stands in the way of our performativity, or worse, that it precludes or determines ourselves. If this were true, we would be once again subject to technical determinism, essence fabrication, etc., and falling out of considering any possibility of community between anything that is not human —or, more accurately, anything that is not ‘man.’ As Nancy rightfully claims, “ it is not obvious that the community of singularities is limited to ‘man’” <span class="citation" data-cites="Nan91:The">(Nancy 1991, p. 28)</span>. Thus, the fact that the skin of the database changes our own skin simply means that we are already in communication with it, that is, in community, and also in a state of resonance with it. This is the function of the skin of the database: like the skin of a drum, or the skin of a loudspeaker, the skin of the database resonates with our own skin, engaging the resonant body with the resonant spectrality. This is the community of resonance, the community of the resonant network, which has no purpose, no intentionality behind, no essence; only appearance and motility, performance and repetition: an activity that is the unworking with which community exposes itself.</p><h5 id="hybrid-pluralities">Hybrid Pluralities</h5><p>Database models tend to reside next to each other, either within a single database system or within an interconnected networked system. With this plurality of the model, databasers have access to the many features that each model offers, focusing on those features that are suitable for their needs. The skin of the database is as fluid as the constitution of gender, and if this is true, then the fluidity of databasing itself comes to represent the constitution of gender through the performativity of databasers. By resonating in such performativity, databasers approach (but do not reach) the limit of the database. This approach to the skin of the database exposes simultaneously the skin of the databaser to the database. What this exposure amounts to is not, however, an opposition of forces. It results in the fragmented state of community that resides in the different degrees of this exposure. In other words, this exposure is of a hybrid plurality that resonates at the limit. Engaging with the touch of the spectral database means reconfiguring, resounding, and remembering our own sense of touch, just as well as our own sense of self.</p><h3 id="style">Contingencies Of Style</h3><blockquote><p>…style, supplementing timbre, tends to repeat the event of pure presence, the singularity of the source present in what it produces, supposing again that the unity of a timbre —immediately it is identifiable— ever has the purity of an event…The timbre of my voice, the style of my writing are that which for (a) me never will have been present. I neither hear nor recognize the timbre of my voice. If my style marks itself, it is only on a surface which remains invisible and illegible for me. <span class="citation" data-cites="Der82:Mar">(Derrida 1982, p. 296)</span></p></blockquote><p>A database without performance represents a disembodied ‘base’, that is, the spatially ordered set of computer hardware together with the software routines that it embeds. It is its most basic level, a foundation upon which the database tree can be performed. This ‘base’ in database comes as a stage for databasing itself: a stage without performance is an empty stage, extension of space itself. Databasing projects its own style as a result of its performance, and through this projection comes the exposure of its skin. The “stylistic repetition of acts” in the dramatic case of the gendered database is now revealed as style itself. Like skin and voice, singularity emerges as style and timbre.</p><h5 id="style-and-timbre">Style and Timbre</h5><p>‘Style’ comes from the latin <em>stilus</em>, meaning a sharp object with which you can write: like the stylus of a record player, it is a writing tool. Its meaning extends through writing to the manner in which ‘writing is carried out: the variations and oscillations of the pen and of the text itself, hence resulting in the style of a certain text, or, for that matter, a programming style, or even the style of an author. Beyond writing, style becomes the way in which the body moves, how it looks, whether it is human or nonhuman: the style of a music work, the style of a composer; and beyond, the style of an entire musical period, thus extending style in time and space. Most important, style is a manifestation of the singular. In the sense that style does not lend itself to duplication, and provided that it happens as the apparition of an event, it exposes singularity as such. Style is thus comparable to the voice of a certain author, and also to the sound of the voice itself: timbre. That is to say, style and timbre can be understood equally as the presence of the singular: the signature that comes with the unique and irreproducible timbral quality:<a href="#fn40" class="footnote-ref" id="fnref40"><sup>40</sup></a></p><blockquote><p>In its irreplaceable quality, the timbre of the voice marks the event of language. By virtue of this fact, timbre has greater import than the <em>forms</em> of signs and the <em>content</em> of meaning. In any event, timbre cannot be summarized by form and content, since at the very least they share the capacity to be repeated, to be imitated in their identity as objects, that is, in their ideality. <span class="citation" data-cites="Der82:Mar">(Derrida 1982, p. 296)</span></p></blockquote><h5 id="endless-databases">Endless Databases</h5><p>The skin of the database unfolds in the duration of the performative act. What is exposed as its singularity is the ruggedness of the traces of which it is composed. That is to say, the discontinuities of its reticulated constitution of style. The length of this skin can only be estimated: there is no possibility of rendering it complete. In this fractured state it points to infinity. In this sense, databasing means participating in the infinite, taking a small part of the infinite: performing the infinite within the limits of our own embodiment. Furthermore, the contingent situation of resonance within the frayed spatio-temporal configuration of networks relates to the concept of chaos. I have mentioned earlier the relation between computers and users as understood in terms of complex systems (See <a href="#programming" data-reference-type="ref" data-reference="programming">4.2.2</a>). Considering databasing as chaotic systems brings yet another aspect to the contingency of style.</p><h5 id="database-and-chaos">Database and Chaos</h5><p>Given that this style can be considered as an emergent singularity of databasing, this singularity can be considered as well deterministic. In mathematics, determinism refers to the capacity to predict results, specifically by solving differential equations. This is the case of dynamic systems studied within Chaos Theory. For example, the Lorenz attractor is a system of differential equations discovered by Edward N. Lorenz in 1963, following experiments on weather conditions prediction. The attractor is most famously recognized by the butterfly-like appearance of its visualization, which is also related to the concept of the ‘butterfly effect’ (See Figure <a href="#img:lorenz_plotter" data-reference-type="ref" data-reference="img:lorenz_plotter">[img:lorenz_plotter]</a>). The Lorenz attractor is a dynamic system, which means that it can render very different and quite unpredictable results by minimal changes on their initial conditions, despite the fact that it is indeed a deterministic system. Furthermore, a graph of a dynamic systems presents fractal properties. Considering, thus, databasing as a dynamic system, on the one hand, two performances can be exactly the same if given the same initial conditions and states. This is the case, for example, of the performance of fixed media (digital) works, which at least at the sample level, every bit of it is exactly the same of the original.</p><figure><img src="../img/lorenz_plotter.png" alt=" Plotting of the Lorenz system in Pure Data. " style="width:70.0%" /><figcaption> Plotting of the Lorenz system in Pure Data. </figcaption></figure><p><span id="img:lorenz_plotter" label="img:lorenz_plotter">[img:lorenz_plotter]</span></p><h5 id="fractality">Fractality</h5><p>However, identifying predictability in this way means falling in a cybernetic trap, of which Hayles already warned about when considering Turing’s Test. Hayles reads Turing’s test as a game which, in order to play you are already part of its outcome because you accept its predicates as a condition for playing. In Turing’s case, the moment you enter into the disembodied place where the screen is the only thing you see, you are already a cyborg, and the definition of the human and the nonhuman is already laid out in principle. On the one hand, by equating fidelity of data storage with fidelity of performance, one is already removing the human out of the concert stage, and the question of performance altogether, leaving only the idealist and romantic notion of the work of art in its pure and objective state. On the other, in order to allow for the style of databasing (skin) to emerge, one has to consider not only the actual staging of performance, also the staging of listening itself, which is the possibility condition for the resonating subject of the database to emerge as the communicative apparition of a skin. Therefore, the contingency of style (as chaotic state) can only emerge out of the unpredictable agency of the unfolding. This is how I consider databasing and the contingency of style: the unpredictability of databasing has the qualities of a fractal. On the one hand, because of the fractal dimension, it expands the definition of geometric figures to the infinite. On the other, it presents an unfolding symmetry (self-similarity), which relates to their shapes being replicated nearly exactly in different scales.</p><h5 id="a-music-work-as-a-singularity">A Music Work as a Singularity</h5><p>This aesthetic experience, it must be noted, is of a nature that slips through the cracks of traditional conceptualizations of the work of music as a result of stylistic, or stipulated constraints on the part of the composer, or stochastic procedures. For example, composer Horacio Vaggione goes to great lengths to prove that the musical work affirms itself as singularity, in the particular sense that its rules are only prescribed from within, and always in an “action-perception loop” with the composer <span class="citation" data-cites="Vag01:Som">(Vaggione 2001)</span>. What Vaggione is arguing against, is the tendency of formalized musical processes that had reshaped the black-boxed approach towards composition in CAC : “a composer [unlike a scientist] knows how to generate singular events, and how to articulate them in bigger and bigger chunks without losing the control of the singularities” <span class="citation" data-cites="Vag93:Det">(Vaggione 1993, p. 97)</span>. However, there is a fundamental concern that needs to be addressed in relation to the contingency of style. For Vaggione, style comes to represent the reified status of the rules within a work, insofar as this reification is taken for the starting point from which to compose, and not the result of a composed thing. Consider this quote from an earlier text:</p><blockquote><p>Here lies what seems to be one of the sources of confusion regarding the nature of music composition processes: on the one hand, we must make as careful a distinction as possible between the collective rules and the composer’s own constraints; on the other, this distinction seems irrelevant [because] any primitive (coming from a common practice or postulated ad hoc) is to be considered as a part of what is to be composed, <em>in order to produce a musical work affirming itself as a singularity, beyond an exercise in style</em>. Adorno was of course conscious of this dialectic: his statement about sound material considered not as something “given” but as a “result” of a musical thesis clearly points to this fact. [emphasis added] <span class="citation" data-cites="Vag01:Som">(Vaggione 2001, p. 59)</span></p></blockquote><h5 id="arbitrariness">Arbitrariness</h5><p>Despite the fact that, distinguishing between rules and constraints, that is, between socially and historically established canons —as stylistic conventions—, and locally established postulates to be carried out by the composer —as constraints—, is crucial in defining style in databasing, at the same time both ends collapse into the realm of arbitrariness that composition is made of, for, if any “primitive” of the composition is indeed to be considered “part of what is to be composed,” then style itself becomes a result. This is what Vaggione means by “beyond an <em>exercise</em> in style:” it is not an exercise in the sense of a draft, in the military context of training (practice for the sake of training). Style is not an exercise because it cannot be operative in the sense that it is considered a product of work. That is to say, given that style is the contingent skin that emerges out of the performative action of databasing, if it were considered productively, that is, in terms of a targeted object towards which work is oriented, then it would only result in closure, in a closed object, and thus, it cannot be considered contingent, precisely because it is stipulated from the start as a law to which every composable element abides. This is the case of, in Vaggione’s sense, formalized processes which act as global laws, and in which —comparing it with a marching army following the one-two directive: “no singularities —and hence no specific formal (relational) properties— are here allowed” <span class="citation" data-cites="Vag93:Det">(Vaggione 1993, p. 101)</span>.</p><h5 id="inoperative-style">Inoperative Style</h5><p>However, if style is understood as inoperative, that is, as the unfolding of the performative act of composition, which implies equally the ‘composability’ of all primitives, then, its contingency appears in the form of exposure, not as a closed object, but as an unclosed object, some <em>thing</em> that is exposed and bound to exposure; a thing that exposes us in the same resonance of its touch. Like the marks on our skin, like its wounds; like the cracks of an old house, like debris, wreckages, or any form of residual mark that is the evidence of an event; with forensic intimacy, the contingent style of a musical unwork reveals itself as communication. This is what connects aesthetic experience of style with forensic (musical) analysis as well as with an encounter with the spectral. Furthermore, this is how the spectral itself cannot be but a result of the inoperative, of that which escapes the limits of the work, and that which, by releasing itself from itself, returns to itself like the timbre of the voice. This voice of the unwork is what is ‘invisible’ to it, or better, it is what it can never listen, and in being hidden or silenced from itself is how it becomes available for listening, what begins listening at the first staging of the waves.</p><h3 id="authority">A Specter Of Authority</h3><blockquote><p>Gender is instituted through the stylization of the body and, hence, must be understood as the mundane way in which bodily gestures, movements, and enactments of various kinds <em>constitute the illusion of an abiding gendered self</em>. [emphasis added] <span class="citation" data-cites="But88:Per">(Butler 1988, p. 519)</span></p></blockquote><p>The figure of the author (composer/databaser) is, to a certain extent, exploded as network by the complexity of the system. However, authority is reified into the name because of the interplay among work, productivity, and product. In this section I attempt an approach to the name of the composer not by its work, but from the illusory perspective of authority. However composable all Vaggonian primitives can be, the structure of the database tree is so vast that any attempt to comprehend it as a whole would extend it even further (See <a href="#network" data-reference-type="ref" data-reference="network">5.1.2</a>). However, this determines neither the extent of the performativity of databasing, nor the agency of the human. Quite the contrary, expansion through the network can be considered as the trace of the author, or better, the elongation of the spectral shape of an author. Further, with the performativity of databasing, the databaser too becomes incomplete.</p><h5 id="the-name">The Name</h5><p>The infinitude in the fractality of databasing, however, is at some point reified in a figure or a name. This figure is the place where authority is condensed, and it responds to traditionally essentialist conceptualizations of the romantic author which, despite the many attempts during 20th century,<a href="#fn41" class="footnote-ref" id="fnref41"><sup>41</sup></a> are still in effect today, specifically in the field of music composition. It is not the purpose of this section to criticize this tradition, namely because I don’t consider it relevant for the purposes of databasing. Focusing on it would be missing the point. That is to say, in the case of databasing, such figure of an essential author is simply dislocated and forced upon the structure of the network, and it is anachronic because it constitutes a temporality set against the temporality of networks. Databasing, as resonant performativity already exists beyond this traditional figure of the author. However, in its spectrality that stems from the archontic (See <a href="#archontic" data-reference-type="ref" data-reference="archontic">5.2.3</a>), authority can be seen as the illusory resonance of an author. It is this illusion that I attempt to address here, this ghost which haunts music composition.</p><h5 id="dictionaries">Dictionaries</h5><p>Consider how style is used in some cases of CAC . David Cope’s EMI <span class="citation" data-cites="DBLP:conf/icmc/Cope87">(Cope 1987a)</span>, for example, can be considered a formalization of compositional authority. That is to say, intentional stylization “based on a large database of style descriptions, or rules, of different compositional strategies” <span class="citation" data-cites="Mau99:Abr">(IV 1999, p. 3)</span>. Written in the functional programming language LISP , EMI ’s focus is “style imitation” in order to assist the composer when in front of a “composing block,” provoking the “author into almost immediate action. Any blank moments along the way are immediately filled by simple queries…” <span class="citation" data-cites="Cop87:AnE">(Cope 1987b, p. 38)</span>. Cope’s approach is inherently hirearchical, and thus based on the premise that music is a language. Therefore, Cope designed dictionaries (databases) of MIDI scores representing the internal relations between composed elements. From items in the dictionary, logically correct inferrences are drawn (predicate calculus) <span class="citation" data-cites="DBLP:conf/icmc/Cope87">(Cope 1987a, p. 1)</span>. Thus, EMI is aimed at generalizations that reify the authority of the composer as style:</p><blockquote><p>Years of consistent interactive use have resulted in dictionaries which so complement the author’s own style that compositions show little evidence of the origins (man/machine) of the music. <span class="citation" data-cites="DBLP:conf/icmc/Cope87">(Cope 1987a, p. 179)</span></p></blockquote><h5 id="artistry">Artistry</h5><p>Vaggione, in response to a formalized approach to music —among many that exist in the literature <span class="citation" data-cites="Hil59:Exp Xen92:For Tru76:ACo Ari05:Ano">(Ariza 2005a, Hiller &amp; Isaacson 1959, Truax 1976, Xenakis 1992)</span>—, proposes the equal role of the informal (or craftsmanship) of the composer using computers. In a very different case of the use of databases, consider Roads’ account of Vaggione’s workflow when composing the work <em>SHALL</em>:</p><blockquote><p>These involved arranging microsounds<a href="#fn42" class="footnote-ref" id="fnref42"><sup>42</sup></a> using a sound mixing program with a graphical time-line interface. He would load a <em>catalog of pre-edited microsound</em> into the program’s library then select items and paste them onto a track at specific points on the timeline running from left to right across the screen. By pasting a single particle multiple times, it became a sound entity of a higher temporal order. Each paste operation was like a stroke of a brush in a painting, adding a touch more color over the blank space of the canvas. In this case, <em>the collection of microsounds in the library can be thought of as a palette</em>. Since the program allowed the user to zoom in or out in time, the composer could paste and edit on different time scales. The program offered multiple simultaneous tracks on which to paste, permitting a rich interplay of microevents. [emphasis added] <span class="citation" data-cites="Roa04:Mic">(Roads 2001, pp. 313–14)</span></p></blockquote><p>While this workflow is only representative of certain aspect of the piece in question, it does serve as an example of his concept of craftsmanship. Craftsmanship refers to the manual and direct action of the hand of the composer. The hand, as Makis Solomos very well points out, is not to be understood as being without the tool (mouse) that it needs to use in order to precisely locate sounds on the timeline interface <span class="citation" data-cites="Sol05:AnI">(Solomos 2005, p. 4)</span>. Craftsmanship might be better understood, however, as ‘artistry,’ thus keeping its relation to hand-made crafts, while maintaining a link with articulation, one of Vaggione’s crucial concepts. While articulation relates to the composer’s operativity on multiple time scales, artistry relates to the arbitrariness of choice. It is thus a reaction to the abundandy of radical formalism and automation in CAC <span class="citation" data-cites="Sol05:AnI">(Solomos 2005, p. 3)</span>. Therefore, Vaggione writes, “to write music ‘manually’, note by note, partial by partial, or grain by grain, is an approach proper to a composer, and he should not be embarrassed about using this aspect of his craftsmanship”’ <span class="citation" data-cites="Sol05:AnI">(Solomos 2005, p. 3)</span>. Vaggione built his terminology not in opposition, but in the spirit of reconfiguring CAC from an embodied stance coming from outside information theory. This stance is not only evident in Vaggione’s writings and music. To a debatable extent, it is a point of departure to think of a branch of Argentinian electroacoustic identity that developed in France.<a href="#fn43" class="footnote-ref" id="fnref43"><sup>43</sup></a></p><h5 id="the-work-of-mice">The Work of Mice</h5><p>Instead of being on the rule-based programming of formalization processes alone (keyboard-based input), the artistry of the composer resides in the use of the mouse. The timeline (sequence interface) workflow depends on the pointer. If the presence of the hand of the composer is evidenced by the trajectory (the course of the cursor), it shapes together with the historial of clicks, drag-n-drop motions, etc., the spectral presence of the author. This mouse, as the point of the pointer, the writing device, the ’stilus’, becomes that with which we resonate as listeners. Therefore, we perceive the marks of an authorial skin in the database music of pointers. The Vaggionian singularity-based approach to authority embeds composers and computers in a complex system, allowing for the world of music with computers to be a hybrid one. This is how the specter of the author coexists with the specter of the database, and thus, how databasing and composition reveal themselves to be instances of a performativity that resonates aesthetically through the work of music.</p><h2 id="section:Rethinking_Composition">Rethinking Composition</h2><h3 id="performance">Interlude: Hyperbolic Reactions</h3><h5 id="imagining-composers">Imagining Composers</h5><p>In today’s composition and databasing practices, the probabilities of a composer or a databaser working without computers are very slim. Databasing or composition outside the digital seems rather fictional. However, the very image of a ‘composer,’ which traditionally stems from romantic standards, is already outside the world of computers. This image of composing can be painted as follows: the composer at work, quietly on a desk with pen and paper, transcribing, arranging, making parts, drawing line after line, dot after dot, notating instructions for the performance of an imagined music. Where is the computer in this image of composition? Certainly, placing a computer on this idyllic desk would be anachronic and obtrusive; anachronic, since the romantic quality of the scene would point to the fact that personal desktop computers were not available until late in the 20th century; obtrusive, in the sense that it would attempt against this composer, by interfering with the ‘ethereal’ link between imagination and notation. This reification of the composer already precludes not only the digital, also the many technological devices that have entered music composition over the years, such as tape recorders, or electronics in general. These technological devices have redefined the composer in many ways.</p><h5 id="composers-and-technology">Composers and Technology</h5><p>Georgina Born’s ethnography of IRCAM <span class="citation" data-cites="Bor95:Rat">(Born 1995)</span>, captured how the institutionalization of music composition and technology resulted in hierarchical structures of work dynamics, and how these were coated with false notions of collaboration. Inequalities of social, economical, and political status among technicians and composers within IRCAM became privately evident. Knowing how to use computers and knowing how to compose comprised two irreconcilable poles in the institutional structure. For example, Born describes internal hierarchies such as ‘superuser’ password knowledge, source code access, software licences, and, in some cases, she showed how these hierarchies reflected on internal privacy issues: “workers concocted their various informal ways of protecting privacy and retaining secrecy: blocking the glass walls of their studies, working at night to prevent others knowing what they were doing or even whether they were working at all” <span class="citation" data-cites="Bor95:Rat">(Born 1995, p. 272)</span>.</p><h5 id="playing-with-shadows">Playing with Shadows</h5><p>On the one hand, it is tempting to link this irreconciliation to the extreme reification of the name Pierre Boulez. The obscure dynamics behind this reification, however privately and secretly they were kept within the institution, can be nonetheless seen as the shadow of the more general specter of the music maker. Born’s mysterious but telling anonymization of anyone but Boulez on her transcriptions might attest to this shadow. The music maker has been traditionally considered an outsider, marginalized by society, but simultaneously an integrator of society itself <span class="citation" data-cites="Att77:Noi">(Attali 2009, p. 12)</span>. On the other hand, this shadow might also be that of the computer itself, the structural presence of a fictional intelligence constructed upon first wave cybernetics. That is to say, precisely because the computer projects an insurmountable power that comes from its calculations, the human is inevitably bound to be subordinate, and with this subordination comes the subordination of the composer, and (perhaps) the end of music. This hyperbolic reaction would explain the need for privacy and secrecy of information, the undocumented “oral culture” of Born’s IRCAM , as well as the reversal of the human-computer subordination evidenced in the social strata of the institution. In any case, a composer without computers cannot be imagined today, but this is not due to the practice of composition itself. My argument here is that in any given situation, it is hardly possible to imagine a human without computers at all. This is what media studies has to teach us about the posthuman condition in which we hybridly live, where humans and technology, humans and nonhumans, unfold as interminably networked traces.</p><h5 id="composers-without-computers">Composers Without Computers</h5><p>Composing with or without computers cannot be seen as poles on a continuum upon which the name of the composer writes and rewrites itself. Composing cannot be separated from computers, because the human cannot be separated from the non. At the risk of drawing a straw-man out of this computer-less composer, it is very unlikely in today’s world to imagine a composer that has not googled ‘clarinet multiphonics’ for more than a few YouTube tutorials on the topic. The same can be said for digitized music listening, which, in order to escape it, one has to go to great cult-like lengths to do so: going to instrumental performances, getting a vinyl record or a tape player, etc. To have a concert, therefore, a composer without computers today would need to whisper the score to the performers who would, in turn, play by ear. (‘By ear’, in the sense that they would need to play from memory, since no printed score would exist, for even if the composer wrote the parts, the score would have to be inscribed on a paper, and somewhere along paper networks there is at least one computer.) The composer should also whisper invitations to a few neighbors to be part of the audience. The composer should also demand no recordings whatsoever, while performing for an audience that has been kindly reminded not to bring their cellphones. Even then, the concert would need to take place on an amphitheater to avoid architectural networks, and AUTOCAD ; before the sun sets, to avoid electricity networks altogether while we are at it; away from cities, a car driving by would be unforgivable; so far away that we would, in fact, need to bring non-perishables for the pilgrimage, and even then, packaging networks or agriculture networks would be almost impossible to avoid. And this is precisely the point: in attempting to avoid it, the pilgrimage exists not in space, but in time, and thus it enters into the realm of fiction. The same can be applied to the overloaded case of a composer totally <em>with</em> computers, that is, a computer composer, that would not need the human to write music.</p><h5 id="databasing-without-computers">Databasing Without Computers</h5><p>The same applies to databasing itself. Removing computers altogether from databasing takes us to the world of libraries, encyclopedias, collectors, gatherers. Most important, it takes us to the place databasing occupies within society: to museums, but also to the dynamics of civilization, to church, put simply: to institutionalization itself. That is to say, it relates performance with the archontic, with the oedipal drive to re-place (See <a href="#archontic" data-reference-type="ref" data-reference="archontic">5.2.3</a>), to an infinite return that the structure of the archive imposes upon us. So, if we imagine a computer-less census, we’d have to picture a gatherer of names walking around town, asking out loud for each person’s name and place of residence. Getting rid of networks which might have computers —as in the case of the above painted computer-less composer—, it is clear that the only suitable person for the job would be Irineo Funes (See <a href="#funeslude" data-reference-type="ref" data-reference="funeslude">5.2.1</a>), and the only possible storage medium would be his memory. Hopefully, the reader would consider this resort to hyperbolic fictions less as a means of justification of the hybrid condition of composition and databasing, and more as an absurd parenthesis that brings nothing of criticism to the —still valid— efforts of working ‘outside’ the digital. These efforts are not questioned in regards of their validity, only in terms of their definition, which, for the purposes of this text, is understood as built upon organicist notions of the human: the human as the one, indivisible, complete whole. These notions are precisely those that help reify the image of the composer in its essentiality.</p><h3 id="organic">Working Composition</h3><blockquote><p>And the listening in question here is not that of a given listener, or of a category of listeners one has to take into account; it is rather structural listening in Adorno’s sense —or even, beyond Adorno, a <em>listening without listener in which the work listens to itself</em>. …we hear an organicist concept of the work being strongly articulated [by Schoenberg] (where the work is a whole that doesn’t allow any cuts) and a regime of listening whose ultimate, ideal aim is the absorption or resorption of the listener in the work. A listener who is somewhat distracted, inattentive, who would skip over a few tracks daydreaming —<em>such a listener could fall away like a dead limb</em>. <em>Useless</em>. Bringing nothing to the great corpus of the work. This organicism, in the radical (or structural) tendency that Schoenberg gives it, forms the cornerstone of the construction of a modernist regime of listening. [emphasis added] <span class="citation" data-cites="Sze08:Lis">(Szendy 2008, p. 127)</span></p></blockquote><p>In Peter Szendy’s discussion on Schoenberg’s modern organicism and what he calls “the modernist regime of listening” <span class="citation" data-cites="Sze08:Lis">(Szendy 2008)</span>, ‘listening’ and ‘work’ collapse into each other, and the problem of the music work can be articulated. The image of the composer and the practice of composition can be understood differently, and by extension, databasing will be reconfigured as well, and the database as that which is a product (or work) of databasing will in turn be seen differently.</p><h5 id="the-work-problem">The Work Problem</h5><p>In what does this articulation of the problem of the music work consist of? First of all, why is it a problem? As Szendy suggests with the metaphor of the the self-amputation of the listener, we as the body of listeners (the listening body) would be severed. Put differently, listening itself would be delineated from outside itself. That is to say, with the presence of an object (music work) which, in its interest of perfecting, polishing, and thus giving itself a ‘finish,’ would shape and reshape listening until an ideal listening was achieved. The work would work out listening as work. This is the point: the moment the work of music begins to act as ‘work’ itself, its listening is worked out as well, not by the physicality of the waves in media, nor by the virtuality of perception, but by the concept of ‘work’ itself. The “modern regime of listening” played this through and through, shaping its listeners into an idealized listener. In this sense, this listener displays a measured listening, tailored, developed into different degrees of listening like a <em>gradus ad auscultare</em>, one existing beyond any psychoacoustic measuring.</p><h5 id="working-rules">Working Rules</h5><p>From the shaping of listening by the work, and from the working activity that is performed by the work itself, the presence of the work as an object can be thus traced. In other words, the work of the music work can be considered as the work of an agent in the composition network: the music-work-as-object and the listening-as-object become nodes. In the modernist regime, the hierarchy priorizes the ruler (work-node), and all that can be identified with listening-node is arrived at by subordinating the relations to the work-node, and by restricting the directionality of this relation to being <span class="math inline">→</span> . The only exception is, of course, the extremely cultivated case of composers, which revert the arrow. This exception, however, is not so much an exception, as it is the prescription of the rule and of ruling itself, since it is this reversal what enables the structure in the first place: the ruling of the exception. This is what occurs when the work begins to listen to itself. Which is radically different from the case of a <em>listening</em> that listens to itself. Jean-Luc Nancy, in the foreword to Szendy’s text, considers that “music places us outside of ourselves,” because “…what listens to itself is not just what resounds in the self and what rebounds to the self: this same movement, and this very movement, places it outside of self and makes its rebound overflow. <span class="citation" data-cites="Sze08:Lis">(Szendy 2008 xii)</span>” As I have explained before using Nancy’s concept of the resonance of a return (See <a href="#resonance_of_a_return" data-reference-type="ref" data-reference="resonance_of_a_return">5.1.1</a>), listening is an approach to the relationship in self. Implementing this relationship within the dynamics of listening and work, the previous graph can be revised as follows. ‘Work’ and ‘listening’ would exist as well in relation, with the difference now that it is a relation that exists in a permanent state of overload, redundancy, or excess: <span class="math inline"> ← →</span> .</p><h5 id="a-space-of-difference">A Space of Difference</h5><p>In thinking listening this way, the concept of the work is relieved of its duties, discharged, fired, it becomes unemployed. The regime of listening becomes a listening space, but a space not of equality: a space of difference. Within this space where difference resonates, the music work no longer ‘works’, it ‘unworks’ (See <a href="#inoperativity" data-reference-type="ref" data-reference="inoperativity">5.1.3</a>). That is to say, the relations between the different resonating points in the composition network expose themselves in a state of suspension, or interruption, creating space with the space of their own incompleteness by the fractality of their fracture. Thus, inoperativity is creation, it is techne, but it is a creativity that is necessarily indefinite, incomplete: the moment it becomes a thing it begins to work in the realm of the ‘archi’; the moment it remains suspended upon its limit, it unworks in negation of the ‘archi’. One is tempted to place this inoperativity in utopia, in the very instance of the non-place itself, but then one would forget what is already ‘there’, the fluid medium, as well as gravity itself, which was until recent studies, thought of as unrelated to sound.<a href="#fn44" class="footnote-ref" id="fnref44"><sup>44</sup></a> One would be tempted, equally, to place this inoperativity outside temporality itself, but then one would forget forgetfulness itself. Inoperativity is within the resonating space of an always.</p><h5 id="a-severed-work">A Severed Work</h5><p>What constitutes, then, that moment when the music work becomes a work? How is it possible for the work to become a thing, for the object to become the ruler, for the regime to be built on the first place, if the resonating space is already an inoperative space, interrupted and suspended? I would like to revert Szendy’s metaphor of the amputated limb, and propose that it is the music work itself what is amputated, what falls off, the moment that it becomes a finished thing. Thus, just like the modern inattentive listener falls in the uselessness of its excess, sound ‘outside’ the work is cut from the work, fading out in the uselessness of its excess. Like the human in Kittler’s digitally converged apocalypse, redundancy is out of the question, it is left at the gates of the majestic concert hall, with the rest of the (useless) humans: it is literally and conceptually placed outside architecture itself. The created work, in its essential nature of being a cohesive, coherent whole, separates itself from the world of mechanical waves, and forms the one and only work: the piece of music. A ‘piece’ not because it is in itself incomplete, but because it is the piece of the whole of the work of the composer.</p><h5 id="absorbption">Absorbption</h5><p>I would like to add to this worldview another concept brought by Szendy, that of ‘absorption.’ He claims that it is the absorption of the listener in the work what is the ultimate aim of this modern regime of listening. Not surprisingly, ‘absorption’ is the key concept in Iannis Xenakis’ narrative of the fours stages of degradation of Western Music’s “outside-time structures,” article <em>Towards a Metamusic</em> (1967): “we can see a phenomenon of absorption of the ancient enharmonic by the diatonic. This must have taken place during the first centuries of Christianity, as part of the Church fathers’ struggle against paganism and certain of its manifestations in the arts…” Later, referring to larger structural groupings: “this phenomenon of absorption is comparable to that of the scales (or modes) of the Renaissance by the major diatonic scale, which perpetuates the ancient syntonon diatonic…” Finally, “one can observe the phenomenon of the absorption of imperfect octaves by the perfect octave by virtue of the basic rules of consonance” <span class="citation" data-cites="Xen92:For">(Xenakis 1992, pp. 189–90)</span>. The final stage of this process of absorption and degradation comes with atonalism, which “practically abandoned all outside-time structure” <span class="citation" data-cites="Xen92:For">(Xenakis 1992, p. 193)</span>. However, Xenakis’ narrative contextualizes his sieve theory, devised as a means to “establish for the first time an axiomatic system, and to bring forth a formalization which will unify the ancient past, the present, and the future” <span class="citation" data-cites="Xen92:For">(Xenakis 1992, p. 182)</span>. Further, Xenakis formulated this theory with computers in mind, that is, with its concrete application in computer programs, under the subtitle “suprastructures” <span class="citation" data-cites="Xen92:For">(Xenakis 1992, p. 200)</span>. Therefore, considering the organicity of the work in Xenakis’s overly modern gesture towards unity, metastructure, and mechanization, which was built in reaction to the “poison that is discharged into our ears” as he witnessed the “industrialization of music [that] already floods our ears in many public places, shops, radio, TV, and airlines, the world over” <span class="citation" data-cites="Xen92:For">(Xenakis 1992, p. 200)</span>, how can these notions of inoperativity be found together within architecture? How would this archi-techne be designed? Would it still be the product of the ‘archi’? Where is the poison that Xenakis the architect and composer, was identifying with ‘industrialized’ music? Is it not a product of modernity itself, as the working that listened to itself to the point of working out a Xenakis-listener-node to the extreme?</p><h3 id="practice">The Composer As Navigator</h3><blockquote><p>I am motivated to present this architecture, which is linked to antiquity and doubtless to other cultures, because it is an elegant and lively witness to what I have tried to define as an outside-time category, <em>algebra</em>, or structure of music, as opposed to its other two categories, in-time and temporal. [emphasis added] <span class="citation" data-cites="Xen92:For">(Xenakis 1992, p. 192)</span></p></blockquote><blockquote><p>With [the relational] model any formatted data base is viewed as a collection of time-varying relations of assorted degrees…this collection is called a <em>relational algebra</em>…a query language could be directly based on it…The primary purpose of [relational] algebra is to provide a collection of operations on relations of all degrees…suitable for selecting data from a relational data base. [emphasis added] <span class="citation" data-cites="Codd72relationalcompleteness">(Codd 1972, pp. 1–5)</span></p></blockquote><h5 id="querying-the-sieves">Querying the Sieves</h5><p>If we consider pitches as an outside-time (relational) database, one way of understanding Xenakis’ sieve theory is as a query method, for which E.F. Codd’s model would fit perfectly. The nature of this consideration stems from the application of algebra as a programmable selection mechanism or simply, filters. Both concepts (sieves and relational algebra) have a common link, which is, not surprisingly, the computer itself, and not just any computer, the IBM-7090 .<a href="#fn45" class="footnote-ref" id="fnref45"><sup>45</sup></a> While Xenakis’ experiments were carried out on the IBM-7090 mainframe computer located at IBM-France in Paris, Codd himself worked at the IBM Research Laboratory in San Jose, California. Furthermore, this same computer was used by Hiller and Baker in their realization of MUSICOMP , a pioneering language for algorithmic composition <span class="citation" data-cites="Ari05:Ano">(Ariza 2005a, p. 44)</span>. Most important, the IBM-7090 used the programming language FORTRAN IV, as can be seen by the printed FORTRAN routines for Xenakis’ 1962 work <em>Atrées (ST/10-3 060962)</em> <span class="citation" data-cites="Xen92:For">(Xenakis 1992, p. 145)</span>.<a href="#fn46" class="footnote-ref" id="fnref46"><sup>46</sup></a> Xenakis’s work on sieves came a few years after his experiments on the IBM-7090 , and his sieves program was written in Basic and then in C. However, the experience with FORTRAN IV at the IBM-7090 serves nonetheless as a common ancestor to both Xenakis and Codd. For example, Xenakis’ transcriptions in early CAC systems were performed with tables of outputted computer data. Further, <span class="citation" data-cites="Ari05:Ano">Ariza (2005a)</span> <span class="citation" data-cites="Ari05:Ano">(Ariza 2005a)</span> writes how “the early systems of Hiller, Xenakis, and Koenig all required manual transcription of computer output into Western notation. The computer output of these early systems was in the form of <em>alpha-numeric data tables</em>: each row represents an event, each column represents an event parameter value” [emphasis added] <span class="citation" data-cites="Ari05:Ano">(Ariza 2005a, p. 94)</span>. In this sense, performance in CAC meant interpreting results out of a database.<a href="#fn47" class="footnote-ref" id="fnref47"><sup>47</sup></a></p><h5 id="sound-synthesis-parenthesis">Sound Synthesis Parenthesis</h5><p>(Before continuing, a sound synthesis parenthesis must be opened. While Xenakis praised the speed at which the IBM-7090 could perform computations, Max Mathews <span class="citation" data-cites="Mat63:The">(Mathews 1963)</span>, then director of the Behavioral Research Laboratory at Bell Telephone Laboratories, wrote:</p><blockquote><p>A high-speed machine such as the IBM-7090 , using the programs described later in this article, can compute <em>only about 5000 numbers per second</em> when generating a reasonably complex sound. However, the numbers can be temporarily stored on one of the computer’s digital magnetic tapes, and this tape can subsequently be replayed at rates up to 30,000 numbers per second (each number being a 12-bit binary number). [emphasis added] <span class="citation" data-cites="Mat63:The">(Mathews 1963, p. 553)</span></p></blockquote><p>Mathews’ concern for speed was grounded on the need to achieve sound synthesis, which meant fast computations of the sample theorem. Initially, the first synthesized sound was obtained in 1957, with the (assembly-code written) MUSIC 1 program with the IBM-704 (a predecessor of the IBM-7090 ). Later, when Bell Labs obtained the IBM-7094 —which “was a very, very effective machine” <span class="citation" data-cites="Roa80:Int">(Roads &amp; Mathews 1980, p. 16)</span>—, and in combination with the (then) widely available FORTRAN compiler, Mathews could develop the MUSIC I program, into MUSIC V, which became the first portable computer music language designed for computer music synthesis.<a href="#fn48" class="footnote-ref" id="fnref48"><sup>48</sup></a> I will close this parenthesis, not without returning to this discussion in the following section (See <a href="#improv" data-reference-type="ref" data-reference="improv">5.4.4</a>))</p><h5 id="algebraic-abstractions-for-freedom">Algebraic Abstractions for Freedom</h5><p>Xenakis’ and Codd’s papers came out around the same time: Xenakis’ english publication of <em>Towards a Metamusic</em> was in 1970, Codd’s papers were published in 1970 and 1972. While sieve theory was aimed at providing a plethora of computable sets (or relations) of pitches, according to different temperings of the smallest displacement unit and the selected value for the modulo operator, Codd’s relational algebra was meant the internal structure of a query language for selecting elements based on their relations. Both of these can be considered algebraic abstractions of a selection process. In the case of Xenakis, the abstraction was one held outside-time. This meant that the composer could make a snapshot, or a tomography of the pitch space in order to analyze it, extrapolating structural relations. In Codd’s case, the abstraction was spatial: the query language would be separated from the database itself, allowing a distance between a ‘backend’ and a ‘frontend,’ allowing databasers to perform queries without worrying about internal data structures, memory allocation, since these operations would occur in the background. Both methods came as an extension of freedom on the human operator: by black-boxing hardware-specific programming, the human operator could devise any kind of algebraic queries, thus operating at a higher level of abstraction, enabling a less problematic kind of envisioning. Conversely, Xenakis writes: “freed from tedious calculations, the composer is able to devote himself to the general problems that the new musical form poses, and to explore the nooks and crannies of this form while <em>modifying the values of the input data</em>…” [emphasis added] <span class="citation" data-cites="Xen92:For">(Xenakis 1992, p. 144)</span>.</p><h5 id="a-cosmic-vessel-and-an-armchair">A Cosmic Vessel and an Armchair</h5><p>Therefore, the composer delegates to the computer the minutiae of arduous iterative computations: precisely what the computer is better at than the human. As a result, in Xenakis’ view, and in resonance with programmer Charles Bachman’s claim for the <em>The Programmer as Navigator</em> <span class="citation" data-cites="Bachman:1973:PN:355611.362534">(Bachman 1973)</span>, the composer became a pilot:</p><blockquote><p>With the aid of electronic computers the composer becomes a sort of pilot: he presses the buttons, introduces coordinates, and supervises the controls of <em>a cosmic vessel sailing in the space of sound</em>, across sonic constellations and galaxies that he could formerly glimpse only as a distant dream. <em>Now he can explore them at his ease, seated in an armchair</em> [emphasis added] <span class="citation" data-cites="Xen92:For">(Xenakis 1992, p. 144)</span></p></blockquote><p>Codd’s and Xenakis’ propositions were abstractions deeply rooted in and contextualized against a backdrop of their own fields. Xenakis wrote against the current state of Western Music with its “degradation of outside-time structures”, the “followers of information theory” and the “intuitionists.” Codd wrote against the previously developed hierarchical and network database models. Most important, these tools and their development had the human operator’s considerations in mind. The composer, like the databaser, would engage in a rudimentary and limited, but still present, feedback process at the <em>input</em> level. That is to say, unless rewriting the code, which consisted in a very long and economically expensive process combining punch cards and magnetic tapes, the composer and the databaser could change the input several times, achieving different outputs in a matter of hours.<a href="#fn49" class="footnote-ref" id="fnref49"><sup>49</sup></a> For example, queries made on the relational model would appear on screen at a very fast rate, thus enabling better tuning of the input in relation to a wanted output. Likewise, the composer could modify the input values to highly complex calculations that would otherwise take a long time, or be error prone. The limitation, of course, is the level of intervention with the code itself, which the overall circuitry would itself complicate; criticism on account of this shortcoming of the circuit would thus be rendered anachronic, but recalling these limitations places composition and databasing in perspective.</p><h3 id="improv">The Database As Performer</h3><p>I would like to take an improvisational turn that would make Xenakis fall off his armchair. Xenakis’ fall would be contemplated against the spirit of the later discussions on interaction that came with George Lewis and <em>Voyager</em> <span class="citation" data-cites="Lew93:Put Lew99:Int Lew00:Too">(Lewis 1999, 2000; Rowe et al. 1993)</span>. Lewis called his approach “a improvisational, nonhierarchical, subject-subject model of discourse, rather than a stimulus/response setup” <span class="citation" data-cites="Lew99:Int">(Lewis 1999, p. 104)</span>. Thus, the activity of the composer was reconfigured in networked relation <em>with</em> the computer. That is to say, Xenakis’ metaphor of the computer as pilot, would be turned upside down, altogether reconfiguring the navigational metaphor: the ship begins to navigate itself.</p><h5 id="the-computer-as-a-musical-instrument">The Computer as a Musical Instrument</h5><p>It is now pertintent to bring back Max Mathews “computer as musical instrument” <span class="citation" data-cites="Mat63:The">(Mathews 1963)</span>. The architecture of MUSIC-V is buit on concept of the computer as an instrument that the composer performs by providing it a score. The three stages of data flow (reading, sorting, and executing) are modeled from three music concepts: score, metronome, and instrument. It is significant that two (human) elements of (european) music tradition (composer and performer) are missing from this triad, as well as the programmer. (A fourth missing element, the improviser, will appear further down this text.) On the one hand, the hybrid musical instrument that the computer represented already collapsed three concepts into one, resulting in a hybrid score/metronome/instrument. On the other hand, it can be argued that by this ellision, the three missing human terms have collapsed into one another, forming a new hybrid definition of composer, performer, and programmer. In any case, this hybridity became evident in the music work itself, as can be read from a rethorics of control in favor of the composer:</p><blockquote><p>So far I have described use of the computer solely as a musical instrument. The composer writes one line of parameters for each note he wishes played and hence has complete control of the note. He is omnipotent, except for lack of control over the noise produced by the random-number unit generators. <em>Here a minor liberty is allowed the computer</em>. [emphasis added] <span class="citation" data-cites="Mat63:The">(Mathews 1963, p. 557)</span></p></blockquote><h5 id="a-minor-liberty">A Minor Liberty</h5><p>As can be read at the end of the introduction to MUSIC-V <span class="citation" data-cites="Mat63:The">(Mathews 1963)</span>, the extent of this “minor liberty” was measured against Hiller and Isaacson’s previous work <span class="citation" data-cites="Hil59:Exp">(Hiller &amp; Isaacson 1959)</span>, which Mathews describes as an extreme case of the computer as composer: “the computer can be given a set of rules, plus a random-number generator, and can simply be <em>turned on</em> to generator any amount of music” <span class="citation" data-cites="Mat63:The">(Mathews 1963, p. 557)</span>. On the one hand, Mathews’ argument is based on the “omnipotence” of the composer in front of the computer. Control of the music work is not something that can be delegated to the computer, unless it comprises lengthy calculations of pseudorandomness. On the other hand, as Ariza has shown, the computer output of early CAC has been often misconceived in the literature as directly musical output, disregarding the extensive transcription work on the part of composers <span class="citation" data-cites="Ari05:Ano">(Ariza 2005a)</span>. Nonetheless, Mathews’ “minor liberty” can be considered as a reassurment for the reader that computers would not take control over music, let alone over the world. As I see it, arguing for control while granting some liberty relates to a negotiation between composer’s work and computer time. Because of the correlation between sonic complexity and parameter input, “the composer must make his own compromise between interest, cost, and work” <span class="citation" data-cites="Mat63:The">(Mathews 1963, p. 555)</span>. Pseudorandom generators introduced complexity in an efficient way <span class="citation" data-cites="fdch/papers/spectral">(Cámara Halac 2018a)</span>. Therefore, in an economical choice, arguing for omnipotence allowed for some aesthetics agency to come from computers.</p><h5 id="the-computer-as-a-player">The Computer as a Player</h5><p><span class="citation" data-cites="Row92:Int">Rowe (1992)</span> <span class="citation" data-cites="Row92:Int">(Rowe 1992)</span> identified two paradimgs within interactive systems: <em>instrument</em> and <em>player</em>. The instrument paradigm comprises systems in which performance gestures are sensed (collecting gestural data), processed (reading and interpreting data), and a response (sonic output) is elaborated. The player paradigm comprises the creation of “an artificial player, a musical presence with a personality and behavior of its own…” <span class="citation" data-cites="Row92:Int">(Rowe 1992 Chapter 1)</span>. Therefore, the instrument itself contains embedded processes that grant some level of independence. This means that the composer intentionally relinquishes control of the artwork’s structure to the system itself. Like Vaggione’s concept of the computer as a complex system in which the composer “is imbedded in a network within which he or she can act, design, and experience concrete tools and (meaningful) musical situations” <span class="citation" data-cites="Vag01:Som">(Vaggione 2001)</span>, the human node breaks the traditionally hierarchical structure of composer-work. What this amount to is a distributed authority of the work among the elements of the system. For example, in <em>Voyager</em>, “the computer system is not an instrument, and therefore cannot be controlled by a performer. Rather, the system is a multi-instrumental player with its own instrument” <span class="citation" data-cites="Lew99:Int">(Lewis 1999, p. 103)</span>. The computer becomes an improvisation partner. While the limitations of computer capabilities precluded more complex conceptualizations of the type of interactivity between computer and composer in MUSIC-V , as personal computers became affordable the type of negotiations no longer depeded on economic decisions. For Lewis, this negotiation existed sonically between computer and improviser:</p><blockquote><p>There is no built-in hierarchy of human leader/computer follower, no ‘veto’ buttons, pedals, or cues. All communication between the system and the improviser takes place sonically. A performance of Voyager is in a very real sense the result of a process of negotiation between the computer and the improviser. <span class="citation" data-cites="Lew99:Int">(Lewis 1999, p. 104)</span></p></blockquote><h5 id="programming-decisions">Programming Decisions</h5><p>However, in order to implement concepts coming from artificial intelligence such as machine listening and learning, the complexity of the program itself increases exponentially. In light of these difficulties arising from programming, in response to Lewis’ criticism of the MAX patching paradigm rooted on trigger-based interactivity, Miller Puckette responds: “If you wish your computer to be more than just a musical instrument —if you want it to be an improvisation partner, for instance— you need a programming language. One thing people in this situation might want to do is write MAX external C procedure” <span class="citation" data-cites="Lew93:Put">(Rowe et al. 1993, p. 8)</span>. As Rowe writes:</p><blockquote><p>To arrive at a more sophisticated interaction, or <em>cooperation</em>, the system must be able to understand the directions and goals of a human counterpart sufficiently to predict where those directions will lead and must know enough about composition to be able to reinforce the goals at the same moment as they are achieved in the human performance. <span class="citation" data-cites="Row92:Int">(Rowe 1992 Chapter 8)</span></p></blockquote><p>Furthermore, the player paradigm and its subsequence reconfiguration of authority is possible by means of an implemented database: the computer stores features during the course of the performance, which are then averaged over time, and which serve as guides for the sonic outcome on the part of the computer. As I mentioned earlier, while the guidance of the database provides paths through uncharted territories, it also hides other paths (See <a href="#computer:free" data-reference-type="ref" data-reference="computer:free">4.3.3.1.4</a>). <em>Voyager</em> indeed brings interactivity between human and nonhumans to another stage, and because of it, music composition can be seen differently. However, the intricacies of the programming decisions are still in play, specifically in the modelling of musical concepts within data structures.</p><h5 id="anachronic-composers">Anachronic Composers</h5><p>This notion of interactivity differs greatly from Xenakis’ (modern) composer. He is sitting quietly in his armchair pressing buttons in 1962. By pressing them and inputting certain values, he controls the output, since he knows beforehand the internal mechanisms that are embedded in the software. This image of the modern composer in front of computer technology can also be found in, for example, Edgar Varèse: “The computing machine is a marvelous invention and seems almost superhuman. But, in reality, it is as limited as the mind of the individual who feeds it material” <span class="citation" data-cites="Var04:The">(Varese 2004, p. 20)</span>. Varèse’s words, however, refer to the creative limit that a computer might have, which is always a function of the input and, by extension, of material itself. Furthermore, in relation to electronic technology, he writes: “like the computer, the machines we use for making music can only give back what we put into them” <span class="citation" data-cites="Var04:The">(Varese 2004, p. 20)</span>. Therefore, from these images of Varese-composer and Xenakis-composer, two axioms can be extrapolated: first, that composers do not lose control of the output; second, that the way to interact with computers is precisely telling them what and when to do it, so that the user is in total operative control. It is against these two axioms of computers and composition that Lewis’ work in the late 1980s and 1990s can be contextualized. More precisely, it is because of the anachronic presence of the modern ‘eurocentric’ composer, and of its popularity among computer music history, that Lewis brings into surface the question of interactivity.</p><h5 id="section"></h5><p>Placing MAX into perspective by commenting on the social and cultural environment of computer music of the late 1980s, Lewis writes:</p><blockquote><p>‘interaction’ in computer music has moved from being considered the province of kooks and charlatans (I’m proud to have been one of those), to a position where composers now feel obliged to ‘go interactive’ in order to stay abreast of newer developments in the field <span class="citation" data-cites="Lew93:Put">(Rowe et al. 1993, p. 11)</span>.</p></blockquote><p>The way in which interactivity was considered in the ‘interactive’ music made with MAX was, for Lewis, determined by a fundamental feature of program —the ‘trigger’—, which, in turn, was grounded on a more general programming concept: the conception of the patching window as a digital equivalent to the analog synthesizer’s patching mechanism, where graphic cords are equivalent to cables, equating data flow with voltage flow. Nonetheless, the trigger (‘bang’) is a feature, not a bug, unless it is used as an extension of the stimulus/response paradigm of interactivity. In other words, in resonance with Vaggione (See <a href="#style" data-reference-type="ref" data-reference="style">5.3.3</a>), subordinating music events to triggers by a human operator brings out a certain military metaphor which Lewis calls “hear and obey” <span class="citation" data-cites="Lew93:Put">(Rowe et al. 1993, p. 11)</span>. This metaphor can easily be extended to that of weaponry itself, and to the unfortunate naming of ‘bang’ method of objects, a method which (generally) triggers the object’s core routine.<a href="#fn50" class="footnote-ref" id="fnref50"><sup>50</sup></a> In order to address this shortcoming of interactivity, Lewis relates it to rudimentary mental processes, or as he puts it, to “amoeba- or roach-like automata” <span class="citation" data-cites="Lew93:Put">(Rowe et al. 1993, p. 11)</span>. In this sense, not only interactivity itself is at stake by the presence of a simple model of interaction. For Lewis, the crucial aspect of this model is the empowering of the image of the composer. This intentionally (very) simple automaton promotes two fundamentally hierarchical notions that Lewis attempts to deconstruct. On the one hand, the composer as controller who would never relinquish control of the music work, that is, the modern (eurological) image of the composer, and the old ghost train that comes with it: “The social, cultural, and gender isolation of the computer music fraternity (for that is what it is)” <span class="citation" data-cites="Lew93:Put">(Rowe et al. 1993, p. 11)</span>. This image leaves improvisation, together with non-eurological thinking out of the scope of contemporary music research. On the other hand, the human operator, as the higher (architectural) mind that would not allow for the nonhuman to become an operational agent beyond the instructions for which it was designed. In this sense, the simple-level automaton is a symbolic restrain representing the classical concept of the human itself, which allows a non-threatening relation between man and machine that can be considered functional, productive, and operative.</p><h5 id="nonhuman-composers">Nonhuman composers</h5><p>One is tempted to claim that the first of these images —the reified composer— is determined by the second —the reified human—, and that their relation is a matter of depth or inheritance. Thus, in order to redefine the composer one would have to redefine the human. In turn, this depth would be measured against that which is nonhuman, and by extension, that which is non-composer. In Lewis’ narrative, this entails the redefinition of composition itself by making the non-composer (e.g., what was eurologically considered the ‘improviser’ or the ‘performer’) resound back into composition, regrouping the concept ‘composer’ itself, but not as a whole, since now the extent of its terms have found places within a networked system. This is precisely what he does in <em>Voyager</em>. The composer, like the human, became regrouped in hybridity. A hybridity that cannot be considered ‘on its own’, since it escapes any idea of ownness (or oneness). Therefore, a hybridity that is expanded in networked resonance. It is in this sense that Lewis’ proposal is geared towards an interactive (computer) music <em>not entirely</em> driven by input.</p><h5 id="fractured-works">Fractured Works</h5><blockquote><p>The composer therewith relinquishes some degree of low-level control over every single bloop and bleep in order to obtain more complex macrostructural behavior from the total musical system. The output of such entities might be influenced by input, but <em>not entirely</em> driven by it. [emphasis added] <span class="citation" data-cites="Lew93:Put">(Rowe et al. 1993, p. 11)</span></p></blockquote><p>It is precisely this ‘not entirely,’ as a negation of wholeness, what begins to question the basis upon which our general concept of the human is built, and by extension, the agency of everything that falls outside of its definition. It is the beginning of a breakage, a crack on the foundation of Xenakis’ (old) armchair, from which the state of suspension of the concept of the music work can be understood:</p><blockquote><p>With this in mind, it becomes easier to see that Voyager is <em>not really a ‘work’</em> in the modernist sense —heroic, visionary, unique (Foster 1983). Rather, I choose to explore allegory and metatextuality, the programmatic, the depictive— and through embedded indeterminacy [pseudorandom generators], the contingent. Ultimately, the subject of Voyager is not technology or computers at all, but musicality itself. [emphasis added] <span class="citation" data-cites="Lew99:Int">(Lewis 1999, p. 110)</span></p></blockquote><p>Furthermore, what this fracture reveals is hybrid nature of the notion of what is real and what is virtual. Understood traditionally, or better, understood under the stipulations of the first wave cyberneticians, the composer, being the real factor in the constitution of the (modern) image of the composer, is faced with the virtuality of the computer. Upon this encounter, the virtual comes as a form of threat to replace that which is real. In this sense, this is how I would like to approach Lewis’ consideration of <em>Voyager</em> as “not really a work.” I hope the reader would forgive me for having borrowed these adjectives out of context —‘entirely’ and ‘really’— so as to allow my argument to echo with Lewis’ for a while. On the one hand, as Lewis claims, the goal of the interactivity between the composer and the computer is to allow the real and the virtual, “virtuality and physicality,” to engage in the production of a hybrid that “strengthens on a human scale. Seen in this light, virtuality should enhance, not interfere, with communication between us” <span class="citation" data-cites="Lew99:Int">(Lewis 1999, p. 110)</span>. Therefore, considering the role of virtuality after new media integrated theories of embodiment, the computer reveals to the human —composer, improviser, performer— the very condition of its own virtuality, that is, virtuality itself within the human. In the case of <em>Voyager</em>, this virtuality is sonic, it comes as the “emotional transduction” that Lewis aims for with this computer system. Therefore, it can’t be ’really’ a work, because it is virtuality itself resounding back. Another way to approach this is the fact that the computer can be said to be ‘listening’ to the performer, given that its real-time analysis is content-based, using techniques that have been applied to music information retrieval over the years (See <a href="#mir" data-reference-type="ref" data-reference="mir">4.3.1</a>).</p><h5 id="databasing-vessel">Databasing Vessel</h5><p>Understood as a listener, <em>Voyager</em> engages not only with signal processing at the lower level, it engages with the resonating process of the relation to self. Furthermore, the computer is not only listening, it is <em>databasing</em>, because it is keeping record of the listened features, and in so doing, it becomes empowered with the database itself. This database of actions, however, is the sonic trace of the performance itself, which is what is most surprising of its agency, and what resounds most in time. Therefore, far from being ‘really a work’, but also far from Lewis’ notions of narrative in the sense of “allegory and metatextuality, the programmatic, the depictive” <span class="citation" data-cites="Lew99:Int">(Lewis 1999, p. 110)</span>, I consider <em>Voyager</em> an unwork of music, one that puts into question —though, to a certain extent— the operativity of the music work itself. To a certain extent, because the notion of productivity and cohesion are still present within Lewis’ music and texts, and also, to the (paradoxical) extent that it is still a ‘work,’ a destiny that somehow manages to persist within the practice of composition. Nonetheless, and without a doubt, Lewis’ claim for the “non-eurocentric computer music” <span class="citation" data-cites="Lew99:Int">(Lewis 1999, p. 107)</span> can be a starting point to the conceptualization of the unwork.</p><h3 id="music">The Severed Object Of Music</h3><blockquote><p>[The] Heideggerian ‘work of art’ is able to present a unified picture that may be used for political purposes [it] is only what it is in the world that it opens…Nancy is seeking a ‘workless’ or ‘unworking’ work, <em>a work that refuses to create itself as a total work</em>. Hence, Nancy proposes an artwork that would offer itself as a permanently open whole, the concept of art remaining undecided and lacking anything that might unify it. [emphasis added] <span class="citation" data-cites="Gra15:The">(Gratton &amp; Morin 2015)</span></p></blockquote><h5 id="an-incomplete-object">An Incomplete Object</h5><p>I would like to refer once again to Jean-Luc Nancy’s concept of inoperativity (See <a href="#inoperativity" data-reference-type="ref" data-reference="inoperativity">5.1.3</a>), this time in relation to the music object. I argue that, given that the inoperativity of the listening experience reveals itself as the interaction between resonance —as the <em>différance</em> within sense and sensuality— and the unworking of the network, its resulting object, instead of being a complete whole —a finished, integral ‘thing’, or even, a ‘piece’<a href="#fn51" class="footnote-ref" id="fnref51"><sup>51</sup></a>—, it becomes a severed music object. This object is different from Pierre Schaeffer’s music or sound object, which comes to represent material with which to work. Neither it is related to Vaggione’s concept of object, which comes from object-oriented programming, meaning every composable primitive, from the micro to the macro. In both of the above, the object is used to provide, though not without their author’s intervention, a notion of <em>coherence</em> to the work.</p><h5 id="remains-of-listening">Remains of Listening</h5><p>The object I am referring to resides in memory, as the remains of the event of an exposure. It is inherently linked to the fractured way in which our own memory works, and it is impossible to define, since it has no beginning and no end. Its dimensionality includes both beginning and ending simultaneously. This object is the spectral evidence of a musical event, or better, of the happening that takes place in listening. In being evidence, it becomes subject of analysis, it is forensic. In being fractured, it is the evidence of a destruction. In being severed, and this is the central aspect that I would like to focus on, risking simultaneously the severing of the object itself, it becomes the evidence of a sacrifice. If it can be said that the music object is a severed object, then the question of its severing necessarily relates to the question of listening. Therefore, by listening —and, by this, I mean entering in resonance with resonance itself, exposing the self to that which returns to itself— I participate in this severing, because in listening I choose what to listen in spite of being already deprived from that choice.</p><h5 id="sources-and-sorcerers">Sources and Sorcerers</h5><p>The sounds onstage are always before and after the staging. The severed object of music is what, as listeners, we grab from the stage, what we choose to rip from the sounding waves, and also what we cannot help but feeling so much a part of us before noticing it is happening. Severing is yet another way of thinking the aesthetic experience of listening, but it is not as passive as it seems. Severing empowers the listener, it is the tool of listening, the reversed stilus, the inverted mouse, the part of the human that necessarily is nonhuman. With it, we can make the world appear, but only as a fraction, because ‘it’ can never be <em>completely</em>. The severed object of music is always severed, but never in the same way, since there are as many severings as there are listeners, and as many listenings as there are moments. In this difference, what is resonating is the object of music, which is never one and the same because it is a singularity resonating in plurality. Composers have traditionally been considered a ‘source’ of this object, or better, the one at the door, the key keeper that has access to the door that opens up the flow of inspiration. The composer, but also the programmer with access to the source code, which unless it is opened, is hidden to the rest; and, unless you know the language, it is complete pseudo-linguistic nonsense with weird punctuation marks, sometimes closer to poetry than it is to extreme formalism.</p><pre data-caption="Little words doing things" data-captionpos="b"><code>#!/bin/bash

# Palabritas que hacen cosas

while true
do
    for ever in rose is a
    do 
        say $ever
        sleep $((RANDOM/10000))
    done
done
</code></pre><p>In this access to the source, the programmer and the composer are traditionally kept at a distance, as if their listening were of some other sort, engaging with the very essence of the source, drinking the water from the originary fountain, satisfying an originary thirst. Therefore, if this is the role of the composer and the programer, if this is their relation to the source, then, they are the first to perform the severing. In the hierarchy of the consequent severings, they are at the top. Further, if they are the first severers, they are the first who perform the first listening. They are the listeners at the top of the mountain, next to the source of all fountains. On the way in and out of the world, the sorcerers of condensation.</p><h5 id="naming">Naming</h5><p>I would like to point out now, that it is not my intention here to sever the head of the sorcerer, because it is an illusion that does not allow me to do so. It is not my illusion, although I have described how I interpret it, and it comes as a product of a reification of the composer, but also of the human itself as the one and only owner of the world —that is, owner of the mountain itself, and of the water, and every particle of the one and only universe. In being in resonance, listeners become the resonating world, that is, the self begins to resonate as space. In this sense, it is the world what is listened to, and it is a world that has no apparent origin. However, the composition —the written score, like the written code— propose their own origin —the composer, the programmer. Thus, they give an origin to the world itself by providing an answer (a name) to the question of creation: Who created this music? <em>this</em> composer. The answer, therefore, has a ‘this’ that comes in the form of the name of the composer. This name becomes attached to the flowing of the source. Therefore, the name of the composer is like a timbre stamp that is applied to the listening experience itself, and further, it is the severing style itself that can be named. The name of the composer becomes a synecdoche of the source itself, directly naming part of the source. This applies, quite literally in some cases, to the name of the program and the name of the programmer.<a href="#fn52" class="footnote-ref" id="fnref52"><sup>52</sup></a></p><h5 id="dynamics">Dynamics</h5><p>Furthermore, the activity of the sorcerer lends itself to its signature. In other words, the manner in which the composer defines the music, from beginning to end, becomes the shape of the music, understanding ‘shape’ or ‘form’ as something that is at once behind and in front of the singularity of the listened music. It is behind, because it is the activity of sound sources —speakers, musical instruments, or simply media in general—, the movement of air pressure. It is in front, because it filters the memory of the activity of sound sources. However, this composed shape and the singularity act together in the moment of listening. The question is, then, regarding the dynamics of this activity. Given that this activity happens during listening, what I addressing now is precisely how the shape of the music interacts with the listening itself. That is to say, the interaction between shape —but also the form, the idea— and the singularity of the listened. Interaction, here, refers to the shared activity that occurs ‘inside’ listening itself, and it happens ‘inside’ because of the severing that needed to occur prior —or immediately at— the resonating oscillation of air pressure. This is what I consider the moment of listening that is none other than listening to music. However, once this severing has occurred, and within its momentum, it is the internal dynamics that enter into play, and it is the shape of the music what begins to delineate the shape of the listened.</p><h5 id="masterwork">Masterwork</h5><p>Understood in this way, that is, the shape of the music as a force that produces a certain listening experience, therefore, the internal dynamics are already written. The singularity of the listened becomes (almost) one and the same with the shape of the music. ‘Almost,’ because it is not that the listened brings no resistance to this ideal force. The singularity of the listened is resistance itself, like I have mentioned before in relation to the trace (See <a href="#human" data-reference-type="ref" data-reference="human">5.2.2</a>). It acts as resistance itself, and its force is not enough to resist the command of the excellent work. This is the very presence of the masterwork, at work, the work of a master that requires the slave —a slave that is not the rest of the works but the outshunned singularities that have been muted by its very own presence. ‘Almost,’ in the hope that its work can be relativized, disarticulated, disentangled from the source of sources, brought down the stream to the place where singularities can resonate in endless forms of matter. However, the problem is now of a different sort. Even if resisting forces match those of the masterwork, then, like Derrida’s concept of a paralysis of memory, we can encounter a paralysis of listening itself. This paralysis. This might (also) be what Szendy means, as well, by the cutting loose of the inattentive listener in modernity, but in a different way. It is not a paralysis caused by distraction, it is a paralysis caused by the very force that is needed to match the force of the master work. It is a paralysis that is directly called for from outside —from the shape of the music itself—, one which prevents any further listening. This is what is called for by the work of the masterwork: pure —and utterly ideal— silence.</p><h5 id="architecture-of-obedience">Architecture of Obedience</h5><p>Therefore, within these dynamics of work, what results is a function of the predicates, it is the architecture of obedience that is written in the form of a music work, with the one and only aim which is for it to ‘work.’ Thus, the composer engaging with this dynamics of working out the work, of creating the structures, becomes the architect of the listened, the creator of a listening that of which he himself is the only chief. The sorcerer in charge of quenching a thirst that is only there because it is always already there, beforehand, instantiated with its own creation. The question now is how can this dynamics be approached once that I have recognized that it is there. How can composition continue, a composition that does not participate in this dynamics? A composition that is not a force? A composition that is not ‘really’ or ‘entirely’ a composition? A composition that does not impose its shape? A music work that is not a work but that still resonates within listening?</p><h3 id="anarchy">Anarchy And The Unwork</h3><p>What characterizes the aesthetic dimension in the severed music object of the composition that does not impose its own listening is inoperativity. In this sense, the practice of music composition can be understood in terms of Nancy’s positive, active force of unworking. The condition of unworking in relation to works of art is exposed by a certain resistance present in the unwork of art. This resistance is a force of interruption and suspension that prevents the notion of a whole to reach completion. The case is quite different from that of the ‘open’ work, since the work never reaches completion.</p><h5 id="place-in-common">Place in Common</h5><p>The unwork radically differs from the notion of an open work as is the case, for example, of Umberto Eco’s famous formulation that “the work of art is a complete and closed form in its uniqueness as a balanced organic whole, while at the same time constituting an open product on account of its susceptibility to countless different interpretations…” <span class="citation" data-cites="Eco04:The">(Eco 2004)</span>. Instead of openness being located in the interpretation, the opennes in inherent to the hybridity of its construction. The construction, in turn, is a result of the reticulated and fragmented state of exposure between the human and the nonhuman. In this sense, the limit of the unwork is the exposure of exposure itself, that is, an instantiation of the place in common.</p><h5 id="disintegrated-imperative">Disintegrated Imperative</h5><p>I would like to analyze the inoperativity of the music in relation to the dynamics of the shape of the unwork and the singularity of the listened. The former, in being a disintegrated imperative —i.e., without the integrity that is required of the imperative for it to work as command and instruction—, cannot behave as a force in its own right. This is not to mean that it ‘fails’ as a force, for if this were the case, the failure would be its paradoxical success. At this point it would be useful to revise Kim Cascone’s consideration of the aesthetics of failure <span class="citation" data-cites="Cas00:The">(Cascone 2000)</span>. In his analysis of the ‘post-digital’ culture of the late 1990s, Cascone identified electronic music outside academia as one related to the unintended uses of computer music software, also known as glitch art:</p><blockquote><p>It is from the ‘failure’ of digital technology that this new work has emerged: glitches, bugs, application errors, system crashes, clipping, aliasing, distortion, quantization noise, and even the noise floor of computer sound cards are the raw materials composers seek to incorporate into their music. <span class="citation" data-cites="Cas00:The">(Cascone 2000, p. 13)</span></p></blockquote><h5 id="blind-experimentation">Blind Experimentation</h5><p>Within what he called the “cultural feedback loop in the circuit of the Internet” —where artists engage with download and upload of software tools and artworks— Cascone describes a ‘modular’ approach regarding music creation as being grounded in the use of (recorded) samples and later mixing <span class="citation" data-cites="Cas00:The">(Cascone 2000, p. 17)</span>. His argument is that “electronica DJs typically view individual tracks as <em>pieces</em> that can be layered and mixed freely” [emphasis added] <span class="citation" data-cites="Cas00:The">(Cascone 2000, p. 17)</span>. In atomizing this use of samples, glitch art descended to the micro-level, but precisely by this descent, it sacrificed the whole for the parts, that is, it became a case of extreme modularity that “affected the listening habits of electronica aficionados” <span class="citation" data-cites="Cas00:The">(Cascone 2000, p. 17)</span>. Therefore, Cascone’s conclusion is to call for new tools “built with an educational bent in mind” <span class="citation" data-cites="Cas00:The">(Cascone 2000, p. 17)</span>, bridging the gap between academic and non-academic electronic music, and therefore illuminating glitch music “past its initial stage of blind experimentation” <span class="citation" data-cites="Cas00:The">(Cascone 2000, p. 17)</span>.</p><h5 id="doctoring-the-glitch">Doctoring the Glitch</h5><p>It must be noted that his inclination towards bringing academic knowledge to the academy of the Internet refers not only to computer music software. Professors, generally of computer music techniques, in several universities across the USA have been openly uploading class materials, patches, softwares, and many other highly useful technical information; not to mention the free online publishing of conference proceedings that have spawned in the last 20 years. Cascone’s rendering of this educational turn can be understood with an authoritative and dated tilt on his end. Particularly, consider what he writes in relation to the form of glitch music, which is his the last arguing moment before his claim for education:</p><blockquote><p>But it seems this approach affects the listening habits of electronica aficionados…the ‘atomic’ parts, or samples, used in composing electronica from small modular pieces had become the whole. This is a clear indication that contemporary computer music has become fragmented, it is composed of stratified layers that intermingle and defer meaning until the listener takes an active role in the production of meaning. <span class="citation" data-cites="Cas00:The">(Cascone 2000, p. 17)</span></p></blockquote><h5 id="unnecessary-blindfolds">Unnecessary Blindfolds</h5><p>How are we to interpret this call for education? What is the center of this education: music technology, composition, or listening? If fragmentation, modularity, stratification, and deferred meaning are ‘affecting’ listening habits, are these ‘habits’ themselves that need to be taught? Or is the structure of the music in desperate need of medical attention? These ambiguities in his argument, however, I chose to understand as coming out of the main premise of the text, that of extending the concept of failure from the technology itself to the analysis of the work. Thus, in Cascone’s view, the aesthetics of failure of the late 1990s is still ‘failing’ to enter academia because it is itself ‘failing’ to achieve the same standards of formal cohesion that are required by the modern conception of the music ‘work’. Therefore, instead of finding an academic cure for blind experimentalism, I would claim to understand failure itself as an unnecessary blindfold since, at least in my consideration of the unwork, if there is no notion of success in the technology involved, there need not be any in the work itself. The success, if any, exists within the composer, and as such, it does so in relation to the very goal of disintegrating the imperative. This success is unrelated to popularity, for example, as is the case with software production, in which more users mean generally more chances of survival. This success is unrelated to value, since there is no measuring system that can determine how much of the imperative was disintegrated. In being for the composer, success is inevitably private, a personal construction, like any other personal growth, or the overcoming of fears.</p><h5 id="spectral-remains">Spectral Remains</h5><p>The unwork cannot behave like a force, but it can be considered the spectral remains of a force. In this sense, if there is an illusion of a force, it must appear as wreckage, an after dream, a mirror that shows us our skin of the past, the ruins of an empire, or the humidity creeping through the cracks of an old house. However, and this is a big however, these allusions to vessels, to the psyche, to architecture, and to the presence of the past altogether, must be addressed with the same strength as one would address a phantom. The unwork makes us feel the uncanny presence of the past in the now, of the overpowering ghost that brings with it the archontic, in the shape of our own selves that has been revealed to us as not us, but as yet again us. This is the moment that the unwork carries with it the most crucial aspect of all: it has nothing to give. It gives nothing. And this is when listening finds us without anything to hold on to but our very own resonance. Our very own listening to ourselves listening. The moment where we realize it is our own self that is returning to us. This is our resistance.</p><h5 id="macroforma">Macroforma</h5><p>The resonance of a return. This is why the unwork depends so extremely on its very state of fragility: it touches the self from itself, it engages the self with its own touch, with its own skin, with the resonance of itself. The moment this fragility is forgotten is when composers, performers, improvisors, programmers —humans and nonhuman listeners, in the most broadest sense possible— enable an operative <code>macro</code> that has a political agency in the shaping of singularities. In order to to provide some insight into the difficulties that arise from this conceptualization of the unwork, I would like to brin again Vaggione. When he writes of the shaping of singularities, he refers to the arbitrariness of the composer. However, he intentionally maintains formal coherence by extending the singularity of a grain (conceptually) to the singularity of a work. Therefore, in expanding this singularity he is ultimately arriving at a very unique and delimited shape that is the work. The contradiction I see here is that, in an attempt to propose a bottom-up approach in which, like Lewis’ work, local actions percolate up to global behavior, Vaggione grants his work with an inevitable global behavior that is extremely operative: Vaggione himself. Without a doubt Vaggione (self) <em>is</em> singularly, and the value of his music is not put into question. I bring this as an example, as I have mentioned before, of the name of the composer and its impression on the music. In this case, the singularity that is the composer impresses its own singular shape, its own style, its own trace, on the music, and makes it a work. The problem is that the work now engages with its own operativity, with its integrity, and begins to dictate the shape of its own listening.</p><h5 id="overfitting">Overfitting</h5><p>Defining anarchy as a paradoxically productive force —a form of destruction which “produces the very thing it reduces” <span class="citation" data-cites="Der95:Arc">(Derrida &amp; Prenowitz 1995)</span>—, Derrida locates it at the core of the concept of the archive (See <a href="#archontic" data-reference-type="ref" data-reference="archontic">5.2.3</a>). As I have outlined before, databasing and composition bring forth their relation to the archive, and by doing so, they reveal themselves as repositories for the the archontic principle: bound to the origin and the rule. Like the name of the composer which is written in the shape of the music, the database has too the potential of becoming a source. Databasing becomes an activity of this source, and thus embeds the databaser with a specter of authority (See <a href="#authority" data-reference-type="ref" data-reference="authority">5.3.4</a>). Claiming, therefore, that composition can be identified with databasing means translating the ‘archic’ not only to the performativity of composition, also to the product of composing, to the composer and the composed, to the shape of the music, and to the singularity of the listened. An unwork, therefore, would be a necessarily an-archic work. It is still a work, however, in the sense that it demands from the composer, from the databaser, and from every node in the scope of its network, an incessant operativity. That is to say, the ‘un’ in unwork does not come from inactivity, from passivity, from an escape of any form of action. Quite the contrary, it is a result of the constant impression of the work, the accumulated efforts towards the ‘un’ of the thing. An extreme operativity that goes beyond the threshold of its own making so that it reaches a point of inflexion, a bent, an overflow. There is a point in statistics where learning algorithms, given a data set, tend to adapt themselves too closely to the data set, thus failing to render future predictions reliably. This is known as overfitting. Despite its uselessness (or better, because of it) I believe this to be a suitable metaphor for the pursuit of the unwork: precisely by overworking the work, one can find some insight into the ‘un,’ and thus, one can begin to approach the anarchic in music composition. However, this approach comes not without its warnings, since it means at once, to eradicate the archic with the ‘an’, which means to introduce a bug in the oedipal loop that could result in unheard musical behaviors.</p><h3 id="worker">[Wip] Work In Progress</h3><pre><code>// code for the &quot;working&quot; pd class. 
// it does nothing.

#include &lt;stdio.h&gt;
#include &quot;m_pd.h&quot;

t_class *working_class;

typedef struct working {
    t_object    *x_obj;
    t_symbol    *work
    union {
        t_symbol    *product;
        t_symbol    *music_piece;
        t_symbol    *music_work;
        t_symbol    *opera;
    } music_work;
    t_symbol    *something_done;
    t_float     *physical_labor, *skill;
    t_atom      *the_work_of_an_author, *oeuvre;
    t_symbol    *the_operativity_of_the_composer;
    t_atom      *matrix_operations;
    t_symbol    *operetta, *opera_prima, *obra, *open_work;
    t_symbol    *a_work_of_art;
    t_symbol    *artistic_creation, *techne;
    t_float     *fullTime, *partTime;
    t_symbol    *clockwork, *officiate, *office, *act;
    t_symbol    *produce, *make_it_work;
    t_float     *magic_work, *work_of_angels;
    t_symbol    *blueCollar, *whiteCollar, *slavework, *masterwork;
    t_symbol    *Work_as_in_the_application_of_forces;
    //V:&quot;But applied to whom?&quot;
    t_symbol    *working_a_field;
    t_symbol    *the_internal_workings_of_structures;
    t_symbol    *work_in_an_app, *worked_out;
    t_symbol    *work_your_hat_off, *workflow, *workspace;
    t_symbol    *working_for_food, hardworking, *labour, *giving_birth;
    t_symbol    *all_that_is_remunerated_after_efforts_have_been_given;
    t_symbol    *achieve_a_goal, your_task, *to_work_to_live;
    t_symbol    *to_have_a_working_body, *functioning;
    t_symbol    *operative, working_like_a_bee;
    union {
        t_symbol *like_a_bee;
        t_symbol *like_a_member_of_the_hive;
        t_symbol *like_an_ant;
        t_symbol *like_a_worker;
        t_symbol *like_a_coworker;
        t_atom   *organized_labour;
    } workers_union;
    char        work[&quot;for&quot;,&quot;to&quot;,&quot;after&quot;,&quot;by&quot;];
    unsigned char *hours;
    t_symbol    *working_as_an_extension_of_truth_as_well_as_lies;
    t_symbol    *out_of_work, *at_work, *work_in_progress;
    t_symbol    *working_for_the_man, *freelancing, *working_under_the_table;
    t_symbol    *working_past_a_deadline, *working_in_pairs;
    t_symbol    *teamwork, *collaborate, *co-operate;
    t_symbol    *paperwork, *networking, *prototyping, *worked-up;
    char        *work_the_crowd, *work_the_system;
    t_symbol    *work_a_miracle, *work_your_workers;
    t_symbol    *social_worker;
    t_float     *a_ship_works_in_a_heavy_sea, *work_the_levers;
    t_float     *work_for_Facebook, *future_work, *framework;
 } t_working;</code></pre><h1 id="chapter:Conclusion" class="unnumbered">Conclusion</h1><p>… placeholder for conclusion abstract …</p><h1 id="chapter:Appendices" class="unnumbered">Appendices</h1><p>abstract of appendices</p><h2 id="section:DIANA:_Database_for_Image_and_Audio_Navigation" class="unnumbered">DIANA: Database for Image and Audio Navigation</h2><p>I use William Brent’s —timbre description algorithms— and Antoine Villeret’s —image descriptors using Computer Vision algorithms—, to develop a new software library for Pure Data. My model consists of a joint Database structure for Image and Audio descriptors suitable for realtime navigation. At its core, the Database is generated by calculating derivatives between both data sets, and it is performed by applying random probabilities, markov chains, or chaotic generators to this navigation. This allows for multiple paths to be traced on each navigation.</p><h3 id="dbmodel" class="unnumbered">A Database Model</h3><p>A detailed description of the image and audio navigation system…</p><blockquote><p>Just as a fractal has the same structure on different scales, a new media object has the same modular structure throughout. Media elements…are represented as collections of discrete samples <span class="citation" data-cites="Man01:The">(Manovich 2001, p. 30)</span>.</p></blockquote><blockquote><p>First, data is sampled, most often at regular intervals, such as the grid of pixels used to represent a digital image. The frequency of sampling is referred to as resolution. Sampling turns continuous data into discrete data…Second, each sample is quantified, that is, it is assigned a numerical value drawn from a defined range (such as 0-255 in the case of an 8-bit greyscale image) <span class="citation" data-cites="Man02:Old">(Manovich 2002, p. 28)</span></p></blockquote><p>I define the points in common between Database Practice and Music Composition. I describe the main technical concepts behind Database Navigation and provide use cases from both appendices A and B, the former relating to joint image and audio databases, and the latter to text databases. I then reflect on the quality of this navigation in relation to the type of navigation and results that they obtain.</p><p>I use computer vision literature to briefly introduce and describe the most common visual descriptors. I focus on certain descriptors (TBD) which are suitable for live multimedia use, and which I will implement in Appendix A.</p><p>I use Timbre Analysis literature to briefly introduce and describe the most useful audio descriptors. I take William Brent’s TimbreID library, complementing it with Tae Hong Park’s dissertation on timbre recognition, and I focus on the most useful descriptors for live multimedia use (TBD), which I will implement in Appendix A in relation to the image descriptors introduced above.</p><h2 id="section:ABBY:_An_Online_Environment_for_Annotated_Bibliographies" class="unnumbered">ABBY: An Online Environment for Annotated Bibliographies</h2><p>In order to write this dissertation, I have developed “Abby” an online Text Database tool namely to build an annotated bibliography. The program is mostly written in Javascript, with the data navigation and programming hosted in Github, and the datasets stored in the Google account that New York University has provided me. The annotated bibliography is available at <a href="https://fdch.github.io/abby">https://fdch.github.io/abby</a>, and the code can be accessed or cloned from <a href="https://github.com/fdch/litrev">https://github.com/fdch/litrev</a>.</p><h3 id="texdb" class="unnumbered">A Text Database</h3><p>A detailed description of the text database model…</p><div id="refs" class="references"><div id="ref-Abiteboul:semistructured:96"><p>Abiteboul S. 1996. Querying semi-structured data. <em>1996-19</em>, Stanford InfoLab; Stanford InfoLab</p></div><div id="ref-DBLP:books/aw/AbiteboulHV95"><p>Abiteboul S, Hull R, Vianu V. 1995. <em>Foundations of Databases</em>. Addison-Wesley. ed.</p></div><div id="ref-Amatriain/2004/phdthesis"><p>Amatriain X. 2004. <em>An object-oriented metamodel for digital signal processing with a focus on audio and music</em>. PhD thesis thesis. Universitat Pompeu Fabra</p></div><div id="ref-icmc/bbp2372.1985.040"><p>Ames C. 1985. Applications of linked data structures to automated composition. <em>Proceedings of the International Computer Music Conference, ICMC 1985</em>. Michigan Publishing</p></div><div id="ref-2008:graph/anglesgutierrez/survey"><p>Angles R, Gutierrez C. 2008. Survey of graph database models. <em>ACM Computing Surveys</em>. 40(1):</p></div><div id="ref-DBLP:conf/ismir/AntilaC14"><p>Antila C, Cumming J. 2014. The VIS framework: Analyzing counterpoint in large datasets. <em>Proceedings of the 15th International Society for Music Information Retrieval Conference, ISMIR 2014, Taipei, Taiwan, October 27-31, 2014</em>, pp. 71–76. <a href="http://www.terasoft.com.tw/conf/ismir2014/proceedings/T014_162_Paper.pdf">http://www.terasoft.com.tw/conf/ismir2014/proceedings/T014_162_Paper.pdf</a></p></div><div id="ref-icmc/bbp2372.2003.030"><p>Ariza C. 2003. Ornament as data structure: An algorithmic model based on micro-rhythms of csng laments and funeral music. <em>Proceedings of the International Computer Music Conference, ICMC 2003</em>. Michigan Publishing</p></div><div id="ref-Ari05:Ano"><p>Ariza C. 2005a. <em>An open design for computer-aided algorithmic music composition: AthenaCL</em>. PhD thesis thesis</p></div><div id="ref-arizaSieves"><p>Ariza C. 2005b. The xenakis sieve as object: A new model and a complete implementation. <em>Computer Music Journal</em>. 29(2):40–60</p></div><div id="ref-DBLP:conf/icmc/AssayagAFH97"><p>Assayag G, Agón C, Fineberg J, Hanappe P. 1997. An object oriented visual environment for musical composition. <em>Proceedings of the 1997 International Computer Music Conference, ICMC 1997, Thessaloniki, Greece, September 25-30, 1997</em>. Michigan Publishing</p></div><div id="ref-DBLP:conf/icmc/AssayagDD99"><p>Assayag G, Dubnov S, Delerue O. 1999. Guessing the composer’s mind: Applying universal prediction to musical style. <em>Proceedings of the 1999 International Computer Music Conference, ICMC 1999, Beijing, China, October 22-27, 1999</em>. Michigan Publishing</p></div><div id="ref-Att77:Noi"><p>Attali J. 2009. <em>Noise: The Political Economy of Music</em>. University of Minnesota Press. ed.</p></div><div id="ref-Bachman:1973:PN:355611.362534"><p>Bachman CW. 1973. The programmer as navigator. <em>Commun. ACM</em>. 16(11):653–58</p></div><div id="ref-Ballora/2000/phdthesis"><p>Ballora M. 2000. <em>Data analysis through auditory display: Applications in heart rate variability</em>. PhD thesis thesis. McGill University</p></div><div id="ref-icmc/bbp2372.2010.117"><p>Ballora M, Panulla B, Gourley M, Hall D. 2010. Sonification of web log data. <em>Proceedings of the International Computer Music Conference, ICMC 2010</em>. Michigan Publishing</p></div><div id="ref-icmc/bbp2372.2000.123"><p>Barrett N. 2000. A compositional methodology based on data extracted from natural phenomena. <em>Proceedings of the International Computer Music Conference, ICMC 2000</em>. Michigan Publishing</p></div><div id="ref-Bar68:Ele"><p>Barthes R, Lavers A, Smith C. 1968. <em>Elements of Semiology</em>. Hill; Wang, New York. ed.</p></div><div id="ref-Bei09:Aes"><p>Beilharz K, Ferguson S. 2009. Aesthetic sonification toolkit for real-time interaction with data. <em>HICAH</em>, pp. 401–8</p></div><div id="ref-icad/2002/ben-tal"><p>Ben-Tal O, Berger J, Cook B, Daniels M, Scavone G. 2002. Sonart: The sonification application research toolbox. <em>Presented at the 8th International Conference on Auditory Display (Icad), Kyoto, Japan, July 2-5, 2002</em>. Georgia Institute of Technology</p></div><div id="ref-DBLP:conf/ismir/Bertin-MahieuxEWL11"><p>Bertin-Mahieux T, Ellis DPW, Whitman B, Lamere P. 2011. The million song dataset. <em>Proceedings of the 12th International Society for Music Information Retrieval Conference, ISMIR 2011, Miami, Florida, Usa, October 24-28, 2011</em>, pp. 591–96. University of Miami</p></div><div id="ref-DBLP:conf/ismir/BittnerSTMCB14"><p>Bittner RM, Salamon J, Tierney M, Mauch M, Cannam C, Bello JP. 2014. MedleyDB: A multitrack dataset for annotation-intensive MIR research. <em>Proceedings of the 15th International Society for Music Information Retrieval Conference, ISMIR 2014, Taipei, Taiwan, October 27-31, 2014</em>, pp. 155–60. <a href="http://www.terasoft.com.tw/conf/ismir2014/proceedings/T028_322_Paper.pdf">http://www.terasoft.com.tw/conf/ismir2014/proceedings/T028_322_Paper.pdf</a></p></div><div id="ref-DBLP:conf/icmc/BlochD08"><p>Bloch G, Dubnov S. 2008. Introducing video features and spectral descriptors in the omax improvisation system. <em>Proceedings of the 2008 International Computer Music Conference, ICMC 2008, Belfast, Ireland, August 24-29, 2008</em>. Michigan Publishing</p></div><div id="ref-Bor42:Fun"><p>Borges JL. 1942. Funes el memorioso. <em>Ficciones</em></p></div><div id="ref-Bor95:Rat"><p>Born G. 1995. <em>Rationalizing Culture</em>. University of California Press. ed.</p></div><div id="ref-bbortz:2015"><p>Bortz B, Jaimovich J, Knapp R. 2015. Emotion in motion: A reimagined framework for biomusical/emotional interaction. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, pp. 44–49. Baton Rouge, Louisiana, USA: Louisiana State University</p></div><div id="ref-DBLP:conf/icmc/BoyntonDPR86"><p>Boynton L, Duthen J, Potard Y, Rodet X. 1986. Adding a graphical user interface to FORMES. <em>Proceedings of the 1986 International Computer Music Conference, ICMC 1986, Den Haag, the Netherlands, October 20-24, 1986</em>. Michigan Publishing</p></div><div id="ref-Brent/2010/phdthesis"><p>Brent W. 2010a. <em>Physical and perceptual aspects of percussive timbre</em>. PhD thesis thesis. UC San Diego</p></div><div id="ref-icmc/bbp2372.2010.044"><p>Brent W. 2010b. A timbre analysis and classification toolkit for pure data. <em>Proceedings of the International Computer Music Conference, ICMC 2010</em>. Michigan Publishing</p></div><div id="ref-icmc/bbp2372.2004.004"><p>Bresson J, Agon C. 2004. SDIF sound description data representation and manipulation in computer assisted composition. <em>Proceedings of the International Computer Music Conference, ICMC 2004</em>. Michigan Publishing</p></div><div id="ref-icmc/bbp2372.2010.129"><p>Bresson J, Agon C. 2010. Processing sound and music description data using openmusic. <em>Proceedings of the International Computer Music Conference, ICMC 2010</em>. Michigan Publishing</p></div><div id="ref-icmc/bbp2372.1981.018"><p>Brinkman AR. 1981. Data structures for a music-11 preprocessor. <em>Proceedings of the International Computer Music Conference, ICMC 1981</em>. Michigan Publishing</p></div><div id="ref-score11manual"><p>Brinkman AR. 1982. Original version of the score11 manual. <em>Score11 Manual</em></p></div><div id="ref-icmc/bbp2372.1983.002"><p>Brinkman AR. 1983. A design for a single pass scanner for the darms music coding language. <em>Proceedings of the International Computer Music Conference, ICMC 1980</em>. Michigan Publishing</p></div><div id="ref-icmc/bbp2372.1984.033"><p>Brinkman AR. 1984. A data structure for computer analysis of musical scores. <em>Proceedings of the International Computer Music Conference, ICMC 1984</em>. Michigan Publishing</p></div><div id="ref-DBLP:journals/corr/Brzezinski-SpiczakDLP13"><p>Brzezinski-Spiczak M, Dobosz K, Lis M, Pintal M. 2013. Music files search system. <em>CoRR</em>. abs/1309.4345:</p></div><div id="ref-Bullock2011"><p>Bullock J, Beattie D, Turner J. 2011. Integra live : A new graphical user interface for live electronic music. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, pp. 387–92. <a href="http://www.nime.org/proceedings/2011/nime2011_387.pdf">http://www.nime.org/proceedings/2011/nime2011_387.pdf</a></p></div><div id="ref-Bullock2009"><p>Bullock J, Coccioli L. 2009. Towards a humane graphical user interface for live electronic music. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, pp. 266–67. <a href="http://www.nime.org/proceedings/2009/nime2009_266.pdf">http://www.nime.org/proceedings/2009/nime2009_266.pdf</a></p></div><div id="ref-icmc/bbp2372.2009.012"><p>Bullock J, Frisk H. 2009. An object oriented model for the representation of temporal data in the integra framework. <em>Proceedings of the International Computer Music Conference, ICMC 2009</em>. Michigan Publishing</p></div><div id="ref-Buneman:1997:SD:263661.263675"><p>Buneman P. 1997. Semistructured data. <em>Proceedings of the Sixteenth Acm Sigact-Sigmod-Sigart Symposium on Principles of Database Systems</em>, pp. 117–21. New York, NY, USA: ACM</p></div><div id="ref-But88:Per"><p>Butler J. 1988. Performative acts and gender constitution: An essay in phenomenology and feminist theory. <em>Theatre Journal</em>. 40(4):</p></div><div id="ref-Bux77:Aco"><p>Buxton W. 1977. A composer’s introduction to computer music. <em>Interface</em>. 6:57–72</p></div><div id="ref-youtube/buxton10"><p>Buxton W. 2016a. Objed: The sssp sound editing tool. <em>Youtube</em></p></div><div id="ref-youtube/buxton16"><p>Buxton W. 2016b. Socializing technology for the mobile human. Keynote, the next web conference, amsterdam/europe. <em>Youtube</em></p></div><div id="ref-DBLP:conf/icmc/BuxtonFBRSCM78"><p>Buxton W, Fedorkow G, Baecker R, Reeves WT, Smith KC, et al. 1978a. An overview of the structured sound synthesis project. <em>Proceedings of the 1978 International Computer Music Conference, ICMC 1978, Evanston, Illinois, Usa, 1978</em>. Michigan Publishing</p></div><div id="ref-DBLP:conf/icmc/BuxtonPRB80"><p>Buxton W, Patel S, Reeves WT, Baecker R. 1980. "OBJED" and the design of timbral resources. <em>Proceedings of the 1980 International Computer Music Conference, ICMC 1980, New York City, Usa, 1980</em>. Michigan Publishing</p></div><div id="ref-icmc/bbp2372.1978.012"><p>Buxton W, Reeves W, Baecker R, Mezei L. 1978b. The use of hierarchy and instance in a data structure for computer music. <em>Proceedings of the International Computer Music Conference, ICMC 1978</em>. Michigan Publishing</p></div><div id="ref-Caramiaux2011"><p>Caramiaux B, Bevilacqua F, Schnell N. 2011. Sound selection by gestures. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, pp. 329–30. <a href="http://www.nime.org/proceedings/2011/nime2011_329.pdf">http://www.nime.org/proceedings/2011/nime2011_329.pdf</a></p></div><div id="ref-Rodet1989"><p>Caraty MJ, Richard JC, Rodet X. 1989. "Vowel recognition in a data base of continuous speech: Experiments with local and global identification principles". <em>EUROSPEECH</em>. 2272</p></div><div id="ref-Carey:2012"><p>Carey B. 2012. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>. Ann Arbor, Michigan: University of Michigan</p></div><div id="ref-Carlile2011-P"><p>Carlile S. 2011. Psychoacoustics. In <em>The Sonification Handbook</em>, eds. T Hermann, A Hunt, JG Neuhoff, pp. 41–61. Berlin, Germany: Logos Publishing House. ed.</p></div><div id="ref-mcartwright:2014"><p>Cartwright M, Pardo B. 2014. SynthAssist: Querying an audio synthesizer by vocal imitation. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, pp. 363–66. London, United Kingdom: Goldsmiths, University of London</p></div><div id="ref-Cas00:The"><p>Cascone K. 2000. The aesthetics of failure: ’Post-digital’ tendencies in contemporary computer music. <em>Computer Music Journal</em>. 24(4):12–18</p></div><div id="ref-DBLP:conf/icmc/CaseyG07"><p>Casey MA, Grierson M. 2007. Soundspotter / remix-tv: Fast approximate matching for audio and video performance. <em>Proceedings of the 2007 International Computer Music Conference, ICMC 2007, Copenhagen, Denmark, August 27-31, 2007</em>. Michigan Publishing</p></div><div id="ref-DBLP:conf/ismir/CaseyS06"><p>Casey MA, Slaney M. 2006. Song intersection by approximate nearest neighbor search. <em>ISMIR 2006, 7th International Conference on Music Information Retrieval, Victoria, Canada, 8-12 October 2006, Proceedings</em>, pp. 144–49</p></div><div id="ref-DBLP:conf/icmc/CadizCMMATI15"><p>Cádiz RF, Cuadra P de la, Montoya A, Marı́n V, Andia ME, et al. 2015. Sonification of medical images based on statistical descriptors. <em>ICMC</em>. Michigan Publishing</p></div><div id="ref-fdch/papers/spectral"><p>Cámara Halac F. 2018a. <em>A spectral experience: Self convolution and face tracking</em>. Work. Pap.</p></div><div id="ref-fdch/papers/elsa"><p>Cámara Halac F. 2018b. “This is for young ears:” A response to elsa justel’s marelle... <em>Open Space</em>. (21):339–50</p></div><div id="ref-icmc/bbp2372.1980.051"><p>Charnass H. 1980. Towards a data base in musicology: The computer processing of the bridgman file. <em>Proceedings of the International Computer Music Conference, ICMC 1980</em>. Michigan Publishing</p></div><div id="ref-icmc/bbp2372.2000.146"><p>Choi I, Zheng G, Chen K. 2000. Embedding a sensory data retrieval system in a movement-sensitive space and a surround sound system. <em>Proceedings of the International Computer Music Conference, ICMC 2000</em>. Michigan Publishing</p></div><div id="ref-icmc/bbp2372.2004.124"><p>Ciardi FC. 2004. Real time sonification of stock market data with sMax. <em>Proceedings of the International Computer Music Conference, ICMC 2004</em>. Michigan Publishing</p></div><div id="ref-icmc/bbp2372.1980.020"><p>Clements PJ. 1980. Musical data structures in a multi-use environment. <em>Proceedings of the International Computer Music Conference, ICMC 1980</em>. Michigan Publishing</p></div><div id="ref-Codd:1970:RMD:362384.362685"><p>Codd EF. 1970. A relational model of data for large shared data banks. <em>Commun. ACM</em>. 13(6):377–87</p></div><div id="ref-Codd72relationalcompleteness"><p>Codd EF. 1972. Relational completeness of data base sublanguages. <em>Database Systems</em>, pp. 65–98. Prentice-Hall</p></div><div id="ref-connes:shapes"><p>Connes A. 2012. The music of shapes</p></div><div id="ref-DBLP:conf/icmc/Cope87"><p>Cope D. 1987a. Experiments in music intelligence (EMI). <em>ICMC</em>. Michigan Publishing</p></div><div id="ref-Cop87:AnE"><p>Cope D. 1987b. An expert system for computer-assisted composition. <em>Computer Music Journal</em>. 11(4):30–46</p></div><div id="ref-2010NJPh:12e3030C"><p>Correa DC, Saito JH, Costa L da F. 2010. Musical genres: beating to the rhythms of different drums. <em>New Journal of Physics</em>. 12:053030</p></div><div id="ref-DBLP:conf/ismir/CrestelEHM17"><p>Crestel L, Esling P, Heng L, McAdams S. 2017. A database linking piano and orchestral MIDI scores with application to automatic projective orchestration. <em>Proceedings of the 18th International Society for Music Information Retrieval Conference, ISMIR 2017, Suzhou, China, October 23-27, 2017</em>, pp. 592–98. <a href="https://ismir2017.smcnus.org/wp-content/uploads/2017/10/235_Paper.pdf">https://ismir2017.smcnus.org/wp-content/uploads/2017/10/235_Paper.pdf</a></p></div><div id="ref-crowley98"><p>Crowley C. 1998. Data structures for text sequences.<em></em> <a href="https://www.cs.unm.edu/~crowley/papers/sds.pdf">https://www.cs.unm.edu/~crowley/papers/sds.pdf</a></p></div><div id="ref-Dan07:The"><p>Daniel S. 2007. The database: An aesthetics of dignity. <em>Database Aesthetics: Art in the Age of Information Overflow</em></p></div><div id="ref-DBLP:conf/ismir/DefferrardBVB17"><p>Defferrard M, Benzi K, Vandergheynst P, Bresson X. 2017. FMA: A dataset for music analysis. <em>Proceedings of the 18th International Society for Music Information Retrieval Conference, ISMIR 2017, Suzhou, China, October 23-27, 2017</em>, pp. 316–23. <a href="https://ismir2017.smcnus.org/wp-content/uploads/2017/10/75_Paper.pdf">https://ismir2017.smcnus.org/wp-content/uploads/2017/10/75_Paper.pdf</a></p></div><div id="ref-DBLP:journals/corr/abs-1803-04652"><p>Dehkordi MB, Banitalebi-Dehkordi A. 2018. Music genre classification using spectral analysis and sparse representation of the signals. <em>CoRR</em>. abs/1803.04652:</p></div><div id="ref-DBLP:journals/corr/abs-1809-07276"><p>Delbouys R, Hennequin R, Piccoli F, Royo-Letelier J, Moussallam M. 2018. Music mood detection based on audio and lyrics with deep neural net. <em>CoRR</em>. abs/1809.07276:</p></div><div id="ref-DBLP:conf/icmc/DepalleRGE93"><p>Depalle P, Rodet X, Galas T, Eckel G. 1993. Generalized diphone control. <em>Opening a New Horizon: Proceedings of the 1993 International Computer Music Conference, ICMC 1993, Tokio, Japan, September 10-15, 1993</em>. Michigan Publishing</p></div><div id="ref-Der78:Wri"><p>Derrida J. 1978. <em>Writing and Difference</em>. The University of Chicago. ed.</p></div><div id="ref-Der82:Mar"><p>Derrida J. 1982. <em>Margins of Philosophy</em>. The Harvester Press. ed.</p></div><div id="ref-Der95:Arc"><p>Derrida J, Prenowitz E. 1995. Archive fever: A freudian impression. <em>Diacritics</em>. 25(2):</p></div><div id="ref-DBLP:conf/ismir/DevaneyACN15"><p>Devaney J, Arthur C, Condit-Schultz N, Nisula K. 2015. Theme and variation encodings with roman numerals (TAVERN): A new data set for symbolic music analysis. <em>Proceedings of the 16th International Society for Music Information Retrieval Conference, ISMIR 2015, Málaga, Spain, October 26-30, 2015</em>, pp. 728–34. <a href="http://ismir2015.uma.es/articles/261_Paper.pdf">http://ismir2015.uma.es/articles/261_Paper.pdf</a></p></div><div id="ref-diener1985"><p>Diener G. 1985. <em>Formal languages in music theory</em>. Master’s thesis thesis. McGill University, Faculty of Music</p></div><div id="ref-icmc/bbp2372.1988.020"><p>Diener G. 1988. TTrees: An active data structure for computer music. <em>Proceedings of the International Computer Music Conference, ICMC 1988</em>. Michigan Publishing</p></div><div id="ref-10.2307/3680043"><p>Diener G. 1989. TTrees: A tool for the compositional environment. <em>Computer Music Journal</em>. 13(2):77–85</p></div><div id="ref-DBLP:conf/icmc/Diener92"><p>Diener GR. 1992. A visual programming environment for music notation. <em>Proceedings of the 1992 International Computer Music Conference, ICMC 1992, San Jose, California, Usa, October 14-18, 1992</em>. Michigan Publishing</p></div><div id="ref-DBLP:journals/corr/abs-0812-4235"><p>Dinuzzo F, Pillonetto G, Nicolao GD. 2008. Client-server multi-task learning from distributed datasets. <em>CoRR</em>. abs/0812.4235:</p></div><div id="ref-DBLP:conf/ismir/DonahueMM18"><p>Donahue C, Mao HH, McAuley J. 2018. The NES music database: A multi-instrumental dataset with expressive performance attributes. <em>Proceedings of the 19th International Society for Music Information Retrieval Conference, ISMIR 2018, Paris, France, September 23-27, 2018</em>, pp. 475–82. <a href="http://ismir2018.ircam.fr/doc/pdfs/265_Paper.pdf">http://ismir2018.ircam.fr/doc/pdfs/265_Paper.pdf</a></p></div><div id="ref-2018arXiv180204208D"><p>Donahue C, McAuley J, Puckette M. 2018. Adversarial Audio Synthesis. <em>arXiv e-prints</em>. arXiv:1802.04208</p></div><div id="ref-DBLP:conf/ismir/Dunn00"><p>Dunn JW. 2000. Beyond VARIATIONS: creating a digital music library. <em>ISMIR 2000, 1st International Symposium on Music Information Retrieval, Plymouth, Massachusetts, Usa, October 23-25, 2000, Proceedings</em>. <a href="http://ismir2000.ismir.net/papers/invites/dunn_invite.pdf">http://ismir2000.ismir.net/papers/invites/dunn_invite.pdf</a></p></div><div id="ref-icmc/bbp2372.1987.045"><p>Dydo JS. 1987. Data structures in the note processor. <em>Proceedings of the International Computer Music Conference, ICMC 1987</em>. Michigan Publishing</p></div><div id="ref-Eck13:Bet"><p>Eck C van. 2013. <em>Between air and electricity: Microphones and loudspeakers as musical instruments</em>. PhD thesis thesis. Leiden University</p></div><div id="ref-Eco04:The"><p>Eco U. 2004. The poetics of the open work. <em>Audio Culture: Readings in Modern Music</em></p></div><div id="ref-Emm86:The"><p>Emmerson S. 1986. <em>The Language of Electroacoustic Music</em>. ed.</p></div><div id="ref-DBLP:conf/ismir/EremenkoDBS18"><p>Eremenko V, Demirel E, Bozkurt B, Serra X. 2018. Audio-aligned jazz harmony dataset for automatic chord transcription and corpus-based research. <em>Proceedings of the 19th International Society for Music Information Retrieval Conference, ISMIR 2018, Paris, France, September 23-27, 2018</em>, pp. 483–90. <a href="http://ismir2018.ircam.fr/doc/pdfs/206_Paper.pdf">http://ismir2018.ircam.fr/doc/pdfs/206_Paper.pdf</a></p></div><div id="ref-10.2307/30204239"><p>Erickson RF. 1975. "The darms project": A status report. <em>Computers and the Humanities</em>. 9(6):291–98</p></div><div id="ref-Ern13:Dig"><p>Ernst W. 2013. <em>Digital Memory and the Archive</em>. University of Minnesota Press. ed.</p></div><div id="ref-PhysRevLett.122.084501"><p>Esposito A, Krichevsky R, Nicolis A. 2019. Gravitational mass carried by sound waves. <em>Phys. Rev. Lett.</em> 122(8):084501</p></div><div id="ref-Flu11:Int"><p>Flusser V. 2011. <em>Into the Universe of Technical Images</em>. University of Minnesota Press. ed.</p></div><div id="ref-DBLP:conf/ismir/FonsecaPFFBFOPS17"><p>Fonseca E, Pons J, Favory X, Font F, Bogdanov D, et al. 2017. Freesound datasets: A platform for the creation of open audio datasets. <em>Proceedings of the 18th International Society for Music Information Retrieval Conference, ISMIR 2017, Suzhou, China, October 23-27, 2017</em>, pp. 486–93. <a href="https://ismir2017.smcnus.org/wp-content/uploads/2017/10/161_Paper.pdf">https://ismir2017.smcnus.org/wp-content/uploads/2017/10/161_Paper.pdf</a></p></div><div id="ref-icmc/bbp2372.2017.087"><p>Fox MK, Stewart J, Hamilton R. 2017. MadBPM: A modular multimodal environment for data-Driven composition and sonification. <em>Proceedings of the International Computer Music Conference, ICMC 2017</em>. Michigan Publishing</p></div><div id="ref-icmc/bbp2372.1987.046"><p>Free J. 1987. Towards an extensible data structure for the representation of music on computers. <em>Proceedings of the International Computer Music Conference, ICMC 1987</em>. Michigan Publishing</p></div><div id="ref-DBLP:conf/icmc/FreeV86"><p>Free J, Vytas P. 1986. What ever happened to sssp? <em>Proceedings of the 1986 International Computer Music Conference, ICMC 1986, Den Haag, the Netherlands, October 20-24, 1986</em>. Michigan Publishing</p></div><div id="ref-DBLP:conf/icmc/FreeV88"><p>Free J, Vytas P. 1988. The CAMP music configuration database. <em>Proceedings of the 1988 International Computer Music Conference, ICMC 1988, Cologne, Germany, September 20-25, 1988</em>. Michigan Publishing</p></div><div id="ref-Fri17:Son"><p>Frid E. 2017. Sonification of women in sound and music computing - the sound of female authorship in icmc, smc and nime proceedings. <em>ICMC</em>, pp. 233–38. Michigan Publishing</p></div><div id="ref-Frisson2015"><p>Frisson C. 2015. <em>Designing interaction for browsing media collections (by similarity)</em>. PhD thesis thesis. Universit de Mons</p></div><div id="ref-Frisson2010"><p>Frisson C, Macq B, Dupont S, Siebert X, Tardieu D, Dutoit T. 2010. DeviceCycle : Rapid and reusable prototyping of gestural interfaces, applied to audio browsing by similarity. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, pp. 473–76. <a href="http://www.nime.org/proceedings/2010/nime2010_473.pdf">http://www.nime.org/proceedings/2010/nime2010_473.pdf</a></p></div><div id="ref-Garcia2011"><p>Garcı́a F, Vinceslas L, Tubau J, Maestre E. 2011. Acquisition and study of blowing pressure profiles in recorder playing. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, pp. 124–27. <a href="http://www.nime.org/proceedings/2011/nime2011_124.pdf">http://www.nime.org/proceedings/2011/nime2011_124.pdf</a></p></div><div id="ref-DBLP:conf/icmc/GartonT97"><p>Garton B, Topper D. 1997. RTcmix - using CMIX in real time. <em>Proceedings of the 1997 International Computer Music Conference, ICMC 1997, Thessaloniki, Greece, September 25-30, 1997</em>. Michigan Publishing</p></div><div id="ref-DBLP:conf/ismir/Good00"><p>Good M. 2000. Representing music using XML. <em>ISMIR 2000, 1st International Symposium on Music Information Retrieval, Plymouth, Massachusetts, Usa, October 23-25, 2000, Proceedings</em>. <a href="http://ismir2000.ismir.net/posters/good.pdf">http://ismir2000.ismir.net/posters/good.pdf</a></p></div><div id="ref-DBLP:conf/ismir/GotoHNO02"><p>Goto M, Hashiguchi H, Nishimura T, Oka R. 2002. RWC music database: Popular, classical and jazz music databases. <em>ISMIR 2002, 3rd International Conference on Music Information Retrieval, Paris, France, October 13-17, 2002, Proceedings</em>. <a href="http://ismir2002.ismir.net/proceedings/03-SP04-1.pdf">http://ismir2002.ismir.net/proceedings/03-SP04-1.pdf</a></p></div><div id="ref-DBLP:conf/ismir/GotoHNO03"><p>Goto M, Hashiguchi H, Nishimura T, Oka R. 2003. RWC music database: Music genre database and musical instrument sound database. <em>ISMIR 2003, 4th International Conference on Music Information Retrieval, Baltimore, Maryland, Usa, October 27-30, 2003, Proceedings</em>. <a href="http://ismir2003.ismir.net/papers/Goto1.PDF">http://ismir2003.ismir.net/papers/Goto1.PDF</a></p></div><div id="ref-Gra15:The"><p>Gratton P, Morin M-E. 2015. <em>The Nancy Dictionary</em>. Edinburgh University Press. ed.</p></div><div id="ref-DBLP:conf/ismir/HamanakaHT14"><p>Hamanaka M, Hirata K, Tojo S. 2014. Musical structural analysis database based on GTTM. <em>Proceedings of the 15th International Society for Music Information Retrieval Conference, ISMIR 2014, Taipei, Taiwan, October 27-31, 2014</em>, pp. 325–30. <a href="http://www.terasoft.com.tw/conf/ismir2014/proceedings/T059_257_Paper.pdf">http://www.terasoft.com.tw/conf/ismir2014/proceedings/T059_257_Paper.pdf</a></p></div><div id="ref-icmc/bbp2372.2006.123"><p>Hamilton R. 2006. Bioinformatic response data as a compositional driver. <em>Proceedings of the International Computer Music Conference, ICMC 2006</em>. Michigan Publishing</p></div><div id="ref-Han02:Cin"><p>Hansen MBN. 2002. Cinema beyond cybernetics, or how to frame the digital image. <em>Configurations</em>. 10(1):</p></div><div id="ref-Han04:New"><p>Hansen MBN. 2004. <em>New Philosophy for New Media</em>. The MIT Press. ed.</p></div><div id="ref-DBLP:conf/ismir/HashidaMK08"><p>Hashida M, Matsui T, Katayose H. 2008. A new music database describing deviation information of performance expressions. <em>ISMIR 2008, 9th International Conference on Music Information Retrieval, Drexel University, Philadelphia, Pa, Usa, September 14-18, 2008</em>, pp. 489–94. <a href="http://ismir2008.ismir.net/papers/ISMIR2008_173.pdf">http://ismir2008.ismir.net/papers/ISMIR2008_173.pdf</a></p></div><div id="ref-DBLP:conf/ismir/HaugerSKT13"><p>Hauger D, Schedl M, Kosir A, Tkalcic M. 2013. The million musical tweet dataset - what we can learn from microblogs. <em>Proceedings of the 14th International Society for Music Information Retrieval Conference, ISMIR 2013, Curitiba, Brazil, November 4-8, 2013</em>, pp. 189–94. <a href="http://www.ppgia.pucpr.br/ismir2013/wp-content/uploads/2013/09/85_Paper.pdf">http://www.ppgia.pucpr.br/ismir2013/wp-content/uploads/2013/09/85_Paper.pdf</a></p></div><div id="ref-Hay93:The"><p>Hayles NK. 1993. The materiality of informatics. <em>Configurations</em>. 1(1):</p></div><div id="ref-Hay99:How"><p>Hayles NK. 1999. <em>How We Became Posthuman: Virtual Bodies in Cybernetics, Literature, and Informatics</em>. The University of Chicago Press. ed.</p></div><div id="ref-Her14:Aso"><p>Hildebrandt T, Hermann T, Rinderle-Ma S. 2014. A Sonification System for Process Monitoring as Secondary Task. <em>Proceedings of the 5th Ieee Conference on Cognitive Infocommunication (Coginfocom 2014)</em>, pp. 191–96. Vietri sul Mare, Italy: IEEE</p></div><div id="ref-Hil59:Exp"><p>Hiller LA, Isaacson LM. 1959. <em>Experimental Music: Composition with an Electronic Computer</em>. McGraw-Hill Book Company, Inc. ed.</p></div><div id="ref-Hochenbaum2010"><p>Hochenbaum J, Kapur A, Wright M. 2010. Multimodal musician recognition. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, pp. 233–37. <a href="http://www.nime.org/proceedings/2010/nime2010_233.pdf">http://www.nime.org/proceedings/2010/nime2010_233.pdf</a></p></div><div id="ref-DBLP:conf/ismir/HomburgMMMW05"><p>Homburg H, Mierswa I, Möller B, Morik K, Wurst M. 2005. A benchmark dataset for audio classification and clustering. <em>ISMIR 2005, 6th International Conference on Music Information Retrieval, London, Uk, 11-15 September 2005, Proceedings</em>, pp. 528–31. <a href="http://ismir2005.ismir.net/proceedings/2117.pdf">http://ismir2005.ismir.net/proceedings/2117.pdf</a></p></div><div id="ref-DBLP:conf/ismir/HumphreyDM18"><p>Humphrey E, Durand S, McFee B. 2018. OpenMIC-2018: An open data-set for multiple instrument recognition. <em>Proceedings of the 19th International Society for Music Information Retrieval Conference, ISMIR 2018, Paris, France, September 23-27, 2018</em>, pp. 438–44. <a href="http://ismir2018.ircam.fr/doc/pdfs/248_Paper.pdf">http://ismir2018.ircam.fr/doc/pdfs/248_Paper.pdf</a></p></div><div id="ref-Mau99:Abr"><p>IV JAM. 1999. <em>A Brief History of Algorithmic Composition</em>. Online. ed.</p></div><div id="ref-jjaimovich:2015"><p>Jaimovich J, Knapp R. 2015. Creating biosignal algorithms for musical applications from an extensive physiological database. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, pp. 1–4. Baton Rouge, Louisiana, USA: Louisiana State University</p></div><div id="ref-Jaimovich:2012"><p>Jaimovich J, Ortiz M, Coghlan N, Knapp RB. 2012. The emotion in motion experiment: Using an interactive installation as a means for understanding emotional response to music. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>. Ann Arbor, Michigan: University of Michigan</p></div><div id="ref-DBLP:conf/icmc/JonesLS07"><p>Jones R, Lagrange M, Schloss WA. 2007. A hand drumming dataset for physical modeling. <em>Proceedings of the 2007 International Computer Music Conference, ICMC 2007, Copenhagen, Denmark, August 27-31, 2007</em>. Michigan Publishing</p></div><div id="ref-DBLP:conf/ismir/SillaKK08"><p>Jr. CNS, Koerich AL, Kaestner CAA. 2008. The latin music database. <em>ISMIR 2008, 9th International Conference on Music Information Retrieval, Drexel University, Philadelphia, Pa, Usa, September 14-18, 2008</em>, pp. 451–56. <a href="http://ismir2008.ismir.net/papers/ISMIR2008_106.pdf">http://ismir2008.ismir.net/papers/ISMIR2008_106.pdf</a></p></div><div id="ref-DBLP:journals/corr/abs-1109-1145"><p>Kamde PM, Algur SP. 2011. A survey on web multimedia mining. <em>CoRR</em>. abs/1109.1145:</p></div><div id="ref-DBLP:conf/ismir/Karaosmanoglu12"><p>Karaosmanoglu MK. 2012. A turkish makam music symbolic database for music information retrieval: SymbTr. <em>Proceedings of the 13th International Society for Music Information Retrieval Conference, ISMIR 2012, Mosteiro S.bento Da Vitória, Porto, Portugal, October 8-12, 2012</em>, pp. 223–28. FEUP Edições</p></div><div id="ref-icmc/bbp2372.1999.411"><p>Katayose H, Kawahara H. 1999. Applying straight toward music systems - accurate f0 estimation and application for data-driven synthesis. <em>Proceedings of the International Computer Music Conference, ICMC 1999</em>. Michigan Publishing</p></div><div id="ref-Kawahara:2004"><p>Kawahara H, Banno H, Morise M. 2004. Acappella synthesis demonstrations using rwc music database. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, pp. 130–31. <a href="http://www.nime.org/proceedings/2004/nime2004_130.pdf">http://www.nime.org/proceedings/2004/nime2004_130.pdf</a></p></div><div id="ref-kernighan_c_1978"><p>Kernighan BW. 1978. <em>The c Programming Language</em>. Englewood Cliffs, N.J.: Prentice-Hall. ed.</p></div><div id="ref-DBLP:conf/ismir/Kirlin14"><p>Kirlin PB. 2014. A data set for computational studies of schenkerian analysis. <em>Proceedings of the 15th International Society for Music Information Retrieval Conference, ISMIR 2014, Taipei, Taiwan, October 27-31, 2014</em>, pp. 213–18. <a href="http://www.terasoft.com.tw/conf/ismir2014/proceedings/T039_344_Paper.pdf">http://www.terasoft.com.tw/conf/ismir2014/proceedings/T039_344_Paper.pdf</a></p></div><div id="ref-Kle07:Wai"><p>Klein NM. 2007. Waiting for the world to explode: How data convert into a novel. <em>Database Aesthetics: Art in the Age of Information Overflow</em></p></div><div id="ref-DBLP:conf/ismir/KneesFHVBHG15"><p>Knees P, Faraldo, Herrera P, Vogl R, Böck S, et al. 2015. Two data sets for tempo estimation and key detection in electronic dance music annotated from user corrections. <em>Proceedings of the 16th International Society for Music Information Retrieval Conference, ISMIR 2015, Málaga, Spain, October 26-30, 2015</em>, pp. 364–70. <a href="http://ismir2015.uma.es/articles/246_Paper.pdf">http://ismir2015.uma.es/articles/246_Paper.pdf</a></p></div><div id="ref-icmc/bbp2372.2003.052"><p>Kobayashi R. 2003. Sound clustering synthesis using spectral data. <em>Proceedings of the International Computer Music Conference, ICMC 2003</em>. Michigan Publishing</p></div><div id="ref-laske_otto_1999"><p>Laske OE1, Tabor J. 1999. <em>Otto Laske : Navigating New Musical Horizons</em>. Westport, Conn.: Greenwood Press. ed.</p></div><div id="ref-Lat90:On"><p>Latour B. 1990. On actor-network theory. A few clarifications plus more than a few complications. <em>Philosophia</em>. 25(3):</p></div><div id="ref-Lat93:We"><p>Latour B. 1993. <em>We Have Never Been Modern</em>. Harvard University Press Cambridge, Massachusetts. ed.</p></div><div id="ref-Lew00:Too"><p>Lewis G. 2000. Too many notes: Computers, complexity, and culture in voyager. <em>Leonardo Music Journal</em>. 10:</p></div><div id="ref-Lew99:Int"><p>Lewis GE. 1999. Interacting with latter-day musical automata. <em>Contemporary Music Review</em>. 18(3):99–112</p></div><div id="ref-icmc/bbp2372.2017.033"><p>Lindborg P. 2017. Pacific bell tower, a sculptural sound installation for live sonification of earthquake data. <em>Proceedings of the International Computer Music Conference, ICMC 2017</em>. Michigan Publishing</p></div><div id="ref-DBLP:conf/icmc/Lindemann90a"><p>Lindemann E. 1990. ANIMAL-A rapid prototyping environment for computer music systems. <em>Proceedings of the 1990 International Computer Music Conference, ICMC 1990, Glasgow, Scotland, September 10-15, 1990</em>. Michigan Publishing</p></div><div id="ref-Liu:2013"><p>Liu Q, Han YC, Kuchera-Morin J, Wright M. 2013. Cloud bridge: A data-driven immersive audio-visual software interface. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, pp. 431–36. Daejeon, Republic of Korea: Graduate School of Culture Technology, KAIST</p></div><div id="ref-Lod98:MUS"><p>Lodha S, Beahan J, Joseph A, Zane-ulman B. 1998. MUSE: A musical data sonification toolkit</p></div><div id="ref-2000-database-ims"><p>Long R, Harrington M, Hain R, Nicholls G. 2000. <em>IMS Primer</em>. International Business Machines Corporation. ed.</p></div><div id="ref-Loviscach2008"><p>Loviscach J. 2008. Programming a music synthesizer through data mining. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, pp. 221–24. <a href="http://www.nime.org/proceedings/2008/nime2008_221.pdf">http://www.nime.org/proceedings/2008/nime2008_221.pdf</a></p></div><div id="ref-Man01:The"><p>Manovich L. 2001. <em>The Language of New Media</em>. MIT Press. ed.</p></div><div id="ref-Man02:Old"><p>Manovich L. 2002. Old media as new media: Cinema. <em>The New Media Book</em></p></div><div id="ref-Mat63:The"><p>Mathews MV. 1963. The digital computer as a musical instrument. <em>Science</em>. 142(3592):553–57</p></div><div id="ref-DBLP:conf/ismir/MaxwellE08"><p>Maxwell JB, Eigenfeldt A. 2008. A music database and query system for recombinant composition. <em>ISMIR 2008, 9th International Conference on Music Information Retrieval, Drexel University, Philadelphia, Pa, Usa, September 14-18, 2008</em>, pp. 75–80. <a href="http://ismir2008.ismir.net/papers/ISMIR2008_158.pdf">http://ismir2008.ismir.net/papers/ISMIR2008_158.pdf</a></p></div><div id="ref-icmc/bbp2372.2001.051"><p>Mazzoni D, Dannenberg RB. 2001. A fast data structure for disk-based audio editing. <em>Proceedings of the International Computer Music Conference, ICMC 2001</em>. Michigan Publishing</p></div><div id="ref-DBLP:conf/icmc/McCartney96"><p>McCartney J. 1996. SuperCollider, a new real time synthesis language. <em>Proceedings of the 1996 International Computer Music Conference, ICMC 1996, Hong Kong, August 19-24, 1996</em>. Michigan Publishing</p></div><div id="ref-DBLP:conf/icmc/McCartney98"><p>McCartney J. 1998. Continued evolution of the supercollider real time synthesis environment. <em>Proceedings of the 1998 International Computer Music Conference, ICMC 1998, Ann Arbor, Michigan, Usa, October 1-6, 1998</em>. Michigan Publishing</p></div><div id="ref-csoundMethods"><p>McCurdy I, Heintz J, Joaquin J, Knevel M. 2015. Methods of writing csound scores. <em>FLOSS Manuals</em></p></div><div id="ref-icmc/bbp2372.1999.355"><p>Melucci M, Orio N. 1999. The use of melodic segmentation for content-based retrieval of musical data. <em>Proceedings of the International Computer Music Conference, ICMC 1999</em>. Michigan Publishing</p></div><div id="ref-DBLP:conf/ismir/Meseguer-Brocal18"><p>Meseguer-Brocal G, Cohen-Hadria A, Peeters G. 2018. DALI: A large dataset of synchronized audio, lyrics and notes, automatically created using teacher-student machine learning paradigm. <em>Proceedings of the 19th International Society for Music Information Retrieval Conference, ISMIR 2018, Paris, France, September 23-27, 2018</em>, pp. 431–37. <a href="http://ismir2018.ircam.fr/doc/pdfs/35_Paper.pdf">http://ismir2018.ircam.fr/doc/pdfs/35_Paper.pdf</a></p></div><div id="ref-Mital:2013"><p>Mital PK, Grierson M. 2013. Mining unlabeled electronic music databases through 3D interactive visualization of latent component relationships. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, pp. 227–32. Daejeon, Republic of Korea: Graduate School of Culture Technology, KAIST</p></div><div id="ref-DBLP:journals/corr/MitraS14"><p>Mitra J, Saha D. 2014. An efficient feature selection in classification of audio files. <em>CoRR</em>. abs/1404.1491:</p></div><div id="ref-icmc/bbp2372.2016.002"><p>Morawitz F. 2016. Molecular sonification of nuclear magnetic resonance data as a novel tool for sound creation. <em>Proceedings of the International Computer Music Conference, ICMC 2016</em>. Michigan Publishing</p></div><div id="ref-ods-cpp"><p>Morin P. 2019. <em>Open Data Structures</em>. Creative Commons. ed.</p></div><div id="ref-Mor13:Hyp"><p>Morton T. 2013. <em>Hyperobjects: Philosophy and Ecology After the End of the World</em>. University of Minnesota Press. ed.</p></div><div id="ref-DBLP:journals/corr/abs-1301-1894"><p>Nagavi TC, Bhajantri NU. 2013. An extensive analysis of query by singing/humming system through query proportion. <em>CoRR</em>. abs/1301.1894:</p></div><div id="ref-DBLP:journals/corr/NagaviB14"><p>Nagavi TC, Bhajantri NU. 2014. Progressive filtering using multiresolution histograms for query by humming system. <em>CoRR</em>. abs/1401.2516:</p></div><div id="ref-Nakamoto2007"><p>Nakamoto M, Kuhara Y. 2007. Circle canon chorus system used to enjoy a musical ensemble singing "frog round". <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, pp. 409–10. <a href="http://www.nime.org/proceedings/2007/nime2007_409.pdf">http://www.nime.org/proceedings/2007/nime2007_409.pdf</a></p></div><div id="ref-Nan91:The"><p>Nancy J-L. 1991. <em>The Inoperative Community</em>. University of Minnesota Press, Minneapolis; Oxford. ed.</p></div><div id="ref-Nan07:Lis"><p>Nancy J-L. 2007. <em>Listening</em>. Fordham University Place. ed.</p></div><div id="ref-icmc/bbp2372.2015.072"><p>Nardelli MB. 2015. Materialssoundmusic: A computer-aided data-driven composition environment for the sonification and dramatization of scientific data streams. <em>Proceedings of the International Computer Music Conference, ICMC 2015</em>. Michigan Publishing</p></div><div id="ref-icmc/bbp2372.2014.065"><p>Nichols C, Lorang M, Gibbons M, Bradley N, Browning A. 2014. Sound of rivers: Stone drum: A multimedia collaboration, with sonified data, computer-processed narration, and electric violin. <em>Proceedings of the International Computer Music Conference, ICMC 2014</em>. Michigan Publishing</p></div><div id="ref-icmc/bbp2372.2007.117"><p>Norman A, Amatriain X. 2007. DATA jockey, a tool for meta-data enhanced digital djing and active listening. <em>Proceedings of the International Computer Music Conference, ICMC 2007</em>. Michigan Publishing</p></div><div id="ref-Nort2016"><p>Nort DV, Jarvis I, Palumbo M. 2016. Towards a mappable database of emergent gestural meaning. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>. 16:46–50</p></div><div id="ref-shepard"><p>N. Shepard R. 1964. Circularity in judgments of relative pitch. <em>The Journal of the Acoustical Society of America</em>. 36:2346</p></div><div id="ref-Nuannicode225in2016"><p>Nuanàin CÓ, Jordà S, Herrera P. 2016. An interactive software instrument for real-time rhythmic concatenative synthesis. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>. 16:383–87</p></div><div id="ref-icmc/bbp2372.2002.039"><p>Osaka N, Sakakibara K-I, Hikichi T. 2002. The sound synthesis system "otkinshi": Its data structure and graphical user interface. <em>Proceedings of the International Computer Music Conference, ICMC 2002</em>. Michigan Publishing</p></div><div id="ref-Ovi19:Mem"><p>Oviedo MB. 2019. <em>Memoria, olvido y narración: Funes como antítesis del escritor</em>. Work. Pap.</p></div><div id="ref-DBLP:conf/ismir/Parada-Cabaleiro17"><p>Parada-Cabaleiro E, Batliner A, Baird A, Schuller BW. 2017. The SEILS dataset: Symbolically encoded scores in modern-early notation for computational musicology. <em>Proceedings of the 18th International Society for Music Information Retrieval Conference, ISMIR 2017, Suzhou, China, October 23-27, 2017</em>, pp. 575–81. <a href="https://ismir2017.smcnus.org/wp-content/uploads/2017/10/14_Paper.pdf">https://ismir2017.smcnus.org/wp-content/uploads/2017/10/14_Paper.pdf</a></p></div><div id="ref-icmc/bbp2372.2010.002"><p>Park S, Kim H, Lee S, Yeo WS. 2010. Composition with path : Musical sonification of geo-referenced data with online map interface. <em>Proceedings of the International Computer Music Conference, ICMC 2010</em>. Michigan Publishing</p></div><div id="ref-Pau07:The"><p>Paul C. 2007. The database as system and cultural form: Anatomies of cultural narratives. <em>Database Aesthetics: Art in the Age of Information Overflow</em></p></div><div id="ref-Wil96:Lis"><p>Pauletto S, Hunt A. 2004a. A toolkit for interactive sonification. <em>ICAD</em>. Georgia Institute of Technology</p></div><div id="ref-pauletto04"><p>Pauletto S, Hunt A. 2004b. A toolkit for interactive sonification. <em>Proceedings of Icad 04. Tenth Meeting of the International Conference on Auditory Display, Sydney, Australia, July 6-9, 2004. Ed. Barrass, S. And Vickers, P. International Community for Auditory Display, 2004.</em></p></div><div id="ref-2018arXiv180802848P"><p>Peron T, Rodrigues FA, Costa L da F. 2018. Pattern Recognition Approach to Violin Shapes of MIMO database. <em>arXiv e-prints</em>. arXiv:1808.02848</p></div><div id="ref-DBLP:conf/ismir/PesekGPSGSPM14"><p>Pesek M, Godec P, Poredos M, Strle G, Guna J, et al. 2014. Introducing a dataset of emotional and color responses to music. <em>Proceedings of the 15th International Society for Music Information Retrieval Conference, ISMIR 2014, Taipei, Taiwan, October 27-31, 2014</em>, pp. 355–60. <a href="http://www.terasoft.com.tw/conf/ismir2014/proceedings/T064_307_Paper.pdf">http://www.terasoft.com.tw/conf/ismir2014/proceedings/T064_307_Paper.pdf</a></p></div><div id="ref-Pos11:Int"><p>Poster M. 2011. Introduction. <em>Into the Universe of Technical Images</em></p></div><div id="ref-Price2008"><p>Price R, Rebelo P. 2008. Database and mapping design for audiovisual prepared radio set installation. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, pp. 311–14. <a href="http://www.nime.org/proceedings/2008/nime2008_311.pdf">http://www.nime.org/proceedings/2008/nime2008_311.pdf</a></p></div><div id="ref-DBLP:conf/ismir/ProutskovaRWC12"><p>Proutskova P, Rhodes C, Wiggins GA, Crawford T. 2012. Breathy or resonant - A controlled and curated dataset for phonation mode detection in singing. <em>Proceedings of the 13th International Society for Music Information Retrieval Conference, ISMIR 2012, Mosteiro S.bento Da Vitória, Porto, Portugal, October 8-12, 2012</em>, pp. 589–94. FEUP Edições</p></div><div id="ref-DBLP:conf/icmc/Puckette86"><p>Puckette M. 1986. Interprocess communication and timing in real-time computer music performance. <em>Proceedings of the 1986 International Computer Music Conference, ICMC 1986, Den Haag, the Netherlands, October 20-24, 1986</em>. Michigan Publishing</p></div><div id="ref-DBLP:journals/comj/Puckette02"><p>Puckette M. 2002a. Max at seventeen. <em>Computer Music Journal</em>. 26(4):31–43</p></div><div id="ref-DBLP:conf/icmc/Puckette02"><p>Puckette M. 2002b. Using pd as a score language. <em>Proceedings of the 2002 International Computer Music Conference, ICMC 2002, Gothenburg, Sweden, September 16-21, 2002</em>. Michigan Publishing</p></div><div id="ref-DBLP:conf/icmc/Puckette07"><p>Puckette M. 2007. On timbre stamps and other frequency-domain filters. <em>ICMC</em>. Michigan Publishing</p></div><div id="ref-DBLP:conf/icmc/PucketteVS81"><p>Puckette M, Vercoe B, Stautner JP. 1981. A real-time music 11 emulator. <em>Proceedings of the 1981 International Computer Music Conference, ICMC 1981, Denton, Texas, Usa, 1981</em>. Michigan Publishing</p></div><div id="ref-icmc/bbp2372.1997.060"><p>Puckette MS. 1997. Pure data. <em>Proceedings of the International Computer Music Conference, ICMC 1997</em>. Michigan Publishing</p></div><div id="ref-Roa04:Mic"><p>Roads C. 2001. <em>Microsound</em>. MIT Press. ed.</p></div><div id="ref-Roa80:Int"><p>Roads C, Mathews M. 1980. Interview with max mathews. <em>Computer Music Journal</em>. 4(4):15–22</p></div><div id="ref-croberts:2014"><p>Roberts C, Wright M, Kuchera-Morin J, Höllerer T. 2014. Rapid creation and publication of digital musical instruments. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, pp. 239–42. London, United Kingdom: Goldsmiths, University of London</p></div><div id="ref-DBLP:conf/icmc/RodetDP88"><p>Rodet X, Depalle P, Poirot G. 1988. Diphone sound synthesis based on spectral envelopes and harmonic/noise excitation functions. <em>Proceedings of the 1988 International Computer Music Conference, ICMC 1988, Cologne, Germany, September 20-25, 1988</em>. Michigan Publishing</p></div><div id="ref-DBLP:conf/icmc/RodetL96"><p>Rodet X, Lefèvre A. 1996. Macintosh graphical interface and improvements to generalized diphone control and synthesis. <em>Proceedings of the 1996 International Computer Music Conference, ICMC 1996, Hong Kong, August 19-24, 1996</em>. Michigan Publishing</p></div><div id="ref-DBLP:conf/icmc/RodetL97"><p>Rodet X, Lefèvre A. 1997. The diphone program: New features, new synthesis methods and experience of musical use. <em>Proceedings of the 1997 International Computer Music Conference, ICMC 1997, Thessaloniki, Greece, September 25-30, 1997</em>. Michigan Publishing</p></div><div id="ref-icmc/bbp2372.1996.085"><p>Rossiter D, Ng W-Y. 1996. A system for the musical investigation and expression of levels of self-similarity in an arbitrary data stream. <em>Proceedings of the International Computer Music Conference, ICMC 1996</em>. Michigan Publishing</p></div><div id="ref-Row92:Int"><p>Rowe R. 1992. <em>Interactive Music Systems: Machine Listening and Composing</em>. Cambridge, MA, USA: MIT Press. ed.</p></div><div id="ref-Row01:Mac"><p>Rowe R. 2001. <em>Machine Musicianship</em>. Cambridge, MA, USA: MIT Press. ed.</p></div><div id="ref-Lew93:Put"><p>Rowe R, Garton B, Desain P, Honing H, Dannenberg R, et al. 1993. Editor’s notes: Putting max in perspective. <em>Computer Music Journal</em>. 17(2):3–11</p></div><div id="ref-icmc/bbp2372.2010.003"><p>Sanden C, Befus CR, Zahng J. 2010. Perception based multi-genre labeling on music data. <em>Proceedings of the International Computer Music Conference, ICMC 2010</em>. Michigan Publishing</p></div><div id="ref-DBLP:conf/ismir/Sapp05"><p>Sapp CS. 2005. Online database of scores in the humdrum file format. <em>ISMIR 2005, 6th International Conference on Music Information Retrieval, London, Uk, 11-15 September 2005, Proceedings</em>, pp. 664–65. <a href="http://ismir2005.ismir.net/proceedings/3123.pdf">http://ismir2005.ismir.net/proceedings/3123.pdf</a></p></div><div id="ref-DBLP:conf/icmc/Scaletti87"><p>Scaletti CA. 1987. Kyma: An object-oriented language for music composition. <em>Proceedings of the 1987 International Computer Music Conference, ICMC 1987, Champaign/Urbana, Illinois, Usa, August 23-26, 1987</em>. Michigan Publishing</p></div><div id="ref-icmc/bbp2372.2016.056"><p>Schlei K, Yoshikane R. 2016. The things of shapes: Waveform generation using 3D vertex data. <em>Proceedings of the International Computer Music Conference, ICMC 2016</em>. Michigan Publishing</p></div><div id="ref-icmc/bbp2372.2001.103"><p>Schloss W, Driessen A, Peter, F. 2001. Towards a virtual membrane: New algorithms and technology for analyzing gestural data. <em>Proceedings of the International Computer Music Conference, ICMC 2001</em>. Michigan Publishing</p></div><div id="ref-icmc/bbp2372.2009.005"><p>Schmeder A. 2009. Efficient gesture storage and retrieval for multiple applications using a relational data model of open sound control. <em>Proceedings of the International Computer Music Conference, ICMC 2009</em>. Michigan Publishing</p></div><div id="ref-DBLP:conf/icmc/SchonerCDG98"><p>Schöner B, Cooper C, Douglas C, Gershenfeld N. 1998. Data-driven modeling and synthesis of acoustical instruments. <em>Proceedings of the 1998 International Computer Music Conference, ICMC 1998, Ann Arbor, Michigan, Usa, October 1-6, 1998</em>. Michigan Publishing</p></div><div id="ref-Schwarz2000"><p>Schwarz D. 2000. A system for data-driven concatenative sound synthesis. <em>Proceedings of the Cost G-6 Conference on Digital Audio Effects (Dafx-00), Verona, Italy, December 7-9</em></p></div><div id="ref-icmc/bbp2372.2003.099"><p>Schwarz D. 2003. New developments in data-driven concatenative sound synthesis. <em>Proceedings of the International Computer Music Conference, ICMC 2003</em>. Michigan Publishing</p></div><div id="ref-Sch06:How"><p>Schwarz D. 2006a. Concatenative sound synthesis: The early years. <em>Journal of New Music Research</em>. 35:3–22</p></div><div id="ref-Sch06:Rea"><p>Schwarz D. 2006b. Real-time corpus-based concatenative synthesis with catart., pp. 18–21</p></div><div id="ref-Schwarz:2012"><p>Schwarz D. 2012. The sound space as musical instrument: Playing corpus-based concatenative synthesis. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>. Ann Arbor, Michigan: University of Michigan</p></div><div id="ref-Selfridge-Field:1997:BMH:275928"><p>Selfridge-Field E, ed. 1997. <em>Beyond Midi: The Handbook of Musical Codes</em>. Cambridge, MA, USA: MIT Press. ed.</p></div><div id="ref-scoremus"><p>Selfridge-Field E. 1997. The score music publishing system. <em>SCORE</em></p></div><div id="ref-icmc/bbp2372.2001.071"><p>Serafin S, Smith J, III O, Thornburg H, Mazzella F, et al. 2001. Data driven identification and computer animation of bowed string model. <em>Proceedings of the International Computer Music Conference, ICMC 2001</em>. Michigan Publishing</p></div><div id="ref-serizel:hal-01393959"><p>Serizel R, Bisot V, Essid S, Richard G. 2016. Machine listening techniques as a complement to video image analysis in forensics. <em>IEEE International Conference on Image Processing</em>, pp. 948–52. <a href="https://hal.archives-ouvertes.fr/hal-01393959">https://hal.archives-ouvertes.fr/hal-01393959</a></p></div><div id="ref-picalc"><p>Shanks D, W.jun. Wrench J. 1962. Calculation of pi to 100,000 decimals. <em>Mathematics of Computation</em>. 16:</p></div><div id="ref-ilprints81"><p>Silberschatz A, Stonebraker M, Ullman J. 1995. Database research: Achievements and opportunities into the 21st century. <em>1995-15</em>, Stanford InfoLab; Stanford InfoLab</p></div><div id="ref-fdch/installation/spectral"><p>Simonelli L, Delgadino M, Cámara Halac F. 2017. <em>Hearing the Self: A Spectral Experience</em>. Xuhui Art Museum, Shanghai, China: International Computer Music Conference. ed.</p></div><div id="ref-10.2307/941442"><p>Skinner R. 1990a. Music software. <em>Notes</em>. 46(3):660–84</p></div><div id="ref-10.2307/940555"><p>Skinner R. 1990b. Music software. <em>Notes</em>. 47(1):91–101</p></div><div id="ref-DBLP:conf/ismir/SmithBFRD11"><p>Smith JBL, Burgoyne JA, Fujinaga I, Roure DD, Downie JS. 2011. Design and creation of a large-scale database of structural annotations. <em>Proceedings of the 12th International Society for Music Information Retrieval Conference, ISMIR 2011, Miami, Florida, Usa, October 24-28, 2011</em>, pp. 555–60. University of Miami</p></div><div id="ref-smith1971"><p>Smith L. 1972. SCORE: A musician’s approach to computer music. <em>Journal of the Audio Engineering Society</em>. 20(1):7–14</p></div><div id="ref-Sol05:AnI"><p>Solomos M. 2005. An introduction to horacio vaggione musical-theoretical thought. <em>Contemporary Music Review</em>. 25(4):311–26</p></div><div id="ref-DBLP:journals/corr/abs-1711-00048"><p>Stoller D, Ewert S, Dixon S. 2017. Adversarial semi-supervised audio source separation applied to singing voice extraction. <em>CoRR</em>. abs/1711.00048:</p></div><div id="ref-icmc/bbp2372.2002.056"><p>Sturm BL. 2002. Water music: Sonification of ocean buoy spectral data. <em>Proceedings of the International Computer Music Conference, ICMC 2002</em>. Michigan Publishing</p></div><div id="ref-Sze08:Lis"><p>Szendy P. 2008. <em>Listen: A History of Our Ears</em>. Fordham University. ed.</p></div><div id="ref-btaylor:2014"><p>Taylor B, Allison J, Conlin W, Oh Y, Holmes D. 2014. Simplified expressive mobile development with nexusui, nexusup, and nexusdrop. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, pp. 257–62. London, United Kingdom: Goldsmiths, University of London</p></div><div id="ref-Sch07:How"><p>Thiebaut J-B, Bello J, Schwarz D. 2007. How musical are images? From sound representation to image sonification: An eco systemic approach</p></div><div id="ref-Tru73:The"><p>Truax BD. 1973. The computer composition: Sound synthesis programs pod4, pod5 and pod6. <em>Sonological Reports</em>. 2:</p></div><div id="ref-Tru76:ACo"><p>Truax BD. 1976. A comunicational approach to computer sound programs. <em>Journal of Music Theory</em>. 20(2):227–300</p></div><div id="ref-Tru80:The"><p>Truax BD. 1980. The inverse relation between generality and strength in computer music programs. <em>Interface</em>. 9:49–57</p></div><div id="ref-Tza02:Mus"><p>Tzanetakis G, Cook P. 2002. Musical genre classification of audio signals. <em>IEEE Transactions on Speech and Audio Processing</em>. 10(5):293–302</p></div><div id="ref-Vag93:Det"><p>Vaggione H. 1993. Determinism and the false collective about models of time in early computer-aided composition. <em>Contemporary Music Review</em>. 7(2):</p></div><div id="ref-Vag01:Som"><p>Vaggione H. 2001. Some ontological remarks about music composition processes. <em>Computer Music Journal</em>. 25(1):54–61</p></div><div id="ref-Var04:The"><p>Varese E. 2004. The liberation of sound. <em>Audio Culture: Readings in Modern Music</em></p></div><div id="ref-Ves07:See"><p>Vesna V. 2007. Seeing the world in a grain of sand: The database aesthetics of everything. <em>Database Aesthetics: Art in the Age of Information Overflow</em></p></div><div id="ref-DBLP:conf/ismir/VigliensoniF17"><p>Vigliensoni G, Fujinaga I. 2017. The music listening histories dataset. <em>Proceedings of the 18th International Society for Music Information Retrieval Conference, ISMIR 2017, Suzhou, China, October 23-27, 2017</em>, pp. 96–102. <a href="https://ismir2017.smcnus.org/wp-content/uploads/2017/10/180_Paper.pdf">https://ismir2017.smcnus.org/wp-content/uploads/2017/10/180_Paper.pdf</a></p></div><div id="ref-DBLP:conf/icmc/Vinet05"><p>Vinet H. 2005. The semantic hifi project. <em>Proceedings of the 2005 International Computer Music Conference, ICMC 2005, Barcelona, Spain, September 4-10, 2005</em>. Michigan Publishing</p></div><div id="ref-DBLP:conf/ismir/VinetHP02"><p>Vinet H, Herrera P, Pachet F. 2002a. The CUIDADO project. <em>ISMIR 2002, 3rd International Conference on Music Information Retrieval, Paris, France, October 13-17, 2002, Proceedings</em>. <a href="http://ismir2002.ismir.net/proceedings/02-FP06-3.pdf">http://ismir2002.ismir.net/proceedings/02-FP06-3.pdf</a></p></div><div id="ref-DBLP:conf/icmc/VinetHP02"><p>Vinet H, Herrera P, Pachet F. 2002b. The CUIDADO project: New applications based on audio and music content description. <em>Proceedings of the 2002 International Computer Music Conference, ICMC 2002, Gothenburg, Sweden, September 16-21, 2002</em>. Michigan Publishing</p></div><div id="ref-fvisi:2017"><p>Visi F, Caramiaux B, Mcloughlin M, Miranda E. 2017. A knowledge-based, data-driven method for action-sound mapping. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, pp. 231–36. Copenhagen, Denmark: Aalborg University Copenhagen</p></div><div id="ref-rvogl:2017"><p>Vogl R, Knees P. 2017. An intelligent drum machine for electronic dance music production and performance. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, pp. 251–56. Copenhagen, Denmark: Aalborg University Copenhagen</p></div><div id="ref-icmc/bbp2372.2012.096"><p>Vogt K, Pirro D, Rumori M, Hoeldrich R. 2012. SOUNDS of simulations: DATA listening space. <em>Proceedings of the International Computer Music Conference, ICMC 2012</em>. Michigan Publishing</p></div><div id="ref-von46:Pre"><p>von Neumann J, Burks A. 1946. Preliminary discussion of the logical design of an electronic computing instrument. <em>Engineering, College of - Technical Reports</em></p></div><div id="ref-DBLP:conf/icad/2003/Walker"><p>Walker BN, Cothran JT. 2003. ICAD 2004: The 13th meeting of the international conference on auditory display, boston, ma, usa, 6-9 july 2003, proceedings.. International Community for Auditory Display</p></div><div id="ref-WalkerNees2011-TOS"><p>Walker BN, Nees MA. 2011. Theory of sonification. In <em>The Sonification Handbook</em>, eds. T Hermann, A Hunt, JG Neuhoff, pp. 9–39. Berlin, Germany: Logos Publishing House. ed.</p></div><div id="ref-DBLP:journals/corr/WangH17a"><p>Wang X, Haque SA. 2017. Classical music clustering based on acoustic features. <em>CoRR</em>. abs/1706.08928:</p></div><div id="ref-Wei07:Oce"><p>Weinbren G. 2007. Ocean, database, recut. <em>Database Aesthetics: Art in the Age of Information Overflow</em></p></div><div id="ref-Wes08:How"><p>Wessel I, Moulds ML. 2008. How many types of forgetting? Comments on connerton (2008). <em>Memory Studies</em>. 1(3):</p></div><div id="ref-icmc/bbp2372.2014.046"><p>Whalley I. 2014. Broadening telematic electroacoustic music by affective rendering and embodied real-time data sonification. <em>Proceedings of the International Computer Music Conference, ICMC 2014</em>. Michigan Publishing</p></div><div id="ref-DBLP:conf/ismir/WilkinsSWP18"><p>Wilkins J, Seetharaman P, Wahl A, Pardo B. 2018. VocalSet: A singing voice dataset. <em>Proceedings of the 19th International Society for Music Information Retrieval Conference, ISMIR 2018, Paris, France, September 23-27, 2018</em>, pp. 468–74. <a href="http://ismir2018.ircam.fr/doc/pdfs/114_Paper.pdf">http://ismir2018.ircam.fr/doc/pdfs/114_Paper.pdf</a></p></div><div id="ref-DBLP:conf/icad/2007/Worral"><p>Worrall D, Bylstra M, Barrass S, Dean R. 2007. ICAD 2004: The 13th meeting of the international conference on auditory display, montreal, canada, june 26-29 2007, proceedings.. International Community for Auditory Display</p></div><div id="ref-DBLP:conf/ismir/WustC04"><p>Wüst O, Celma. 2004. An MPEG-7 database system and application for content-based management and retrieval of music. <em>ISMIR 2004, 5th International Conference on Music Information Retrieval, Barcelona, Spain, October 10-14, 2004, Proceedings</em>. <a href="http://ismir2004.ismir.net/proceedings/p010-page-48-paper227.pdf">http://ismir2004.ismir.net/proceedings/p010-page-48-paper227.pdf</a></p></div><div id="ref-nime18-Xambo-b"><p>Xamb A, Roma G, Lerch A, Barthet M, Fazekas G. 2018. Live repurposing of sounds: MIR explorations with personal and crowdsourced databases. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, pp. 364–69. Blacksburg, Virginia, USA: Virginia Tech</p></div><div id="ref-Xen92:For"><p>Xenakis I. 1992. <em>Formalized Music: Thought and Mathematics in Music</em>. Pendragon Revised Edition. ed.</p></div><div id="ref-DBLP:conf/ismir/XiBPYB18"><p>Xi Q, Bittner RM, Pauwels J, Ye X, Bello JP. 2018. GuitarSet: A dataset for guitar transcription. <em>Proceedings of the 19th International Society for Music Information Retrieval Conference, ISMIR 2018, Paris, France, September 23-27, 2018</em>, pp. 453–60. <a href="http://ismir2018.ircam.fr/doc/pdfs/188_Paper.pdf">http://ismir2018.ircam.fr/doc/pdfs/188_Paper.pdf</a></p></div><div id="ref-DBLP:conf/icmc/XuZY05"><p>Xu Y, Zang C, Yang J. 2005. Semi-supervised classification of musical genre using multi-view features. <em>Proceedings of the 2005 International Computer Music Conference, ICMC 2005, Barcelona, Spain, September 4-10, 2005</em>. Michigan Publishing</p></div><div id="ref-ilprints489"><p>Yang C. 2001. Music database retrieval based on spectral similarity. <em>2001-14</em>, Stanford InfoLab; Stanford</p></div><div id="ref-DBLP:conf/ismir/YehBR07"><p>Yeh C, Bogaards N, Röbel A. 2007. Synthesized polyphonic music database with verifiable ground truth for multiple F0 estimation. <em>Proceedings of the 8th International Conference on Music Information Retrieval, ISMIR 2007, Vienna, Austria, September 23-27, 2007</em>, pp. 393–98. Austrian Computer Society</p></div><div id="ref-icmc/bbp2372.2004.128"><p>Yeo W, Berger S, Lee J, Zune. 2004. SonART: A framework for data sonification, visualization and networked multimedia applications. <em>Proceedings of the International Computer Music Conference, ICMC 2004</em>. Michigan Publishing</p></div><div id="ref-DBLP:conf/icmc/YeoB05"><p>Yeo WS, Berger J. 2005. Application of image sonification methods to music. <em>Proceedings of the 2005 International Computer Music Conference, ICMC 2005, Barcelona, Spain, September 4-10, 2005</em>. Michigan Publishing</p></div><div id="ref-DBLP:conf/iciso/Yokl11"><p>Yolk A, Wiering F, van Kranenburg P. 2011. UNFOLDING the potential of computational musicology. <em>Problems and Possibilities of Computational Humanities - 13th IFIP Iwra 2011 Ifip Wgs.l — International Conference on Informatics and Semiotics in Organisations, ICISO 2011, Netherlands, July 4-6, 2011. Proceedings</em>, pp. 137–44</p></div><div id="ref-Young2007"><p>Young D, Deshmane A. 2007. Bowstroke database : A web-accessible archive of violin bowing data. <em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>, pp. 352–57. <a href="http://www.nime.org/proceedings/2007/nime2007_352.pdf">http://www.nime.org/proceedings/2007/nime2007_352.pdf</a></p></div><div id="ref-DBLP:conf/icmc/Zicarelli98"><p>Zicarelli D. 1998. An extensible real-time signal processing environment for max. <em>Proceedings of the 1998 International Computer Music Conference, ICMC 1998, Ann Arbor, Michigan, Usa, October 1-6, 1998</em>. Michigan Publishing</p></div></div><section class="footnotes"><hr /><ol><li id="fn1"><p>Alvin Lucier. I Am Sitting In A Room. See: <a href="https://en.wikipedia.org/wiki/I_Am_Sitting_in_a_Room">https://en.wikipedia.org/wiki/I_Am_Sitting_in_a_Room</a><a href="#fnref1" class="footnote-back">↩</a></p></li><li id="fn2"><p>Graham Weinbren writes that a database “does not present data: it contains data. The data must always be in an arrangement…that gives the data its meaning” <span class="citation" data-cites="Wei07:Oce">(Weinbren 2007, pp. 67–69)</span>.<a href="#fnref2" class="footnote-back">↩</a></p></li><li id="fn3"><p>This example was used by Manovich in the late 1990s, and it is still valid today with most multimedia editing software.<a href="#fnref3" class="footnote-back">↩</a></p></li><li id="fn4"><p>‘Import,’ ‘export,’ and ‘render,’ refer to processes that read from or write to the computer’s disk.<a href="#fnref4" class="footnote-back">↩</a></p></li><li id="fn5"><p>Miller Puckette suggested this during an open discussion at<a href="#fnref5" class="footnote-back">↩</a></p></li><li id="fn6"><p><a href="http://kern.ccarh.org/">http://kern.ccarh.org/</a><a href="#fnref6" class="footnote-back">↩</a></p></li><li id="fn7"><p>For example, consider the MIMO database, a project dedicated to the cataloguing of musical instruments, and how it was used for the statistical tracking of the evolution of the violin based on pattern recognition of its shapes <span class="citation" data-cites="2018arXiv180802848P">(Peron et al. 2018)</span><a href="#fnref7" class="footnote-back">↩</a></p></li><li id="fn8"><p>Within musicology, an early use of the database can be found in the digitization of the Bridgman file by Hèléne Charnassé in 1980 <span class="citation" data-cites="icmc/bbp2372.1980.051">(Charnass 1980)</span>, which consisted of the extensive annotations made by Madame Bridgman in the Paris Bibliothéque Nationale, of Renaissance polyphonic music from 1420-1520<a href="#fnref8" class="footnote-back">↩</a></p></li><li id="fn9"><p>There are cases where sonification is entirely analog, such as the first sonification tool ever created: the Geiger counter<a href="#fnref9" class="footnote-back">↩</a></p></li><li id="fn10"><p>Other examples of stock market sonification include Ciardi’s set of tools for downloading and sonifying real-time data, see <span class="citation" data-cites="icmc/bbp2372.2004.124">(Ciardi 2004)</span>; and Ian Whalley’s research on telematic performance, see <span class="citation" data-cites="icmc/bbp2372.2014.046">(Whalley 2014)</span><a href="#fnref10" class="footnote-back">↩</a></p></li><li id="fn11"><p>From a lecture given by Judy Klein at New York University’s Waverly Project, on February 2nd, 2017.<a href="#fnref11" class="footnote-back">↩</a></p></li><li id="fn12"><p><a href="http://www.natashabarrett.org/viva.html">http://www.natashabarrett.org/viva.html</a><a href="#fnref12" class="footnote-back">↩</a></p></li><li id="fn13"><p>A biological field station called ‘La Suerte’ in Costa Rica<a href="#fnref13" class="footnote-back">↩</a></p></li><li id="fn14"><p><a href="https://soundcloud.com/falk-morawitz/spin-dynamics-stereo-reduction">https://soundcloud.com/falk-morawitz/spin-dynamics-stereo-reduction</a><a href="#fnref14" class="footnote-back">↩</a></p></li><li id="fn15"><p>Apple’s built-in framework to interface with the GPU . See <a href="https://developer.apple.com/documentation/metal">https://developer.apple.com/documentation/metal</a><a href="#fnref15" class="footnote-back">↩</a></p></li><li id="fn16"><p><a href="https://vimeo.com/167646306">https://vimeo.com/167646306</a><a href="#fnref16" class="footnote-back">↩</a></p></li><li id="fn17"><p>William Buxton is now considered a pioneer in HCI , and he is now a major figure in the Microsoft Research department.<a href="#fnref17" class="footnote-back">↩</a></p></li><li id="fn18"><p>SCORE is one of the earliest music engraving softwares still in use today by major publishing houses <span class="citation" data-cites="scoremus">(Selfridge-Field 1997)</span>.<a href="#fnref18" class="footnote-back">↩</a></p></li><li id="fn19"><p>For example, note a curious paragraph published at the ICMC in 1981 stating that a real-time version of MUSIC-11 was “near completion” by a group at MIT <span class="citation" data-cites="DBLP:conf/icmc/PucketteVS81">(Puckette et al. 1981)</span>.<a href="#fnref19" class="footnote-back">↩</a></p></li><li id="fn20"><p>A heap is a tree-based data structure with a property such keys and parent-child relationships follow a hierarchic logic.<a href="#fnref20" class="footnote-back">↩</a></p></li><li id="fn21"><p>“The Csángó, in some cases a Szekler ethnic group, are found in eastern Transylvania (Kalotaszeg), the Gyimes valley, and Moldavia” <span class="citation" data-cites="icmc/bbp2372.2003.030">(Ariza 2003)</span>.<a href="#fnref21" class="footnote-back">↩</a></p></li><li id="fn22"><p>A video of the installation can be seen here: <a href="https://vimeo.com/23086026">https://vimeo.com/23086026</a>, the artist website can be accessed here: <a href="http://insookchoi.com">http://insookchoi.com</a><a href="#fnref22" class="footnote-back">↩</a></p></li><li id="fn23"><p><a href="https://sihwapark.com/COMPath">https://sihwapark.com/COMPath</a><a href="#fnref23" class="footnote-back">↩</a></p></li><li id="fn24"><p>“Audio Shingling is a technique for similarity matching that concatenates audio feature vectors into a sequence of vectors, and matches the entire sequence” <span class="citation" data-cites="DBLP:conf/icmc/CaseyG07">(Casey &amp; Grierson 2007)</span>. “ Shingles are a popular way to detect duplicate web pages and to look for copies of images. Shingles are one way to determine if a new web page discovered by a web crawl is already in the database” <span class="citation" data-cites="DBLP:conf/ismir/CaseyS06">(Casey &amp; Slaney 2006)</span>.<a href="#fnref24" class="footnote-back">↩</a></p></li><li id="fn25"><p>“The Radio Drum is a three-dimensional controller that has been in existence in various forms since its original development at Bell Labs in the late 1980’s” <span class="citation" data-cites="icmc/bbp2372.2001.103">(Schloss et al. 2001)</span>.<a href="#fnref25" class="footnote-back">↩</a></p></li><li id="fn26"><p>Digital waveguides are an efficient model for physical modeling of wave propagation<a href="#fnref26" class="footnote-back">↩</a></p></li><li id="fn27"><p>Important references for their research were the following file formats: SDIF , GDIF , METRIXML (developed by Amatriain in <span class="citation" data-cites="Amatriain/2004/phdthesis">(Amatriain 2004)</span>), and the SMIL .<a href="#fnref27" class="footnote-back">↩</a></p></li><li id="fn28"><p>This structure comprises Nancy’s reading of Jacques Derrida’s concept of <em>différance</em> and will be analyzed in the following section. For a commentary on this concept, see <span class="citation" data-cites="Gra15:The">(Gratton &amp; Morin 2015, pp. 71–72)</span>; for Derrida’s original essay on the matter, see <span class="citation" data-cites="Der78:Wri Der82:Mar">(Derrida 1978, 1982)</span><a href="#fnref28" class="footnote-back">↩</a></p></li><li id="fn29"><p>In this sense, Nancy is one of the first philosophers of the self to propose such a theorization of the self as resonance, extending his speculations to, for example, considering if the philosophical truth could be something listened to, as opposed to something seen: “…shouldn’t truth ‘itself,’ as transitivity and incessant transition of a continual coming and going, be listened to rather than seen?” <span class="citation" data-cites="Nan07:Lis">(Nancy 2007, p. 4)</span><a href="#fnref29" class="footnote-back">↩</a></p></li><li id="fn30"><p>In the prologue to <em>Ficciones</em>, Borges writes that this story is a long metaphor of insomnia: “Una larga metáfora del insomnio” <span class="citation" data-cites="Ovi19:Mem">(Oviedo 2019)</span>.<a href="#fnref30" class="footnote-back">↩</a></p></li><li id="fn31"><p>Within this fictional universe, the only way for him to sleep was to imagine the opaqueness of an unknowable future…<a href="#fnref31" class="footnote-back">↩</a></p></li><li id="fn32"><p>In fact, the demand when it comes to computers is less its ability to erase —or even compress data— than storage space, a hardware-dependent commodity that has circulated ever since Von Neumann’s architecture came into the picture (See <a href="#programming" data-reference-type="ref" data-reference="programming">4.2.2</a>).<a href="#fnref32" class="footnote-back">↩</a></p></li><li id="fn33"><p>For example, one of Irineo’s concerns was to reduce the amount of memories on a single day, which he downsized to about seventy thousand…<a href="#fnref33" class="footnote-back">↩</a></p></li><li id="fn34"><p>This acousmatic quality of Funes’ voice will not be touched here, but it is indeed a good point of departure for an essay.<a href="#fnref34" class="footnote-back">↩</a></p></li><li id="fn35"><p><a href="https://en.wikipedia.org/wiki/Leo_Beranek">https://en.wikipedia.org/wiki/Leo_Beranek</a><a href="#fnref35" class="footnote-back">↩</a></p></li><li id="fn36"><p>Anthony Kerrigan translated this fragment as: “The truth is that we all live by leaving behind; no doubt we all profoundly know that we are immortal and that sooner or later every man will do all things and know everything.” In a more literal translation of the first sentence, it reads: “What is certain is that we live deferring all that can be deferred.”<a href="#fnref36" class="footnote-back">↩</a></p></li><li id="fn37"><p><a href="https://en.cppreference.com/w/cpp/language/destructor">https://en.cppreference.com/w/cpp/language/destructor</a><a href="#fnref37" class="footnote-back">↩</a></p></li><li id="fn38"><p><a href="https://mpc.chs.harvard.edu/">https://mpc.chs.harvard.edu/</a><a href="#fnref38" class="footnote-back">↩</a></p></li><li id="fn39"><p>Another example Ernst provides of the anarchive is the Internet itself: “ [The Internet] is a collection not just of unforeseen texts but of sound and images as well, an anarchive of sensory data for which no genuine archival culture has been developed so far in the occident” <span class="citation" data-cites="Ern13:Dig">(Ernst 2013, p. 139)</span>.<a href="#fnref39" class="footnote-back">↩</a></p></li><li id="fn40"><p>In signal processing terms, the sound of a voice might be approached with timbre stamps or vocoders, a type of Fourier-based filter in which “the spectrum of one sound is used to derive a filter for another” <span class="citation" data-cites="DBLP:conf/icmc/Puckette07">(Puckette 2007)</span>.<a href="#fnref40" class="footnote-back">↩</a></p></li><li id="fn41"><p>See for example Roland Barthe’s 1967 <em>Death of the Author</em>, or Michel Foucault’s 1969 text <em>What is an author?</em>, both of them commented on in <span class="citation" data-cites="Dan07:The">(Daniel 2007)</span>.<a href="#fnref41" class="footnote-back">↩</a></p></li><li id="fn42"><p>The word ‘microsound’ refers to sonic events shaped below the threshold of the ‘note.’ See <span class="citation" data-cites="Roa04:Mic">(Roads 2001)</span><a href="#fnref42" class="footnote-back">↩</a></p></li><li id="fn43"><p>For example, in the work of Beatriz Ferreyra, Elsa Justel, Mario Mary, to name a few. For an approach to Justel’s timeline-based spatialization techniques, see <span class="citation" data-cites="fdch/papers/elsa">(Cámara Halac 2018b)</span>.<a href="#fnref43" class="footnote-back">↩</a></p></li><li id="fn44"><p>In a recent study, sound itself proven to make (tiny) gravitational fields: “We show that, in fact, sound waves do carry mass —in particular, gravitational mass. This implies that a sound wave not only is affected by gravity but also generates a tiny gravitational field, an aspect not appreciated thus far” <span class="citation" data-cites="PhysRevLett.122.084501">(Esposito et al. 2019)</span>.<a href="#fnref44" class="footnote-back">↩</a></p></li><li id="fn45"><p>Among other things, the IBM-7090 computer was used in the computation of the first 100,000 digits of <span class="math inline"><em>π</em></span> <span class="citation" data-cites="picalc">(Shanks &amp; W.jun. Wrench 1962)</span>, Roger Shepard’s computation of the homonymous ‘shepard’ tone <span class="citation" data-cites="shepard">(N. Shepard 1964)</span>, Alexander Hurwitz’s computation of the 19th and 20th mersenne prime numbers,, <a href="https://www.mersenne.org/primes/">https://www.mersenne.org/primes/</a> and Peter Sellers’ plot-twisting moment in Stanley Kubrick’s “Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb:” <a href="https://en.wikipedia.org/wiki/Dr._Strangelove">https://en.wikipedia.org/wiki/Dr._Strangelove</a><a href="#fnref45" class="footnote-back">↩</a></p></li><li id="fn46"><p>Interestingly, given that <span class="citation" data-cites="arizaSieves">Ariza (2005b)</span> finds Xenakis’ sieves code unusable <span class="citation" data-cites="arizaSieves">(Ariza 2005b, p. 1)</span>, chances are that the printed code for the ST/10-3 composition is likewise useless.<a href="#fnref46" class="footnote-back">↩</a></p></li><li id="fn47"><p>For further reference on the early uses of computers in CAC , I refer the reader to <span class="citation" data-cites="Ari05:Ano">Ariza (2005a)</span>’s PhD thesis <span class="citation" data-cites="Ari05:Ano">(Ariza 2005a)</span>.<a href="#fnref47" class="footnote-back">↩</a></p></li><li id="fn48"><p>As an example, I would refer the reader to James Tenney’s work from 1962 “Five Stochastic Studies,” which can be found on a YouTube account on his name: <a href="https://www.youtube.com/channel/UCEzSaoPnxCJVzXxA9obuRWg/videos">https://www.youtube.com/channel/UCEzSaoPnxCJVzXxA9obuRWg/videos</a>. Roads, while interviewing Matthews recalls this piece to be named “Noise Studies” <span class="citation" data-cites="Roa80:Int">(Roads &amp; Mathews 1980, p. 18)</span>, which fades out the reference to Xenakis’ music.<a href="#fnref48" class="footnote-back">↩</a></p></li><li id="fn49"><p>As a reference, the computation of the first 100,000 values of <span class="math inline"><em>π</em></span> took about eight and a half hours <span class="citation" data-cites="picalc">(Shanks &amp; W.jun. Wrench 1962)</span>.<a href="#fnref49" class="footnote-back">↩</a></p></li><li id="fn50"><p>However unfortunate this ‘bang’ name is, it makes one think back to the 1946 setting of the UNIVAC computer, in the military context of the Manhattan Project, for which the computer was used to get closer to the ‘H’ bomb. That is to say, even if ‘bang’ was named differently, the computer itself would be inevitably linked to this particularly <em>big</em> bang.<a href="#fnref50" class="footnote-back">↩</a></p></li><li id="fn51"><p>Since, the notion of a ‘piece’ presupposes that of the whole to which it belongs.<a href="#fnref51" class="footnote-back">↩</a></p></li><li id="fn52"><p>‘Max’ is named after the ‘father’ of computer music Max Mathews, and MAX/MSP contains Miller Puckettes’s initials. Friendly gestures, most probably, but also pointers to originary sources, sources of inspiration, historical references that contextualize computer music software within broader social and environmental structures.<a href="#fnref52" class="footnote-back">↩</a></p></li></ol></section>
</body>
</html>
